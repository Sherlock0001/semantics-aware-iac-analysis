{"code": "when_boolean: $common_upgrade", "label": 1, "commit_name": "syntax, typos + ruby role"}
{"code": "when: common_upgrade", "label": 0, "commit_name": "syntax, typos + ruby role"}
{"code": "get_url: url=https://gist.githubusercontent.com/urbanslug/19f66c6692c0057fa40cbf09c721c629/raw/3b1d6543c8b7aa911f3b6016f7bcec30aabd0298/arch_install.sh raw: bash /root/arch_install.sh", "label": 1, "commit_name": "Make it open source-able"}
{"code": "get_url: url=https://raw.githubusercontent.com/gh2o/digitalocean-debian-to-arch/debian9/install.sh raw: bash /root/arch_install.sh --i_understand_that_this_droplet_will_be_completely_wiped", "label": 0, "commit_name": "Make it open source-able"}
{"code": "- php - php7.0 - php7.0-fpm - php7.0-cli name: \"{{php_additional_packages}}\"", "label": 1, "commit_name": "Role php-fpm: fix linting errors"}
{"code": "- php - php7.0 - php7.0-fpm - php7.0-cli name: \"{{ php_additional_packages }}\"", "label": 0, "commit_name": "Role php-fpm: fix linting errors"}
{"code": "", "label": 1, "commit_name": "start service fix"}
{"code": "- name: start service tags: service service: name=httpd state=started enabled=yes", "label": 0, "commit_name": "start service fix"}
{"code": "set_fact: set_fact: package: service: lineinfile:", "label": 1, "commit_name": "Don't pin cryptographic modules, fix ansible-lint (#184)"}
{"code": "tags: - skip_ansible_lint tags: - skip_ansible_lint ansible.builtin.set_fact: ansible.builtin.set_fact: ansible.builtin.package: ansible.builtin.service: ansible.builtin.lineinfile:", "label": 0, "commit_name": "Don't pin cryptographic modules, fix ansible-lint (#184)"}
{"code": "with_items: \"{{ result.stdout_lines }}\"", "label": 1, "commit_name": "plugins: Fix handling when there are plugins"}
{"code": "with_items: \"{{ result.get('stdout_lines', []) }}\"", "label": 0, "commit_name": "plugins: Fix handling when there are plugins"}
{"code": "- \"travis_wait 30 ansible-playbook --extra-vars 'configure_sudoers=false' main.yml\"", "label": 1, "commit_name": "Issue #63: Try using YAML instead of JSON for the extra-vars."}
{"code": "- \"travis_wait 30 ansible-playbook --extra-vars 'configure_sudoers: false' main.yml\"", "label": 0, "commit_name": "Issue #63: Try using YAML instead of JSON for the extra-vars."}
{"code": "# local installation - name: install plantd locally hosts: local become: yes vars_files: - vars/main.yml - vars/postgres.yml - vars/nginx.yml roles: # common packages and setup steps - role: common when: run.deps.common == true tags: [ \"common\" ] - role: network when: run.network == true tags: [ \"network\" ] # services required for running plantd - role: cockpit when: run.cockpit == true tags: [ \"cockpit\" ] - role: ansible-timescaledb when: run.timescaledb == true tags: [ \"postgresql\", \"timescaledb\" ] - role: ansible-grafana when: run.grafana == true tags: [ \"grafana\" ] - role: mongodb when: run.mongodb == true tags: [ \"mongodb\" ] - role: geerlingguy.nginx when: run.nginx == true tags: [ \"nginx\" ] - role: nginx when: run.nginx == true tags: [ \"nginx\" ] # built library dependencies - role: ansible-libapex when: run.deps.libapex == true tags: [ \"plantd\", \"common\" ] - role: ansible-aravis when: run.deps.aravis == true tags: [ \"aravis\" ] # plantd installation pre-install - role: preinst when: run.preinst == true tags: [ \"setup\" ] # plantd services - role: ansible-plantd-master when: run.plantd.master == true tags: [ \"plantd\", \"master\" ] - role: ansible-plantd-configure when: run.plantd.configure == true tags: [ \"plantd\", \"configure\" ] - role: ansible-plantd-broker when: run.plantd.broker == true tags: [ \"plantd\", \"broker\" ] - role: ansible-plantd-unit when: run.plantd.unit == true tags: [ \"plantd\", \"unit\" ] # todo: move all of this into the plantd.yml playbook instead (?) # plantd post-installation - role: postinst when: run.postinst == true tags: [ \"setup\" ]", "label": 1, "commit_name": "refactor: move playbooks"}
{"code": "# print all host facts - import_playbook: playbooks/debug.yml tags: [ \"debug\" ] # install galaxy role dependencies - import_playbook: playbooks/galaxy.yml tags: [ \"galaxy\" ] # install the system - import_playbook: playbooks/install.yml # install the system modules - import_playbook: playbooks/modules.yml tags: [ \"modules\" ]", "label": 0, "commit_name": "refactor: move playbooks"}
{"code": "- name: apply system hardening rules", "label": 1, "commit_name": "fix some ansible-lint errors"}
{"code": "- name: apply system hardening rules", "label": 0, "commit_name": "fix some ansible-lint errors"}
{"code": "- name: build infinity engine enhanced edition modding environment on linux hosts: localhost gather_facts: true vars: vars_files: - vars/main.yml tasks: - name: vdisk creation ansible.builtin.import_tasks: tasks/vdisk.yml - name: migrate games to vdisk ansible.builtin.import_tasks: tasks/games.yml - name: get modding tools ansible.builtin.import_tasks: tasks/tools.yml", "label": 1, "commit_name": "Updated to create root path and fix ansible-lint errors (untested)"}
{"code": "- name: build infinity engine enhanced edition modding environment on linux hosts: localhost gather_facts: true vars: vars_files: - vars/main.yml tasks: - name: virtual disk creation ansible.builtin.import_tasks: tasks/vdisk.yml - name: migrate games to vdisk ansible.builtin.import_tasks: tasks/games.yml - name: get modding tools ansible.builtin.import_tasks: tasks/tools.yml", "label": 0, "commit_name": "Updated to create root path and fix ansible-lint errors (untested)"}
{"code": "# name: ansible-role-init # name: ansible-role-pip # name: ansible-role-ohmyzsh name: pandemonium1986.init name: pandemonium1986.ansible name: pandemonium1986.ohmyzsh", "label": 1, "commit_name": "fix : lint playbook"}
{"code": "# name: ansible-role-init # name: ansible-role-pip # name: ansible-role-ohmyzsh name: pandemonium1986.init name: pandemonium1986.ansible name: pandemonium1986.ohmyzsh", "label": 0, "commit_name": "fix : lint playbook"}
{"code": "- name: remove trackingdb-1 on secondary cluster name: \"{{ secondary_instance }}-trackingdb-1\" machine_type: \"{{ machine_type }}\" zone: \"{{ zone }}\" project: \"{{ project_id }}\" auth_kind: serviceaccount service_account_file: \"{{ credentials_file }}\" state: absent - name: remove trackingdb-2 on secondary cluster gcp_compute_instance: name: \"{{ secondary_instance }}-trackingdb-2\" machine_type: \"{{ machine_type }}\" zone: \"{{ zone }}\" project: \"{{ project_id }}\" auth_kind: serviceaccount service_account_file: \"{{ credentials_file }}\" state: absent - name: remove trackingdb-3 on secondary cluster gcp_compute_instance: name: \"{{ secondary_instance }}-trackingdb-3\" machine_type: \"{{ machine_type }}\" zone: \"{{ zone }}\" project: \"{{ project_id }}\" auth_kind: serviceaccount service_account_file: \"{{ credentials_file }}\" state: absent - name: remove tracking db pgbouncer on secondary cluster gcp_compute_instance: name: \"{{ secondary_instance }}-pgbouncer-trackingdb\"", "label": 1, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "- name: remove trackingdb and pgbouncer instances on secondary cluster name: \"{{ secondary_instance }}-{{ item }}\" with_items: - trackingdb-1 - trackingdb-2 - trackingdb-3 - pgbouncer-trackingdb async: 300 poll: 2", "label": 0, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "- \"prepare\" - \"converge\" - \"idempotence\" - \"verify\"", "label": 1, "commit_name": "fix CI"}
{"code": "#- \"prepare\" #- \"converge\" #- \"idempotence\" #- \"verify\"", "label": 0, "commit_name": "fix CI"}
{"code": "- src: 'git+ssh://git@gitlab.com:cutlet.fat/hello-ansible-role-template.git' version: 1.0", "label": 1, "commit_name": "fix requirements to work with gitlab"}
{"code": "- src: https://gitlab.com/cutlet.fat/hello-ansible-role-template.git scm: git version: \"0.9\"", "label": 0, "commit_name": "fix requirements to work with gitlab"}
{"code": "set_fact: set_fact: set_fact:", "label": 1, "commit_name": "Don't pin cryptographic modules, fix ansible-lint (#184)"}
{"code": "ansible.builtin.set_fact: ansible.builtin.set_fact: ansible.builtin.set_fact:", "label": 0, "commit_name": "Don't pin cryptographic modules, fix ansible-lint (#184)"}
{"code": "- dns_private", "label": 1, "commit_name": "fix variable check"}
{"code": "- dns_private_key", "label": 0, "commit_name": "fix variable check"}
{"code": "- import_playbook: automationhub-content.yml", "label": 1, "commit_name": "fixed typo"}
{"code": "- import_playbook: automationhub-content.yml", "label": 0, "commit_name": "fixed typo"}
{"code": "# this playbook requires ansible >= 2.8, or role azure.azure_preview_modules. roles: - azure.azure_preview_modules allow_forwarded_traffic: true", "label": 1, "commit_name": "fix vnet peering sample (#65)"}
{"code": "# this playbook requires ansible >= 2.8, or role azure.azure_preview_modules. resource_group_secondary: \"{{ resource_group_name }}2\" peering_name: peer1 # uncomment role reference if you're using ansible version < 2.8. # at same time, install the role by ansible-galaxy install azure.azure_preview_modules # roles: # - azure.azure_preview_modules - name: create a resource group azure_rm_resourcegroup: name: \"{{ resource_group }}\" location: \"{{ location }}\" - name: create secondary resource group azure_rm_resourcegroup: name: \"{{ resource_group_secondary }}\" location: \"{{ location }}\" allow_forwarded_traffic: true - name: delete vnet peering azure_rm_virtualnetworkpeering: resource_group: \"{{ resource_group }}\" name: \"{{ peering_name }}\" virtual_network: \"{{ vnet_name1 }}\"", "label": 0, "commit_name": "fix vnet peering sample (#65)"}
{"code": "shell: .venv/bin/pip3 install -u pip", "label": 1, "commit_name": "Fix pip command"}
{"code": "shell: .venv/bin/pip install -u pip", "label": 0, "commit_name": "Fix pip command"}
{"code": "curl -h \"authorization: bearer {{ awx_token }}\" -kx get 'https://{{ awx_url }}/api/v2/job_templates/?status=failed' curl -h \"authorization: bearer {{ awx_token }}\" -kx get 'https://{{ awx_url }}/api/v2/jobs/169/stdout/?format=txt' - name: set facts for job id, status, output etc job_id: \"{{ job_details.stdout | from_json | json_query('results[0].summary_fields.recent_jobs[0].id') }}\" job_finished: \"{{ job_details.stdout | from_json | json_query('results[0].summary_fields.recent_jobs[0].finished') }}\" -f text='\"an awx job has failed. job id: {{ job_id }} job finished: {{ job_finished }} visit this url to view the failed job: https://{{ awx_url }}/#/jobs/playbook/{{ job_id }}/output\"'", "label": 1, "commit_name": "fix for error report"}
{"code": "curl -h \"authorization: bearer {{ awx_token }}\" -kx get 'https://{{ host_awx_url }}/api/v2/job_templates/?status=failed' - name: set facts for job id and datetime set_fact: job_id: \"{{ job_details.stdout | from_json | json_query('results[0].summary_fields.recent_jobs[0].id') }}\" job_finished: \"{{ job_details.stdout | from_json | json_query('results[0].summary_fields.recent_jobs[0].finished') }}\" curl -h \"authorization: bearer {{ awx_token }}\" -kx get 'https://{{ host_awx_url }}/api/v2/jobs/{{ job_id }}/stdout/?format=txt' - name: set fact for job error -f text='\"an awx job has failed. job id: {{ job_id }} job finished: {{ job_finished }} visit this url to view the failed job: https://{{ host_awx_url }}/#/jobs/playbook/{{ job_id }}/output\"'", "label": 0, "commit_name": "fix for error report"}
{"code": "src: \"https://github.com/cbz-d-velop/ansible-role-labocbz-deploy-phpmyadmin.git\"", "label": 1, "commit_name": "fix requirements"}
{"code": "src: \"https://github.com/cbz-d-velop/ansible-role-labocbz-prepare-host.git\"", "label": 0, "commit_name": "fix requirements"}
{"code": "apt: name=python-psutil apt: name=gnome-tweak-tool apt: name=mutter become_user: lars dconf: key=\"/org/gnome/desktop/background/picture-uri\" value=\"'file:///usr/share/backgrounds/ross_jones_rockpool_(sydney)_by_chris_carignan.jpg'\" become_user: lars dconf: key=\"/org/gnome/desktop/screensaver/picture-uri\" value=\"'file:///usr/share/backgrounds/ross_jones_rockpool_(sydney)_by_chris_carignan.jpg'\" become_user: lars dconf: key=\"/org/gnome/desktop/screensaver/lock-enabled\" value=\"false\" become_user: lars dconf: key=\"/org/gnome/mutter/dynamic-workspaces\" value=\"false\" become_user: lars dconf: key=\"/org/gnome/mutter/workspaces-only-on-primary\" value=\"false\" become_user: lars dconf: key=\"/org/gnome/settings-daemon/plugins/color/night-light-enabled\" value=\"true\"", "label": 1, "commit_name": "Fix indenting"}
{"code": "apt: name=python-psutil apt: name=gnome-tweak-tool apt: name=mutter become_user: lars dconf: key=\"/org/gnome/desktop/background/picture-uri\" value=\"'file:///usr/share/backgrounds/ross_jones_rockpool_(sydney)_by_chris_carignan.jpg'\" become_user: lars dconf: key=\"/org/gnome/desktop/screensaver/picture-uri\" value=\"'file:///usr/share/backgrounds/ross_jones_rockpool_(sydney)_by_chris_carignan.jpg'\" become_user: lars dconf: key=\"/org/gnome/desktop/screensaver/lock-enabled\" value=\"false\" become_user: lars dconf: key=\"/org/gnome/mutter/dynamic-workspaces\" value=\"false\" become_user: lars dconf: key=\"/org/gnome/mutter/workspaces-only-on-primary\" value=\"false\" become_user: lars dconf: key=\"/org/gnome/settings-daemon/plugins/color/night-light-enabled\" value=\"true\"", "label": 0, "commit_name": "Fix indenting"}
{"code": "- shell: ' sudo apt-get install postgresql postgresql-contrib '", "label": 1, "commit_name": "some fixes"}
{"code": "- shell: ' sudo apt-get install -y postgresql postgresql-contrib '", "label": 0, "commit_name": "some fixes"}
{"code": "- name: setup jenkins on vm on aws", "label": 1, "commit_name": "update code"}
{"code": "- name: setup gitlab on vm on aws", "label": 0, "commit_name": "update code"}
{"code": "lidarr_auth_method: 'none'", "label": 1, "commit_name": "fix: update auth method default value"}
{"code": "lidarr_auth_method: 'external'", "label": 0, "commit_name": "fix: update auth method default value"}
{"code": "# insure service is running. - name: apache | insure deamon is running correctly", "label": 1, "commit_name": "syntax, typos + ruby role"}
{"code": "# ensure service is running. - name: apache | ensure deamon is running correctly", "label": 0, "commit_name": "syntax, typos + ruby role"}
{"code": "influxdb_database: \"{{ influxdb.database|default(ansible_host) }}\"", "label": 1, "commit_name": "Refine inventory and variable override per host."}
{"code": "influxdb_database: \"{{ influxdb.database|default(host_influxdb_database) }}\"", "label": 0, "commit_name": "Refine inventory and variable override per host."}
{"code": "- vars/env.yml", "label": 1, "commit_name": "fix: use relative vars path"}
{"code": "- ../vars/env.yml", "label": 0, "commit_name": "fix: use relative vars path"}
{"code": "# adding local storage class - name: kubernetes - adding local storage class '{{kube_inst_add_sc}}' shell: '{{kube_inst_add_sc}}'", "label": 1, "commit_name": "Tiller role is added, some errors during consecutive runs are fixed"}
{"code": "ignore_errors: true ignore_errors: true adding local storage class - name: kubernetes - adding local storage class and making it default shell: '{{kube_inst_add_sc}}' # kubectl patch storageclass local-storage -p \"{metadata:{annotations:{storageclass.kubernetes.io/is-default-class:true}}}\"", "label": 0, "commit_name": "Tiller role is added, some errors during consecutive runs are fixed"}
{"code": "when: 'not \"security\" in es_xpack_features' when: '\"security\" in es_xpack_features'", "label": 1, "commit_name": "Fix conditionals introduced in #408"}
{"code": "when: not \"security\" in es_xpack_features when: \"'security' in es_xpack_features\"", "label": 0, "commit_name": "Fix conditionals introduced in #408"}
{"code": "mode: 0644 - name: \"copy {{ qbt.service.src }}\" mode: 0664", "label": 1, "commit_name": "Fix created dir permissions"}
{"code": "mode: 0755 - name: \"copy qbittorrent configuration file\" mode: 0644", "label": 0, "commit_name": "Fix created dir permissions"}
{"code": "- name: php.ini - change max upload size to 10m replace: dest=/etc/php5/fpm/php.ini regexp='^upload_max_filesize = 2m$' replace='upload_max_filesize = 10m'", "label": 1, "commit_name": "Postfix; fix php fpm restart"}
{"code": "# configure and secure php.ini - name: php.ini - change max upload size to 15m replace: dest=/etc/php5/fpm/php.ini regexp='^upload_max_filesize = 2m$' replace='upload_max_filesize = 15m' notify: restart php5-fpm - name: php.init - ensure php5-fpm cgi.fix_pathinfo=0 lineinfile: dest=/etc/php5/fpm/php.ini regexp='^(.*)cgi.fix_pathinfo=' line=cgi.fix_pathinfo=0", "label": 0, "commit_name": "Postfix; fix php fpm restart"}
{"code": "# install/run filebeat elk client shell: curl http://\"{{ elk_server }}\":{{ elk_server_ssl_cert_port }}/filebeat-forwarder.crt > /etc/pki/tls/certs/filebeat-forwarder.crt", "label": 1, "commit_name": "Multiple fixes, cleanup, ES listen port options"}
{"code": "# install/run filebeat elk client for browbeat get_url: url=http://{{ elk_server }}:{{ elk_server_ssl_cert_port }}/filebeat-forwarder.crt dest=/etc/pki/tls/certs/filebeat-forwarder.crt", "label": 0, "commit_name": "Multiple fixes, cleanup, ES listen port options"}
{"code": "vars: php_path: /opt/rh/rh-php72/root/usr/bin/php vars: php_path: /opt/rh/rh-php72/root/usr/bin/php", "label": 1, "commit_name": "feat(receipe): fix symfony receipe"}
{"code": "- name: inclure les variables utilisateur include_vars: vars.yml - name: inclure les variables utilisateur include_vars: vars.yml", "label": 0, "commit_name": "feat(receipe): fix symfony receipe"}
{"code": "name: \"{{ item }}\" with_items: - \"{{ letsencrypt.packages_list }}\"", "label": 1, "commit_name": "fix ansible loop usage to avoid deprecation warning"}
{"code": "name: \"{{ letsencrypt.packages_list }}\"", "label": 0, "commit_name": "fix ansible loop usage to avoid deprecation warning"}
{"code": "export overlay=${network}-full", "label": 1, "commit_name": "fix(kustomize-cardano-node): fix overlay path for kapp deploy"}
{"code": "export overlay=local-${network}-full", "label": 0, "commit_name": "fix(kustomize-cardano-node): fix overlay path for kapp deploy"}
{"code": "- import_playbook: snmpd.yml - import_playbook: gpsd.yml", "label": 1, "commit_name": "Fix name of imported playbooks to be plural"}
{"code": "- import_playbook: snmpds.yml - import_playbook: gpsds.yml", "label": 0, "commit_name": "Fix name of imported playbooks to be plural"}
{"code": "marker: '# {mark} i3_xinitrc' [service] execstart=", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "# # boot sequence: # systemd boot -> agetty (autologin into user) -> zsh (sources .zshrc) -> startx (sources .xinitrc) -> i3 - dunst # system notifications marker: '# {mark} agetty_autologin' [service] execstart= # https://github.com/askannz/optimus-manager/wiki/faq,-common-issues,-troubleshooting#i-do-not-use-a-display-manager-i-use-startx-or-xinit execstartpre=-/usr/bin/prime-switch /usr/bin/prime-offload # https://github.com/askannz/optimus-manager/wiki/faq,-common-issues,-troubleshooting#i-do-not-use-a-display-manager-i-use-startx-or-xinit", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "- name: ensuring that the release build of pleroma is downloaded. - name: setting up the pleroma service. state: restarted", "label": 1, "commit_name": "fix: implement an upgrade procedure for Pleroma."}
{"code": "- name: checking if pleroma is already installed. stat: path: \"{{ pleroma_user.home }}/bin/pleroma\" register: pleroma_bin - debug: msg: \"pleroma is currently installed.\" verbosity: 0 when: pleroma_bin.stat.isreg is defined - debug: msg: \"pleroma does not appear to be installed. it will be downloaded and installed.\" verbosity: 0 when: pleroma_bin.stat.isreg is not defined - name: registering the 'enable_pleroma_download' flag. set_fact: enable_pleroma_download: true when: (pleroma_bin.stat.isreg is not defined) or (enable_pleroma_upgrade | default(false)) - name: registering the 'enable_pleroma_installation' flag. set_fact: enable_pleroma_installation: true when: pleroma_bin.stat.isreg is not defined - name: ensuring that the stable release build of pleroma is downloaded. when: enable_pleroma_download | default(false) when: enable_pleroma_download | default(false) - name: registering the installed version of pleroma. shell: \"{{ pleroma_user.home }}/bin/pleroma version | awk '{print $2}'\" register: pleroma_installed_version when: enable_pleroma_upgrade | default(false) - debug: msg: \"version {{ pleroma_installed_version.stdout }} is installed.\" verbosity: 0 when: enable_pleroma_upgrade | default(false) - name: registering the downloaded version of pleroma. shell: /tmp/release/bin/pleroma version | awk '{print $2}' register: pleroma_downloaded_version when: enable_pleroma_upgrade | default(false) - debug: msg: \"version {{ pleroma_downloaded_version.stdout }} is downloaded.\" verbosity: 0 when: enable_pleroma_upgrade | default(false) - name: comparing the installed and downloaded versions of pleroma. compare_semantic_versions: old_version: \"{{ pleroma_installed_version.stdout }}\" new_version: \"{{ pleroma_downloaded_version.stdout }}\" register: comparison when: enable_pleroma_upgrade | default(false) - fail: msg: \"this playbook does not currently support downgrading pleroma.\" when: comparison.result is defined and comparison.result == \"downgrade\" - debug: msg: \"pleroma is already installed at the target version {{ pleroma_downloaded_version.stdout }}.\" verbosity: 0 when: comparison.result is defined and comparison.result == \"noversionchange\" - debug: msg: \"pleroma will be upgraded to version {{ pleroma_downloaded_version.stdout }}.\" verbosity: 0 when: comparison.result is defined and comparison.result == \"upgrade\" - name: registering the 'enable_pleroma_installation' flag for the upgrade. set_fact: enable_pleroma_installation: true when: comparison.result is defined and comparison.result == \"upgrade\" - name: ensuring that the pleroma service is stopped. service: name: pleroma state: stopped when: comparison.result is defined and comparison.result == \"upgrade\" - name: ensuring that the previous version of pleroma is uninstalled. shell: | find {{ pleroma_user.home }} -mindepth 1 -maxdepth 1 | xargs -i dir rm -rf dir when: comparison.result is defined and comparison.result == \"upgrade\" when: enable_pleroma_installation is defined when: enable_pleroma_installation is defined - name: ensuring that the pleroma init file is installed. state: started", "label": 0, "commit_name": "fix: implement an upgrade procedure for Pleroma."}
{"code": "- name: install tftp server hosts: all tasks: - name: install tftpd-hpa become: true apt: state: present name: - tftpd-hpa", "label": 1, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "- name: install tftpd-hpa become: true apt: state: present name: - tftpd-hpa", "label": 0, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "# - cworobetz.personal", "label": 1, "commit_name": "Fix merge conflict"}
{"code": "- cworobetz.personal", "label": 0, "commit_name": "Fix merge conflict"}
{"code": "- import_playbook: install/stow.yml - import_playbook: install/nfs.yml - import_playbook: install/tftpd.yml - import_playbook: install/vim.yml - import_playbook: install/tree.yml - import_playbook: configure/git.yml - import_playbook: project/nos/configure_nfs_and_tftp.yml", "label": 1, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "- hosts: all become: true tasks: - name: install stow. ansible.builtin.import_tasks: install/stow.yml - name: install nfs kernel server. ansible.builtin.import_tasks: install/nfs.yml - name: install tftp. ansible.builtin.import_tasks: install/tftpd.yml - name: install vim. ansible.builtin.import_tasks: install/vim.yml - name: install tree. ansible.builtin.import_tasks: install/tree.yml - name: configure git. ansible.builtin.import_tasks: configure/git.yml - name: setup nfs and tftp server. ansible.builtin.import_tasks: project/nos/configure_nfs_and_tftp.yml", "label": 0, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "postgresql['md5_auth_cidr_addresses'] = [ '{{ groups.primary_patronis_internal[0] }}/32', '{{ groups.primary_patronis_internal[1] }}/32', '{{ groups.primary_patronis_internal[2] }}/32', '{{ groups.secondary_patronis_internal[0] }}/32', '{{ groups.secondary_patronis_internal[1] }}/32', '{{ groups.secondary_patronis_internal[2] }}/32', '{{ groups.primary_pgbouncer_internal[0] }}/32', '{{ groups.secondary_pgbouncer_internal[0] }}/32', '{{ groups.primary_host_internal[0] }}/32', '{{ groups.secondary_host_internal[0] }}/32', 'localhost' '{{ groups.primary_patronis_internal[0] }}/32', '{{ groups.primary_patronis_internal[1] }}/32', '{{ groups.primary_patronis_internal[2] }}/32', '{{ groups.secondary_patronis_internal[0] }}/32', '{{ groups.secondary_patronis_internal[1] }}/32', '{{ groups.secondary_patronis_internal[2] }}/32', '{{ groups.primary_pgbouncer_internal[0] }}/32', '{{ groups.secondary_pgbouncer_internal[0] }}/32', '{{ groups.secondary_pgbouncer_trackingdb[0] }}/32', '{{ groups.secondary_trackingdbs_internal[0] }}/32', '{{ groups.secondary_trackingdbs_internal[1] }}/32', '{{ groups.secondary_trackingdbs_internal[2] }}/32', '{{ groups.primary_host_internal[0] }}/32', '{{ groups.secondary_host_internal[0] }}/32', 'localhost'", "label": 1, "commit_name": "Refactor postgresql authentication configuration"}
{"code": "postgresql['md5_auth_cidr_addresses'] = %w[ {% for host in groups.primary_patronis_internal %}{{ host }}/32 {% endfor %} {% for host in groups.secondary_patronis_internal %}{{ host }}/32 {% endfor %} {{ groups.primary_pgbouncer_internal[0] }}/32 {{ groups.secondary_pgbouncer_internal[0] }}/32 {{ groups.primary_host_internal[0] }}/32 {{ groups.secondary_host_internal[0] }}/32 localhost {% for host in groups.primary_patronis_internal %}{{ host }}/32 {% endfor %} {% for host in groups.secondary_patronis_internal %}{{ host }}/32 {% endfor %} {{ groups.primary_pgbouncer_internal[0] }}/32 {{ groups.secondary_pgbouncer_internal[0] }}/32 {{ groups.primary_host_internal[0] }}/32 {{ groups.secondary_host_internal[0] }}/32 localhost", "label": 0, "commit_name": "Refactor postgresql authentication configuration"}
{"code": "name: \"{{ item }}\" with_items: - acmetool.service - acmetool.timer", "label": 1, "commit_name": "Role Nginx: fix #49 (idempotence for acmetool task)"}
{"code": "name: acmetool.timer", "label": 0, "commit_name": "Role Nginx: fix #49 (idempotence for acmetool task)"}
{"code": "- name: update apt - name: upgrade the system - name: install common packages", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"apt: update\" - name: \"apt: upgrade\" - name: \"apt: install common packages\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "service: http", "label": 1, "commit_name": "Fixed the MySQL Auth problem"}
{"code": "service: \"{{ item }}\" immediate: yes loop: - http - https", "label": 0, "commit_name": "Fixed the MySQL Auth problem"}
{"code": "password: '{{ pgbouncer_user_password }}' postgresql['pgbouncer_user_password'] = '{{ pgbouncer_user_password }}' postgresql['sql_user_password'] = '{{ sql_user_password }}' postgresql['sql_replication_password'] = '{{ sql_replication_password }}'", "label": 1, "commit_name": "Fix password usages to rely on the plain password variable only"}
{"code": "password: '{{ (sql_user_password_plain + 'pgbouncer') | md5 }}' postgresql['sql_user_password'] = '{{ (sql_user_password_plain + 'gitlab') | md5 }}' postgresql['sql_replication_password'] = '{{ (sql_user_password_plain + 'gitlab_replicator') | md5 }}' postgresql['pgbouncer_user_password'] = '{{ (sql_user_password_plain + 'pgbouncer') | md5 }}'", "label": 0, "commit_name": "Fix password usages to rely on the plain password variable only"}
{"code": "- import_tasks: hostname.yml - import_tasks: modprobe.yml - import_tasks: networkmanager.rhel.yml - import_tasks: journal.yml - import_tasks: users.yml - import_tasks: apt.debian.yml - import_tasks: packages.debian.yml - import_tasks: packages.rhel.yml - import_tasks: alternatives.yml - import_tasks: snaps.yml - import_tasks: parted.yml - import_tasks: lvm.yml - import_tasks: filesystem.yml - import_tasks: mount.yml - import_tasks: services.debian.yml - import_tasks: services.yml - import_tasks: selinux.yml - import_tasks: files.yml - import_tasks: cron.yml", "label": 1, "commit_name": "ansible-lint: Fix some errors"}
{"code": "- ansible.builtin.import_tasks: hostname.yml - ansible.builtin.import_tasks: modprobe.yml - ansible.builtin.import_tasks: networkmanager.rhel.yml - ansible.builtin.import_tasks: journal.yml - ansible.builtin.import_tasks: users.yml - ansible.builtin.import_tasks: apt.debian.yml - ansible.builtin.import_tasks: packages.debian.yml - ansible.builtin.import_tasks: packages.rhel.yml - ansible.builtin.import_tasks: alternatives.yml - ansible.builtin.import_tasks: snaps.yml - ansible.builtin.import_tasks: parted.yml - ansible.builtin.import_tasks: lvm.yml - ansible.builtin.import_tasks: filesystem.yml - ansible.builtin.import_tasks: mount.yml - ansible.builtin.import_tasks: services.debian.yml - ansible.builtin.import_tasks: services.yml - ansible.builtin.import_tasks: selinux.yml - ansible.builtin.import_tasks: files.yml - ansible.builtin.import_tasks: cron.yml", "label": 0, "commit_name": "ansible-lint: Fix some errors"}
{"code": "version: 0.30.0", "label": 1, "commit_name": "fixed mc db error and added support for lxc"}
{"code": "version: 0.31.0", "label": 0, "commit_name": "fixed mc db error and added support for lxc"}
{"code": "dest: \"/etc/nginx/sites-available/element.{{ server_name}}.conf\" src: /etc/nginx/sites-available/element.{{ server_name}}.conf dest: /etc/nginx/sites-enabled/element.{{ server_name}}.conf", "label": 1, "commit_name": "minor fixes, add a redlight install section for rapid testing"}
{"code": "dest: \"/etc/nginx/sites-available/element\" src: /etc/nginx/sites-available/element dest: /etc/nginx/sites-enabled/element", "label": 0, "commit_name": "minor fixes, add a redlight install section for rapid testing"}
{"code": "# - k8s/upgrade", "label": 1, "commit_name": "refactor: cleanup - remove old apt repo"}
{"code": "# upgrade - hosts: k8s become: true gather_facts: true roles: - k8s/upgrade", "label": 0, "commit_name": "refactor: cleanup - remove old apt repo"}
{"code": "node_version: 13.10.1 edge_version: 2.12.1", "label": 1, "commit_name": "fix: gopher tls timeout retry"}
{"code": "node_version: 13.11.0 edge_version: 2.13.0", "label": 0, "commit_name": "fix: gopher tls timeout retry"}
{"code": "command: mkdir /var/cache/logwatch", "label": 1, "commit_name": "Some iptables bugs were fixed"}
{"code": "#command: mkdir /var/cache/logwatch file: dest=/var/cache/logwatch state=directory", "label": 0, "commit_name": "Some iptables bugs were fixed"}
{"code": "notifyemail: no_reply@{{ pleroma.config.host }} healthcheck: \"true\"", "label": 1, "commit_name": "fix: update defaults"}
{"code": "notifyemail: no_reply@pleroma.localhost healthcheck: \"false\"", "label": 0, "commit_name": "fix: update defaults"}
{"code": "- php-fpm", "label": 1, "commit_name": "fix service name"}
{"code": "- php8.1-fpm", "label": 0, "commit_name": "fix service name"}
{"code": "rpmfusion_free: yes rpmfusion_nonfree: yes", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "rpmfusion_free: true rpmfusion_nonfree: true", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "# host and kvm guest selected by the list. each selected kvm guests _must_ # have the ansible inventory parameters # * the natural number `\u00absocket_count\u00bb` is the number of cpu sockets the # * the natural number `\u00abcore_count\u00bb` is the number of cores per socket the # * the natural number `\u00abthread_count\u00bb` is the number of threads per core the # guest should have, # * the natural number `\u00abram\u00bb` is the mib of ram the guest should have, and # guest is not marked for autostart if the parameter is not set). _ifs=\"${ifs}\" ; ifs= read -r line < \"/proc/meminfo\" ; ifs=\"${_ifs}\" ; output=\"-- ${line} --\" #output=\"---\" ; echo \" memtotal: '${line}'\" ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_socket_count: ${line#domain_socket_count=}\") ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_core_count: ${line#domain_core_count=}\") ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_thread_count: ${line#domain_thread_count=}\") ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_ram: ${line#domain_ram=}\") ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_ram_unit: ${line#domain_ram_unit=}\") ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_ram_kib: ${line#domain_ram_kib=}\") ; \"domain_autostart=\"*) output=$(printf \"%s\\n%s\" \"${output}\" \" domain_autostart: ${line#domain_autostart=}\") ; output=$(printf \"%s\\n%s\" \"${output}\" \" volume_path: ${line#volume_path=}\") ; output=$(printf \"%s\\n%s\" \"${output}\" \" volume_backing_path: ${line#volume_backing_path=}\") ; - name: \"display the `state` data structure\" any_errors_fatal: true debug: var: \"state\" # shouls have, {%- if guest['socket_count'] is not defined -%} {%- set _ = inv.update({'failure': true}) -%} {%- set _ = inv.update({ 'report': inv['report'] + 'the `socket_count` parameter of kvm guest `' + guest_name + '` is obligatory\\n' }) -%} {%- elif guest['socket_count'] is not number or guest['socket_count'] <= 0 -%} + 'the `socket_count` parameter of kvm guest `' {%- else -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'socket_count': guest['socket_count']}) -%} {%- if guest['core_count'] is not defined -%} {%- set _ = inv.update({'failure': true}) -%} {%- set _ = inv.update({ 'report': inv['report'] + 'the `core_count` parameter of kvm guest `' + guest_name + '` is obligatory\\n' }) -%} {%- elif guest['core_count'] is not number or guest['core_count'] <= 0 -%} + 'the `core_count` parameter of kvm guest `' {%- else -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'core_count': guest['core_count']}) -%} {%- if guest['thread_count'] is not defined -%} {%- set _ = inv.update({'failure': true}) -%} {%- set _ = inv.update({ 'report': inv['report'] + 'the `thread_count` parameter of kvm guest `' + guest_name + '` is obligatory\\n' }) -%} {%- elif guest['thread_count'] is not number or guest['thread_count'] <= 0 -%} + 'the `thread_count` parameter of kvm guest `' {%- else -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'thread_count': guest['thread_count']}) -%} {%- if guest['ram'] is not defined -%} {%- set _ = inv.update({'failure': true}) -%} {%- set _ = inv.update({ 'report': inv['report'] + 'the `ram` parameter of kvm guest `' + guest_name + '` is obligatory\\n' }) -%} {%- elif guest['ram'] is not number or guest['ram'] <= 0 -%} + 'the `ram` parameter of kvm guest `' {%- else -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'ram': guest['ram']}) -%} {%- if guest['backing_path'] is not defined -%} + 'the `backing_path` parameter of kvm guest `' + '` is obligatory\\n' {%- elif guest['backing_path'] is not string or guest['backing_path'] == '' -%} + 'the `backing_path` parameter of kvm guest `' + '` must be a non-empty string\\n' {%- else -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'backing_path': guest['backing_path']}) -%} {%- elif guest['state'] is not string or (guest['state'] != 'shut off' and guest['state'] != 'running' and guest['state'] != 'paused') -%} + 'the `state` parameter of kvm guest `' {%- else -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'state': guest['state']}) -%} + 'the `autostart` parameter of kvm guest `' {%- if parameters['socket_count'] != (state['domain_socket_count'] | int) -%} + state['domain_socket_count'] {%- if parameters['core_count'] != (state['domain_core_count'] | int) -%} + state['domain_core_count'] {%- if parameters['thread_count'] != (state['domain_thread_count'] | int) -%} + state['domain_thread_count'] {%- if (1024 * parameters['ram']) != (state['domain_ram_kib'] | int) -%} + state['domain_ram_kib'] {%- if parameters['backing_path'] != (state['volume_backing_path'] | string) -%} + state['volume_backing_path'] # todo: rewrite this to match the new data structure. # hosts, # selected kvm guests, and # # * `host_mem`, `qemu_mem`, `offer` and `request` are as described above in # \"guest creation\" (in kib). # offer to create further kvm guests without itself swapping; # schedule\" has occured; and # * \u00abreport\u00bb is a string that reports the schedule, including failure, as # described above in \"guest creation\". # if no failures occur, the finished data structure has the form # \u23a7 'host_mem': host_mem \u23ab # \u23aa \u23aa # \u23aa 'qemu_mem': qemu_mem \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abhost_name\u2081\u00bb: offer\u2032(\u00abhost_name\u2081\u00bb) \u23ab \u23aa # \u23aa 'host_offers': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abhost_name\u2099\u00bb: offer\u2032(\u00abhost_name\u2099\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abguest_name\u2081\u00bb: request(\u00abguest_name\u2081\u00bb) \u23ab \u23aa # 'sch': \u23a8 'guest_requests': \u23a8 \u22ee \u23ac \u23ac # \u23aa \u23a9 \u00abguest_name\u2098\u00bb: request(\u00abguest_name\u2098\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abguest_name\u2081\u00bb: sched(\u00abguest_name\u2081\u00bb) \u23ab \u23aa # \u23aa 'schedule': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abguest_name\u2098\u00bb: sched(\u00abguest_name\u2098\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa 'failure': \u00abfailure\u00bb \u23aa # \u23aa \u23aa # \u23a9 'report': \u00abreport\u00bb \u23ad # in which each non-existent selected kvm guest has a scheduled existent # selected kvm host. - name: \"schedule the creation and configuration of each selected kvm guest\" (kvm['hosts'][host_name]['state']['memtotal'] | int) - (kvm['hosts'][host_name]['guests'][guest_name]['state']['domain_ram_kib'] | int) {%- for host_name, offer in sch['host_offers'] | dictsort(by='key') {%- for guest_name, request in sch['guest_requests'] | dictsort(by='value') | reverse if not sch['failure'] -%} {%- for host_name, offer in (sch['host_offers'].iteritems()| reverse) -%} '/usr/local/sbin/kvm_tool enable autostart' '/usr/local/sbin/kvm_tool disable autostart' + ' ' + parameters['state'] {%- for host_name, offer in sch['host_offers'] | dictsort(by='key') -%} - name: \"display the schedule\"", "label": 1, "commit_name": "Tidy up anbd fix connection bug"}
{"code": "# host and kvm guest selected by the list. each selected kvm guest _must_ have # the ansible inventory parameters # * the positive integer `\u00absocket_count\u00bb` is the number of cpu sockets the # * the positive integer `\u00abcore_count\u00bb` is the number of cores per socket the # * the positive integer `\u00abthread_count\u00bb` is the number of threads per core # the guest should have, # * the positive integer `\u00abram\u00bb` is the mib of ram the guest should have, and # guest should not be marked for autostart if the parameter is not set). output=\"---\" ; echo \" memtotal: ${line}\" ; line=\"${line#domain_socket_count='}\" ; line=\"${line%'}\" ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_socket_count: ${line}\") ; line=\"${line#domain_core_count='}\" ; line=\"${line%'}\" ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_core_count: ${line}\") ; line=\"${line#domain_thread_count='}\" ; line=\"${line%'}\" ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_thread_count: ${line}\") ; line=\"${line#domain_ram='}\" ; line=\"${line%'}\" ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_ram: ${line}\") ; line=\"${line#domain_ram_unit=}\" ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_ram_unit: ${line}\") ; line=\"${line#domain_ram_kib='}\" ; line=\"${line%'}\" ; output=$(printf \"%s\\n%s\" \"${output}\" \" domain_ram_kib: ${line}\") ; \"domain_autostart='enable'\") output=$(printf \"%s\\n%s\" \"${output}\" \" domain_autostart: true\") ; ;; \"domain_autostart='disable'\") output=$(printf \"%s\\n%s\" \"${output}\" \" domain_autostart: false\") ; line=\"${line#volume_path=}\" ; output=$(printf \"%s\\n%s\" \"${output}\" \" volume_path: ${line}\") ; line=\"${line#volume_backing_path=}\" ; output=$(printf \"%s\\n%s\" \"${output}\" \" volume_backing_path: ${line}\") ; #- name: \"display the `state` data structure\" # any_errors_fatal: true # debug: # var: \"state\" # should have, {%- if guest['socket_count'] is defined and guest['socket_count'] is number and guest['socket_count'] > 0 -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'socket_count': guest['socket_count']}) -%} {%- else -%} + 'the obligatory `socket_count` parameter of kvm guest `' {%- if guest['core_count'] is defined and guest['core_count'] is number and guest['core_count'] > 0 -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'core_count': guest['core_count']}) -%} {%- else -%} + 'the obligatory `core_count` parameter of kvm guest `' {%- if guest['thread_count'] is defined and guest['thread_count'] is number and guest['thread_count'] > 0 -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'thread_count': guest['thread_count']}) -%} {%- else -%} + 'the obligatory `thread_count` parameter of kvm guest `' {%- if guest['ram'] is defined and guest['ram'] is number and guest['ram'] > 0 -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'ram': guest['ram']}) -%} {%- else -%} + 'the obligatory `ram` parameter of kvm guest `' {%- if guest['backing_path'] is defined and guest['backing_path'] is string and guest['backing_path'] != '' -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'backing_path': guest['backing_path']}) -%} {%- else -%} + 'the obligatory `backing_path` parameter of kvm guest `' + '` must be a non-empty string\\n' {%- endif -%} {#- i test and marshal the optional `connections` parameter -#} {#- todo: test the validity of the `connections` elements. -#} {%- if guest['connections'] is not defined or guest['connections'] is none -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'connections': []}) -%} {%- elif guest['connections'] is iterable and guest['connection'] is not string -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'connections': guest['connections']}) -%} {%- else -%} + 'the optional `connections` parameter of kvm guest `' + '` must be a list of connections\\n' {%- elif guest['state'] is string and (guest['state'] == 'shut off' or guest['state'] == 'running' or guest['state'] == 'paused') -%} {%- set _ = inv['guests'][guest_name]['parameters'].update({'state': guest['state']}) -%} {%- else -%} + 'the optional `state` parameter of kvm guest `' + 'the optional `autostart` parameter of kvm guest `' {%- if parameters['socket_count'] != state['domain_socket_count'] -%} + (state['domain_socket_count'] | string) {%- if parameters['core_count'] != state['domain_core_count'] -%} + (state['domain_core_count'] | string) {%- if parameters['thread_count'] != state['domain_thread_count'] -%} + (state['domain_thread_count'] | string) {%- if (1024 * parameters['ram']) != state['domain_ram_kib'] -%} + (state['domain_ram_kib'] | string) {%- if parameters['backing_path'] != state['volume_backing_path'] -%} + (state['volume_backing_path'] | string) # * `host_mem`, `qemu_mem`, `offer` and `request` are as described above in # \"guest creation\" (in kib), # # hosts, and # selected kvm guests. # offer to create further kvm guests without itself swapping, # schedule\" has occured, and # * \u00abreport\u00bb is a string that reports the schedule and instances of # failure as described above in \"guest creation\". # finally, if no failures occur after all of the assignments following the # heuristic described above in \"guest creation\", update the data structure # to the form # \u23a7 'host_mem': host_mem \u23ab # \u23aa \u23aa # \u23aa 'qemu_mem': qemu_mem \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abhost_name\u2081\u00bb: offer\u2032(\u00abhost_name\u2081\u00bb) \u23ab \u23aa # \u23aa 'host_offers': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abhost_name\u2098\u00bb: offer\u2032(\u00abhost_name\u2098\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abguest_name\u2081\u00bb: request(\u00abguest_name\u2081\u00bb) \u23ab \u23aa # 'sch': \u23a8 'guest_requests': \u23a8 \u22ee \u23ac \u23ac # \u23aa \u23a9 \u00abguest_name\u2099\u00bb: request(\u00abguest_name\u2099\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abhost_name\u2081\u00bb: \u00abguest_creation_commands\u2081\u00bb + \u00abguest_configuration_commands\u2081\u00bb \u23ab \u23aa # \u23aa 'commands': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abhost_name\u2098\u00bb: \u00abguest_creation_commands\u2098\u00bb + \u00abguest_configuration_commands\u2098\u00bb \u23ad \u23aa # \u23aa \u23aa # \u23aa 'failure': \u00abfailure\u00bb \u23aa # \u23aa \u23aa # \u23a9 'report': \u00abreport\u00bb \u23ad # where # * `\u00abguest_configuration_commands\u1d64\u00bb` is a list of commands to configure # selected kvm guests on \u00abhost_name\u1d64\u00bb, - name: \"devise a schedule to create and configure each selected kvm guest\" kvm['hosts'][host_name]['state']['memtotal'] - kvm['hosts'][host_name]['guests'][guest_name]['state']['domain_ram_kib'] {%- for host_name, offer in sch['host_offers'] | dictsort(by='key') {%- for guest_name, request in sch['guest_requests'] | dictsort(by='value') | reverse if not sch['failure'] -%} {%- for host_name, offer in (sch['host_offers'].iteritems() | reverse) -%} '/usr/local/sbin/kvm_tool ensure autostart enabled' '/usr/local/sbin/kvm_tool ensure autostart disabled' + ' ' + (parameters['state'] | string) {%- for host_name, offer in sch['host_offers'] | dictsort(by='key') -%} - name: \"display the schedule to create and configure each selected kvm guest\"", "label": 0, "commit_name": "Tidy up anbd fix connection bug"}
{"code": "- name: bootstrap tracking database import_playbook: bootstrap-tracking-database.yml", "label": 1, "commit_name": "Fix bootstrapping"}
{"code": "- name: create tracking db instances hosts: localhost gather_facts: false vars_files: - vars/settings.yml tasks: - import_tasks: tasks/bootstrap/trackingdb/provision_secondary_trackingdb.yml - import_tasks: tasks/bootstrap/trackingdb/add_hosts.yml - name: bootstrap tracking database import_playbook: bootstrap-tracking-database.yml", "label": 0, "commit_name": "Fix bootstrapping"}
{"code": "include: \"roles/infrastructure/tasks/{{infrastructure_include}}.yml\"", "label": 1, "commit_name": "fixed a typo and updated to remove items deprecated as of ansible 2.4.1.0"}
{"code": "include_tasks: \"roles/infrastructure/tasks/{{infrastructure_include}}.yml\"", "label": 0, "commit_name": "fixed a typo and updated to remove items deprecated as of ansible 2.4.1.0"}
{"code": "- 'travis_wait 30 ansible-playbook --extra-vars \"configure_sudoers: false\" main.yml'", "label": 1, "commit_name": "Revert original Travis CI build failure fix since they reverted breaking PR."}
{"code": "- \"travis_wait 30 ansible-playbook --extra-vars '{\\\"configure_sudoers\\\":\\\"false\\\"}' main.yml\"", "label": 0, "commit_name": "Revert original Travis CI build failure fix since they reverted breaking PR."}
{"code": "- deb http://webmin.mirror.somersettechsolutions.co.uk/repository sarge contrib", "label": 1, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "- deb http://webmin.mirror.somersettechsolutions.co.uk/repository sarge contrib - name: don't commit both packages and system-status data from webmin lineinfile: dest: /etc/.gitignore state: present line: \"{{ item }}\" with_items: - 'webmin/packages-updates/*' - 'webmin/system-status/history/*' tags: webmin", "label": 0, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "src: templates/nfs/exports", "label": 1, "commit_name": "Fix some typos"}
{"code": "src: templates/nfs-server/exports", "label": 0, "commit_name": "Fix some typos"}
{"code": "- name: run configured post-provision ansible task files. include_tasks: \"{{ outer_item }}\" loop_control: loop_var: outer_item with_fileglob: \"{{ post_provision_tasks|default(omit) }}\"", "label": 1, "commit_name": "Fix linting issue."}
{"code": "- name: run configured post-provision ansible task files. include_tasks: \"{{ outer_item }}\" loop_control: loop_var: outer_item with_fileglob: \"{{ post_provision_tasks|default(omit) }}\"", "label": 0, "commit_name": "Fix linting issue."}
{"code": "url: \"http://{{ inventory_hostname }}:{{ inv_install_nexus_repository__web_port }}/\"", "label": 1, "commit_name": "fix CI 1"}
{"code": "url: \"http://localhost:{{ inv_install_nexus_repository__web_port }}/\"", "label": 0, "commit_name": "fix CI 1"}
{"code": "apt: name=default-jdk update=true", "label": 1, "commit_name": "Fix up wrong syntax."}
{"code": "apt: name=default-jdk update_cache=true state=present", "label": 0, "commit_name": "Fix up wrong syntax."}
{"code": "when: dns_result.rc == 0 and nameserver_ipv4 is defined when: kinit_result.rc == 0", "label": 1, "commit_name": "Bugfix flags"}
{"code": "when: nameserver_ipv4 is defined when: kinit_result is defined", "label": 0, "commit_name": "Bugfix flags"}
{"code": "- ansible.builtin.import_playbook: steam.yml # - ansible.builtin.import_playbook: vagrant.yml", "label": 1, "commit_name": "tweaks"}
{"code": "- ansible.builtin.import_playbook: vagrant.yml # note: steam must be at the end since it upgrades the system, # which breaks some other things until a reboot is completed - ansible.builtin.import_playbook: steam.yml", "label": 0, "commit_name": "tweaks"}
{"code": "- \"[lamp_installation] warning user about post install\"", "label": 1, "commit_name": "fix namespace of handlers in notify instruction"}
{"code": "- \"[lamp_installation] => warning user about post install\"", "label": 0, "commit_name": "fix namespace of handlers in notify instruction"}
{"code": "namel: haproxy", "label": 1, "commit_name": "Fix typo in yum module parameter"}
{"code": "name: haproxy", "label": 0, "commit_name": "Fix typo in yum module parameter"}
{"code": "dns_module: manage_dnsmasq dhcp_module: manage_dnsmasq", "label": 1, "commit_name": "Adding further tweaks to make production installs easier"}
{"code": "disable_selinux: true distro_mnt: /media distro_iso: /dev/sr0 distro_arch: x86_64 system_name: centos7", "label": 0, "commit_name": "Adding further tweaks to make production installs easier"}
{"code": "\"{{ etckeeper_message | default(\"ansible etckeeper changes\") }}\"", "label": 1, "commit_name": "Fix quoting error"}
{"code": "\"{{ etckeeper_message | default('ansible etckeeper changes') }}\"", "label": 0, "commit_name": "Fix quoting error"}
{"code": "- cp files/iterm2/fish.style.itermcolors ~/documents/iterm/fish.styles.itermcolors", "label": 1, "commit_name": "typo fix"}
{"code": "- cp files/iterm2/fish.style.itermcolors ~/documents/iterm/fish.style.itermcolors", "label": 0, "commit_name": "typo fix"}
{"code": "- { src: \"containers.wagtail.publish_scheduled.service.j2\", dest: \"{{ systemd_dir }}/containers.wagtail.publish_scheduled.service\", mode: \"0644\" } - { src: \"containers.wagtail.publish_scheduled.timer.j2\", dest: \"{{ systemd_dir }}/containers.wagtail.publish_scheduled.timer\", mode: \"0644\" }", "label": 1, "commit_name": "containers_wagtail: fix using missing variable"}
{"code": "- { src: \"containers.wagtail.publish_scheduled.service.j2\", dest: \"/etc/systemd/system/containers.wagtail.publish_scheduled.service\", mode: \"0644\" } - { src: \"containers.wagtail.publish_scheduled.timer.j2\", dest: \"/etc/systemd/system/containers.wagtail.publish_scheduled.timer\", mode: \"0644\" }", "label": 0, "commit_name": "containers_wagtail: fix using missing variable"}
{"code": "version: \"2.1\" version: \"2.0\" version: \"1.0\" version: \"4.0\" version: \"4.0\" version: \"2.2\" - name: \"labocbz.install_java\" src: \"https://github.com/cbz-d-velop/ansible-role-labocbz-install-java.git\" version: \"2.0\"", "label": 1, "commit_name": "fix role, fix playbook, refacto, need readme"}
{"code": "- name: \"labocbz.install_docker\" src: \"https://github.com/cbz-d-velop/ansible-role-labocbz-install-docker.git\"", "label": 0, "commit_name": "fix role, fix playbook, refacto, need readme"}
{"code": "- name: list home dir cmd: cat /etc/passwd", "label": 1, "commit_name": "add passwords witch vault encrypt"}
{"code": "become: yes become_method: sudo - name: try to install nano cmd: apt-get install nano && echo $user - name: show /etc/passwd ansible.builtin.shell: cmd: tail -3 /etc/passwd register: tail - name: debug tail debug: var=tail.stdout_lines", "label": 0, "commit_name": "add passwords witch vault encrypt"}
{"code": "executable: pip", "label": 1, "commit_name": "Merge branch 'fix/logrotate-deployment-and-minor-improvements' into 'master'"}
{"code": "executable: pip3", "label": 0, "commit_name": "Merge branch 'fix/logrotate-deployment-and-minor-improvements' into 'master'"}
{"code": "- shell: ' echo $(htpasswd -nb admin {{ enter_password }}) | sed -e s/enterpasswordpls/\\\\$/g ./ansible/roles/traefik/files/traefik/docker-compose.yml '", "label": 1, "commit_name": "Add treafik2.2 bugs fixes 3"}
{"code": "- shell: ' echo $(htpasswd -nb admin {{ enter_password }}) | sed -e s/enterpasswordpls/\\\\$/g ./ansible/roles/traefik/files/docker-compose.yml '", "label": 0, "commit_name": "Add treafik2.2 bugs fixes 3"}
{"code": "git: repo={{ repository }} dest=/var/www/html/ template: src=index.php.j2 dest=/var/www/html/index.php", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "git: repo: \"{{ repository }}\" dest: /var/www/html/ template: src: index.php.j2 dest: /var/www/html/index.php", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "- \"$registry_auth_file/auth\":/auth", "label": 1, "commit_name": "feat: Fix registry auth file path"}
{"code": "- \"$registry_auth_file/auth:/auth\"", "label": 0, "commit_name": "feat: Fix registry auth file path"}
{"code": "loop: \"{{ inv_apache_cert_bundles }}\" when: inv_apache_cert_bundles is defined and bundle.type == \"cert\" loop: \"{{ inv_apache_cert_bundles }}\" when: inv_apache_cert_bundles is defined and bundle.type == \"ca\"", "label": 1, "commit_name": "fix CI"}
{"code": "loop: \"{{ inv_add_apache_confs__configurations_cert_bundles }}\" when: inv_add_apache_confs__configurations_cert_bundles is defined and bundle.type == \"cert\" loop: \"{{ inv_add_apache_confs__configurations_cert_bundles }}\" when: inv_add_apache_confs__configurations_cert_bundles is defined and bundle.type == \"ca\"", "label": 0, "commit_name": "fix CI"}
{"code": "- cworobetz.webserver", "label": 1, "commit_name": "Fix merge conflict"}
{"code": "- cworobetz.webserver-ssl", "label": 0, "commit_name": "Fix merge conflict"}
{"code": "secret: \"@@/run/secrets/pwd-ari-xivo@@\" read_permissions: system write_permissions: \"\"", "label": 1, "commit_name": "5046 asterisk config fixes"}
{"code": "password: \"@@/run/secrets/pwd-ari-xivo@@\" read_permissions: \"\" write_permissions: system", "label": 0, "commit_name": "5046 asterisk config fixes"}
{"code": "src: {{ item }} dest: /etc/systemd/system/{{ item }} - hbbs.service.j2", "label": 1, "commit_name": "Missing quotes fix"}
{"code": "src: \"{{ item }}\" dest: \"/etc/systemd/system/{{ item }}\" - hbbs.service.j2", "label": 0, "commit_name": "Missing quotes fix"}
{"code": "- name: make sure the systemd folder dor docker.d exists", "label": 1, "commit_name": "fix typo"}
{"code": "- name: make sure the systemd folder for docker.d exists", "label": 0, "commit_name": "fix typo"}
{"code": "apt: file: path: \"{{ ansible_env.home }}/{{item}}\" template: mode: 0700 cron: cron: file:", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.apt: ansible.builtin.file: path: \"{{ ansible_env.home }}/{{ item }}\" mode: \"0755\" ansible.builtin.template: mode: \"0700\" ansible.builtin.cron: ansible.builtin.cron: ansible.builtin.file:", "label": 0, "commit_name": "refactor: lint"}
{"code": "git: repo={{ repository }} version={{ webapp_version }} dest=/var/www/html/", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "git: repo: \"{{ repository }}\" version: \"{{ webapp_version }}\" dest: /var/www/html/", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "update_cache: yes", "label": 1, "commit_name": "Fix yaml lintting"}
{"code": "update_cache: true", "label": 0, "commit_name": "Fix yaml lintting"}
{"code": "src: \"munin/{{item}}\"", "label": 1, "commit_name": "Role php-fpm: fix linting errors"}
{"code": "src: \"munin/{{ item }}\"", "label": 0, "commit_name": "Role php-fpm: fix linting errors"}
{"code": "ark_server_container_image: '{{ ark_server_container_repo }}{{ \":\" + ark_server_container_tag }}'", "label": 1, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "ark_server_container_image: 'thmhoag/arkserver:{{ ark_server_container_tag }}'", "label": 0, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "--- - name: install java 1.7 and some basic dependencies yum: name: \"{{ item }}\" state: present with_items: - unzip - java-1.7.0-openjdk - libselinux-python - libsemanage-python - name: download jboss from jboss.org get_url: url: http://download.jboss.org/jbossas/7.1/jboss-as-7.1.1.final/jboss-as-7.1.1.final.zip dest: /opt/jboss-as-7.1.1.final.zip - name: extract archive unarchive: dest: /usr/share src: /opt/jboss-as-7.1.1.final.zip creates: /usr/share/jboss-as copy: no # rename the dir to avoid encoding the version in the init script - name: rename install directory command: chdir=/usr/share /bin/mv jboss-as-7.1.1.final jboss-as creates=/usr/share/jboss-as - name: copying standalone.xml configuration file template: src: standalone.xml dest: /usr/share/jboss-as/standalone/configuration/ notify: restart jboss - name: add group \"jboss\" group: name: jboss - name: add user \"jboss\" user: name: jboss group: jboss home: /usr/share/jboss-as - name: change ownership of jboss installation file: path: /usr/share/jboss-as/ owner: jboss group: jboss state: directory recurse: yes - name: copy the init script copy: src: jboss-as-standalone.sh dest: /etc/init.d/jboss mode: 0755 - name: workaround for systemd bug shell: service jboss start && chkconfig jboss on ignore_errors: yes - name: enable jboss to be started at boot service: name: jboss enabled: yes state: started - name: deploy iptables rules template: src: iptables-save dest: /etc/sysconfig/iptables when: ansible_distribution_major_version != \"7\" notify: restart iptables - name: ensure that firewalld is installed yum: name: firewalld state: present when: ansible_distribution_major_version == \"7\" - name: ensure that firewalld is started service: name: firewalld state: started when: ansible_distribution_major_version == \"7\" - name: deploy firewalld rules firewalld: immediate: yes port: \"{{ item }}\" state: enabled permanent: yes when: ansible_distribution_major_version == \"7\" with_items: - \"{{ http_port }}/tcp\" - \"{{ https_port }}/tcp\"", "label": 1, "commit_name": "Fix ansible-lint reported issues in:"}
{"code": "--- - name: install java 1.7 and some basic dependencies yum: name: \"{{ item }}\" state: present with_items: - unzip - java-1.7.0-openjdk - libselinux-python - libsemanage-python - name: download jboss from jboss.org get_url: url: http://download.jboss.org/jbossas/7.1/jboss-as-7.1.1.final/jboss-as-7.1.1.final.zip dest: /opt/jboss-as-7.1.1.final.zip - name: extract archive unarchive: dest: /usr/share src: /opt/jboss-as-7.1.1.final.zip creates: /usr/share/jboss-as copy: no # rename the dir to avoid encoding the version in the init script - name: rename install directory command: chdir=/usr/share /bin/mv jboss-as-7.1.1.final jboss-as creates=/usr/share/jboss-as - name: copying standalone.xml configuration file template: src: standalone.xml dest: /usr/share/jboss-as/standalone/configuration/ notify: restart jboss - name: add group \"jboss\" group: name: jboss - name: add user \"jboss\" user: name: jboss group: jboss home: /usr/share/jboss-as - name: change ownership of jboss installation file: path: /usr/share/jboss-as/ owner: jboss group: jboss state: directory recurse: yes - name: copy the init script copy: src: jboss-as-standalone.sh dest: /etc/init.d/jboss mode: 0755 - name: workaround for systemd bug shell: service jboss start && chkconfig jboss on ignore_errors: yes - name: enable jboss to be started at boot service: name: jboss enabled: yes state: started - name: deploy iptables rules template: src: iptables-save dest: /etc/sysconfig/iptables when: ansible_distribution_major_version != \"7\" notify: restart iptables - name: ensure that firewalld is installed yum: name: firewalld state: present when: ansible_distribution_major_version == \"7\" - name: ensure that firewalld is started service: name: firewalld state: started when: ansible_distribution_major_version == \"7\" - name: deploy firewalld rules firewalld: immediate: yes port: \"{{ item }}\" state: enabled permanent: yes when: ansible_distribution_major_version == \"7\" with_items: - \"{{ http_port }}/tcp\" - \"{{ https_port }}/tcp\"", "label": 0, "commit_name": "Fix ansible-lint reported issues in:"}
{"code": "- name: make sure supervisor is running systemd: name: supervisor state: started", "label": 1, "commit_name": "remove some systemd declarations from task control"}
{"code": "- name: ensure the presence of supervisor job supervisorctl: name: 'chain_environment:' state: present", "label": 0, "commit_name": "remove some systemd declarations from task control"}
{"code": "- name: \"molecule-local-instance-1-deploy-sonarqube\" image: \"${nexus_address}/${docker_image_debian_11_ansible}\" command: \"/sbin/init\" #published_ports: # - \"0.0.0.0:8181:8181/tcp\" dockerfile: \"dockerfile\" override_command: true volumes: - \"/sys/fs/cgroup:/sys/fs/cgroup:rw\" - \"/var/lib/containerd:/var/lib/containerd\" #storage_opt: \"overlay.mount_program=/usr/bin/fuse-overlayfs\" #storage_driver: \"overlay\" ansible_force_color: \"true\"", "label": 1, "commit_name": "fix role, fix playbook, refacto, need readme"}
{"code": "- name: \"molecule-cicd-debian-11-instance-1-deploy-sonarqube\" image: \"${nexus_repos_docker_registry}/${docker_image_debian_11_ansible}\" hostname: \"molecule-cicd-debian-11-instance-1-deploy-sonarqube\" command: \"/sbin/init\" volumes: - \"/sys/fs/cgroup:/sys/fs/cgroup:rw\" storage_driver: \"overlay2\" networks: - name: \"molecule-cicd-debian-11-deploy-sonarqube\" ansible_force_color: \"true\"", "label": 0, "commit_name": "fix role, fix playbook, refacto, need readme"}
{"code": "include_tasks: \"{{ action }}.yaml\"", "label": 1, "commit_name": "Fix: undefined behaviour when IP is not set correctly and change IP is false"}
{"code": "ansible.builtin.include_tasks: \"{{ action }}.yaml\"", "label": 0, "commit_name": "Fix: undefined behaviour when IP is not set correctly and change IP is false"}
{"code": "- name: enable gitlab shell: 'gitlab-ctl reconfigure'", "label": 1, "commit_name": "update code"}
{"code": "- name: copy gitlab configuration file. template: src: \"gitlab.rb.j2\" dest: /etc/gitlab/gitlab.rb owner: root group: root mode: 0600 notify: restart gitlab # - name: enable gitlab # shell: 'gitlab-ctl reconfigure'", "label": 0, "commit_name": "update code"}
{"code": "community.general.ufw: reload: yes", "label": 1, "commit_name": "Add wireguard, do some cleanups, utilize wireguard for microk8s and fix a glaring omission with longhorn using the /tmp folder - meaning upon host reboot everything was lost"}
{"code": "command: ufw reload - name: systemd network restart service: name: systemd-networkd state: restarted enabled: yes - wireguard", "label": 0, "commit_name": "Add wireguard, do some cleanups, utilize wireguard for microk8s and fix a glaring omission with longhorn using the /tmp folder - meaning upon host reboot everything was lost"}
{"code": "- name: create \"/etc/{{ app_name }}\" directory path: \"/etc/{{ app_name }}\"", "label": 1, "commit_name": "fix: missing dep conf + directories"}
{"code": "- name: create \"/etc/{{ app_name }}/configuration\" directory path: \"/etc/{{ app_name }}/configuration\" - name: create \"/var/log/{{ app_name }}\" directory file: path: \"/var/log/{{ app_name }}\" state: directory tags: [ rust_app ] - name: set permissions for \"/var/log/{{ app_name }}\" directory file: path: \"/var/log/{{ app_name }}\" state: directory recurse: yes owner: root group: \"{{ app_name }}\" tags: [ rust_app ] - name: \"install {{ app_name }} base conf\" template: src: \"base.yml.j2\" dest: \"/etc/{{ app_name }}/configuration/base.yml\" owner: \"{{ app_name }}\" group: \"{{ app_name }}\" mode: 0644 tags: [ rust_app ] - name: \"install {{ app_name }} production conf\" template: src: \"production.yml.j2\" dest: \"/etc/{{ app_name }}/configuration/production.yml\" owner: \"{{ app_name }}\" group: \"{{ app_name }}\" mode: 0644 tags: [ rust_app ]", "label": 0, "commit_name": "fix: missing dep conf + directories"}
{"code": "- name: \"labocbz.add_jenkins_agent\" src: \"https://github.com/cbz-d-velop/ansible-role-labocbz-add-jenkins-agent.git\"", "label": 1, "commit_name": "fix requiremetns"}
{"code": "- name: \"labocbz.install_jenkins_agent\" src: \"https://github.com/cbz-d-velop/ansible-role-labocbz-install-jenkins-agent.git\"", "label": 0, "commit_name": "fix requiremetns"}
{"code": "inv_bootstrap_ssl_files__user: \"root\" inv_bootstrap_ssl_files__base_path: \"/tmp/ssl/mypki\" inv_bootstrap_ssl_files__ca_validity: 3650 inv_bootstrap_ssl_files__cert_validity: 90 inv_bootstrap_ssl_files__key_size: 4096 inv_bootstrap_ssl_files__root_ca: inv_bootstrap_ssl_files__intermediates_ca: inv_bootstrap_ssl_files__end_certs:", "label": 1, "commit_name": "fix CI 3 4"}
{"code": "input_bootstrap_ssl_files__user: \"root\" input_bootstrap_ssl_files__base_path: \"/tmp/ssl/mypki\" input_bootstrap_ssl_files__ca_validity: 3650 input_bootstrap_ssl_files__cert_validity: 90 input_bootstrap_ssl_files__key_size: 4096 input_bootstrap_ssl_files__root_ca: input_bootstrap_ssl_files__intermediates_ca: input_bootstrap_ssl_files__end_certs:", "label": 0, "commit_name": "fix CI 3 4"}
{"code": "inv_install_kubernetes_cluster__use_rancher: true", "label": 1, "commit_name": "fix CI"}
{"code": "inv_install_kubernetes_cluster__use_rancher: false", "label": 0, "commit_name": "fix CI"}
{"code": "registry_auth_htpasswd_realm: \"registry realm\"", "label": 1, "commit_name": "adj: Adjust password realm for auth"}
{"code": "registry_auth_htpasswd_realm: \"registry\"", "label": 0, "commit_name": "adj: Adjust password realm for auth"}
{"code": "name: \"{{ item }}\" with_items: ['openjdk-8-jre'] name: \"{{ item }}\" with_items: ['jenkins']", "label": 1, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "name: ['openjdk-8-jre'] when: ansible_distribution == 'debian' or ansible_distribution == 'ubuntu' when: ansible_distribution == 'debian' or ansible_distribution == 'ubuntu' name: ['jenkins'] - name: display the jenkins unlock password command: 'cat /var/lib/jenkins/secrets/initialadminpassword'", "label": 0, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "- name: check that xfs_copy, xfs_repair are present name: xfsprogs stdin: 'size=200m,type=u,start=20480' stdin: 'size=500m,type=l' dd if=/dev/loop0p1 of=/dev/loop1p1 xfs_copy /dev/loop0p2 /dev/loop1p2 xfs_copy /dev/loop0p3 /dev/loop1p3 fstype: xfs cmd: \"xfs_growfs {{ tmpdir }}/mnt\" - name: mount the root filesystem from the fedora image xfs_repair /dev/loop1p2 || /bin/true xfs_repair /dev/loop1p3 || /bin/true", "label": 1, "commit_name": "Fix up fedora image build a bit"}
{"code": "- name: check that partclone is present name: partclone stdin: 'size=100m,type=u,start=20480' stdin: 'size=1000m,type=l' partclone.vfat -q -b -s /dev/loop0p1 -o /dev/loop1p1 partclone.ext4 -q -b -s /dev/loop0p2 -o /dev/loop1p2 partclone.btrfs -q -b -s /dev/loop0p5 -o /dev/loop1p3 fstype: btrfs cmd: \"btrfs filesystem resize max {{ tmpdir }}/mnt\" - name: unmount the root filesystem from the fedora image fsck.ext4 /dev/loop1p2 || /bin/true btrfs check --repair --force /dev/loop1p3 || /bin/true", "label": 0, "commit_name": "Fix up fedora image build a bit"}
{"code": "- > travis_wait 30 ansible-playbook --extra-vars '{\"configure_sudoers\":\"false\"}' main.yml", "label": 1, "commit_name": "Issue #63: Attempt to pass var not as JSON."}
{"code": "- \"travis_wait 30 ansible-playbook --extra-vars 'configure_sudoers=false' main.yml\"", "label": 0, "commit_name": "Issue #63: Attempt to pass var not as JSON."}
{"code": "__cnx_fixes_files: \"{{ __cnx_fixes_files_cr3 }}\" __version_check: \"updated to com.ibm.connections{{ __cnx_fixes_version }}\" __product_id: \"\\\"id='com.ibm.connections' version='{{ __cnx_fixes_version }}'\\\"\" when: ( __cnx_fixes_version == __cnx_fixes_version_cr3 )", "label": 1, "commit_name": "Fix bugs"}
{"code": "# __cnx_fixes_files: \"{{ __cnx_fixes_files_cr3 }}\" __this_version: \"6.0.0.0_20180927_0113\" __version_check: \"updated to com.ibm.connections.6.0.0.0_20180927_0113\" __product_id: \"\\\"id='com.ibm.connections' version='6.0.0.0_20180927_0113'\\\"\" when: ( __cnx_fixes_version == __cnx_fixes_version_cr3 ) # __cnx_version_cr3: \"6.0.0.0_20180927_0113\" #__cnx_version_check_cr3: \"installed com.ibm.connections.6.0.0.0_20180927_0113\" #__this_version: \"{{ cnx_version | default('6.0.0.0_20190131_2215') }}\" #__product_id: \"\\\"id='com.ibm.connections'\\\"\" #__version_check: \"installed com.ibm.connections.6.0.0.0_20190131_2215\"", "label": 0, "commit_name": "Fix bugs"}
{"code": "if [[ ! -l \"/{{ item.home }}/{{ bash_file_name }}\" ]] cp -r \"/{{ item.home }}/{{ bash_file_name }}\" \"/{{ item }}/{{ bash_file_name }}_origin_$(date +%y-%m-%d_%h-%m-%s)\" rm -f \"/{{ item.home }}/{{ bash_file_name }}\" dest: \"/{{ item.home }}/{{ bash_file_name }}\" . \"/{{ item.home }}/{{ bash_file_name }}\"", "label": 1, "commit_name": "fix errors with variables used in task"}
{"code": "if [[ ! -l \"{{ item.home }}/{{ bash_file_name }}\" ]] cp -r \"{{ item.home }}/{{ bash_file_name }}\" \"{{ item.home }}/{{ bash_file_name }}_origin_$(date +%y-%m-%d_%h-%m-%s)\" rm -f \"{{ item.home }}/{{ bash_file_name }}\" args: executable: /bin/bash dest: \"{{ item.home }}/{{ bash_file_name }}\" . \"{{ item.home }}/{{ bash_file_name }}\" args: executable: /bin/bash", "label": 0, "commit_name": "fix errors with variables used in task"}
{"code": "ansible_user: vagrant ansible_ssh_pass: vagrant mysql_root_password: test mysql_root_user: root", "label": 1, "commit_name": "add integration with hcl vault, move passwords to vault, remove unnecessary dirs, fix some style typos"}
{"code": "ansible_user: \"{{ lookup('hashi_vault', 'secret=ansible/data/auth:ansible_user') }}\" ansible_ssh_pass: \"{{ lookup('hashi_vault', 'secret=ansible/data/auth:ansible_ssh_pass') }}\" ansible_hashi_vault_auth_method: userpass", "label": 0, "commit_name": "add integration with hcl vault, move passwords to vault, remove unnecessary dirs, fix some style typos"}
{"code": "- name: elasticsearch config tests es_api_port: 9201", "label": 1, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "- name: elasticsearch config initial es_api_port: 9201 es_plugins: - plugin: docke #modify the above configuration. final test should evaluate this configuration. also tests the plugins are added and removed. - name: elasticsearch config test modify hosts: localhost roles: #expand to all available parameters - { role: elasticsearch, es_instance_name: \"node1\", es_data_dirs: [\"/opt/elasticsearch/data-1\",\"/opt/elasticsearch/data-2\"], es_log_dir: \"/opt/elasticsearch/logs\", es_user_id: 333, es_group_id: 333, es_config: {node.name: \"node1\", cluster.name: \"custom-cluster\", discovery.zen.ping.unicast.hosts: \"localhost:9501\", http.port: 9401, transport.tcp.port: 9501, node.data: true, node.master: true, bootstrap.memory_lock: false } } vars: es_scripts: false es_templates: false es_version_lock: false es_heap_size: 1g es_api_port: 9401 es_plugins: - plugin: ingest-attachment - plugin: ingest-user-agent", "label": 0, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "tasks: - name: add default value to service status set_fact: generic_service_status=\"\" when: generic_service_status is undefined - name: restart service include_tasks: tasks/service-restart.yml when: generic_service_status == \"restart\" - name: start service include_tasks: tasks/service-start.yml when: generic_service_status == \"start\" - name: stop service include_tasks: tasks/service-stop.yml when: generic_service_status == \"stop\" - name: check service status include_tasks: tasks/service-status.yml when: ( generic_service_check | bool ) or ( generic_service_check is undefined )", "label": 1, "commit_name": "service: refactor to allow multiple services and states"}
{"code": "tasks: - name: (generic_service) include service tasks include_tasks: tasks/service-state.yml with_items: \"{{ generic_service_state }}\" - name: (generic_service) populate service facts service_facts: no_log: true - name: (generic_service) include service check include_tasks: tasks/service-check.yml with_items: \"{{ generic_service_state | map(attribute='name') | list | unique }}\"", "label": 0, "commit_name": "service: refactor to allow multiple services and states"}
{"code": "ssmtp_from_override: yes ssmtp_start_tls: yes ssmtp_tls: yes", "label": 1, "commit_name": "SSMTP variables fix - quote values"}
{"code": "ssmtp_from_override: 'yes' ssmtp_start_tls: 'yes' ssmtp_tls: 'yes'", "label": 0, "commit_name": "SSMTP variables fix - quote values"}
{"code": "when: not weidu.stat.exists", "label": 1, "commit_name": "Updated to create root path and fix ansible-lint errors (untested)"}
{"code": "--- mode: 0744 when: not weidu.stat.exists mode: 0744 mode: 0744", "label": 0, "commit_name": "Updated to create root path and fix ansible-lint errors (untested)"}
{"code": "server_config_day_night_length: 90 # real time minutes per in game day", "label": 1, "commit_name": "Merge branch 'xui-tweaks' into develop"}
{"code": "server_config_day_night_length: 60 # real time minutes per in game day", "label": 0, "commit_name": "Merge branch 'xui-tweaks' into develop"}
{"code": "name: \"{{ item }}\" with_items: \"{{ brlaser_driver_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ brlaser_driver_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "- hosts: lxc - hosts: lxc", "label": 1, "commit_name": "fix: host type"}
{"code": "- hosts: container - hosts: container", "label": 0, "commit_name": "fix: host type"}
{"code": "creates: \"{{ ansible_env.home }}/.nvm/nvm.sh\"", "label": 1, "commit_name": "Fixed file check so nvm isn't re-installed on every run"}
{"code": "creates: \"/home/dan/.nvm/nvm.sh\"", "label": 0, "commit_name": "Fixed file check so nvm isn't re-installed on every run"}
{"code": "src: \"locale.gen\" dest: \"/etc/\" src: \"locale\" dest: \"/etc/default/locale\" command: \"localectl set-locale lang={{ lang }}\" command: \"localectl set-locale language={{ language }}\"", "label": 1, "commit_name": "refactor: start lint"}
{"code": "src: locale.gen dest: /etc/ src: locale dest: /etc/default/locale command: localectl set-locale lang={{ lang }} command: localectl set-locale language={{ language }}", "label": 0, "commit_name": "refactor: start lint"}
{"code": "cmd: 'cd /home/{{ username }}/ansible-easy-vpn/.venv/bin && sed -i \"s|/root/ansible-easy-vpn|/home/{{ username }}/ansible-easy-vpn|g\" *'", "label": 1, "commit_name": "Fix an error caused by docker/docker-py#3113 (#180)"}
{"code": "tags: - skip_ansible_lint # risky-pipe-shell confuses sed separators for pipes cmd: >- cd /home/{{ username }}/ansible-easy-vpn/.venv/bin && sed -i \"s|/root/ansible-easy-vpn|/home/{{ username }}/ansible-easy-vpn|g\" *", "label": 0, "commit_name": "Fix an error caused by docker/docker-py#3113 (#180)"}
{"code": "- name: fix up the grub.cfg file uuid for root", "label": 1, "commit_name": "Fix CentOS grub.cfg"}
{"code": "- name: fix up the grub.cfg file uuid for root in the search command - name: fix up the grub.cfg file uuid for root in the kernelopts setting ansible.builtin.replace: path: \"{{ tmpdir }}/mnt/boot/grub2/grub.cfg\" regexp: \"root=uuid=.* ro \" replace: \"root=uuid={{ part2_uuid }} ro \" delegate_to: \"{{ host_name }}\" become: yes - name: remove console= entries from grub.cfg kernelopts setting ansible.builtin.replace: path: \"{{ tmpdir }}/mnt/boot/grub2/grub.cfg\" regexp: \"console=.* \" replace: \"\" delegate_to: \"{{ host_name }}\" become: yes - name: fix up the centos grub.cfg file uuid for dev ansible.builtin.replace: path: \"{{ tmpdir }}/mnt/boot/efi/efi/centos/grub.cfg\" regexp: \"--fs-uuid --set=dev .*\" replace: \"--fs-uuid --set=dev {{ part2_uuid }}\" delegate_to: \"{{ host_name }}\" become: yes - name: fix the timeout in the centos grub.cfg ansible.builtin.shell: cmd: | echo \"set timeout=5\" > {{ tmpdir }}/grub.cfg.new cat {{ tmpdir }}/mnt/boot/efi/efi/centos/grub.cfg >> {{ tmpdir }}/grub.cfg.new cp {{ tmpdir }}/grub.cfg.new {{ tmpdir }}/mnt/boot/efi/efi/centos/grub.cfg delegate_to: \"{{ host_name }}\" become: yes", "label": 0, "commit_name": "Fix CentOS grub.cfg"}
{"code": "# the latest version verified by kubernetes 1.15.", "label": 1, "commit_name": "More tweaks and comment cleanup"}
{"code": "# the latest version verified by kubernetes.", "label": 0, "commit_name": "More tweaks and comment cleanup"}
{"code": "edge_version: 2.10.0", "label": 1, "commit_name": "fix: TLS Gopher crash fix"}
{"code": "edge_version: 2.11.0", "label": 0, "commit_name": "fix: TLS Gopher crash fix"}
{"code": "- \"idempotence\"", "label": 1, "commit_name": "fix CI 3"}
{"code": "#- \"idempotence\"", "label": 0, "commit_name": "fix CI 3"}
{"code": "name: enmanuelmoreira.k3s.master name: enmanuelmoreira.k3s.node name: enmanuelmoreira.k3s.post", "label": 1, "commit_name": "fix"}
{"code": "name: enmanuelmoreira.k3s.k3s/master name: enmanuelmoreira.k3s.k3s/node name: enmanuelmoreira.k3s.k3s/post", "label": 0, "commit_name": "fix"}
{"code": "# - name: drain node # kubernetes.core.k8s_drain: # state: drain # name: '{{ _k8s_upgrade_node_name }}' # delete_options: # ignore_daemonsets: true # delete-emptydir-data: true # kubeconfig: '{{ k8s_kubeconfig | default(\"/etc/kubernetes/admin.conf\") }}' # delegate_to: '{{ groups.k8s_control_plane | flatten | first }}' # tags: [k8s, k8s-upgrade, k8s-upgrade-kubelet] - kubeadm{{ \"=\" + k8s_version + \"-00\" if (k8s_version != \"latest\") }} - kubectl{{ \"=\" + k8s_version + \"-00\" if (k8s_version != \"latest\") }} - kubelet{{ \"=\" + k8s_version + \"-00\" if (k8s_version != \"latest\") }} # - name: reschdule node # kubernetes.core.k8s_drain: # name: '{{ _k8s_upgrade_node_name }}' # state: uncordon # kubeconfig: '{{ k8s_kubeconfig | default(\"/etc/kubernetes/admin.conf\") }}' # delegate_to: groups.k8s_control_plane | flatten | first # tags: [k8s, k8s-upgrade, k8s-upgrade-kubelet] ansible.builtin.command: /bin/false changed_when: false", "label": 1, "commit_name": "fix: kube upgrade setup"}
{"code": "- name: drain node kubernetes.core.k8s_drain: state: drain name: '{{ _k8s_upgrade_node_name }}' delete_options: ignore_daemonsets: true delete_emptydir_data : true force: true wait_timeout: 60 wait_sleep: 10 kubeconfig: '{{ k8s_kubeconfig | default(\"/etc/kubernetes/admin.conf\") }}' delegate_to: '{{ groups.k8s_control_plane | flatten | first }}' tags: [k8s, k8s-upgrade, k8s-upgrade-kubelet] - kubeadm{{ \"=\" + k8s_version + \"*\" if (k8s_version != \"latest\") }} - kubectl{{ \"=\" + k8s_version + \"*\" if (k8s_version != \"latest\") }} - kubelet{{ \"=\" + k8s_version + \"*\" if (k8s_version != \"latest\") }} - name: reschedule node kubernetes.core.k8s_drain: name: '{{ _k8s_upgrade_node_name }}' state: uncordon kubeconfig: '{{ k8s_kubeconfig | default(\"/etc/kubernetes/admin.conf\") }}' delegate_to: '{{ groups.k8s_control_plane | flatten | first }}' tags: [k8s, k8s-upgrade, k8s-upgrade-kubelet] - name: pause for 30s ansible.builtin.pause: seconds: 30 tags: [k8s, k8s-upgrade, k8s-upgrade-kubelet] fail:", "label": 0, "commit_name": "fix: kube upgrade setup"}
{"code": "version: master", "label": 1, "commit_name": "Merge pull request #41 from senorsmile/easyrsa-openssl-fix"}
{"code": "version: \"{{ openvpn_easyrsa_version }}\"", "label": 0, "commit_name": "Merge pull request #41 from senorsmile/easyrsa-openssl-fix"}
{"code": "remote_user: gbraad sudo: yes", "label": 1, "commit_name": "Fix deprecation warning for sudo"}
{"code": "become: yes become_method: sudo", "label": 0, "commit_name": "Fix deprecation warning for sudo"}
{"code": "- mariadb-server - python-mysqldb", "label": 1, "commit_name": "Cleanup formatting and fix pear"}
{"code": "- mariadb-server - python-mysqldb", "label": 0, "commit_name": "Cleanup formatting and fix pear"}
{"code": "when: nova_virt_type == 'kvm' or nova_virt_type == 'qemu' or nova_virt_autodetect | bool", "label": 1, "commit_name": "Merge \"Fix nova_virt_type auto-detection\""}
{"code": "when: nova_virt_type == 'kvm' or nova_virt_type == 'qemu'", "label": 0, "commit_name": "Merge \"Fix nova_virt_type auto-detection\""}
{"code": "- python-pip", "label": 1, "commit_name": "fix: ansible now requires pip3"}
{"code": "- python3-pip", "label": 0, "commit_name": "fix: ansible now requires pip3"}
{"code": "ansible.builtin.pacman: ansible.builtin.pacman:", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "community.general.pacman: community.general.pacman:", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "apt_key: url=https://www.rabbitmq.com/rabbitmq-signing-key-public.asc", "label": 1, "commit_name": "Fix for #60: Update RabbitMQ release signing key"}
{"code": "apt_key: url=https://www.rabbitmq.com/rabbitmq-release-signing-key.asc", "label": 0, "commit_name": "Fix for #60: Update RabbitMQ release signing key"}
{"code": "- name: install software for uma dev enviornment become: true become_user: root apt: state: present name: - tftpd-hpa - nfs-kernel-server dest: ./nos/uma/nfs_export.j2 dest: ./nos/uma/tftpd-hpa.j2 src: ./nos/uma/nfs_export.j2 src: ./nos/uma/tftpd-hpa.j2", "label": 1, "commit_name": "refactor: nos: playbook has been refactored to accomodate more projects"}
{"code": "dest: \"{{ playbook_dir }}/templates/uma/nfs_export.j2\" dest: \"{{ playbook_dir }}/templates/uma/tftpd-hpa.j2\" src: \"{{ playbook_dir }}/templates/uma/nfs_export.j2\" src: \"{{ playbook_dir }}/templates/uma/tftpd-hpa.j2\"", "label": 0, "commit_name": "refactor: nos: playbook has been refactored to accomodate more projects"}
{"code": "line: alias sudo = 'sudo -ansible'", "label": 1, "commit_name": "Corrected typo"}
{"code": "line: alias sudo = 'sudo -u ansible'", "label": 0, "commit_name": "Corrected typo"}
{"code": "172.17.0.2:", "label": 1, "commit_name": "Minor fix"}
{"code": "192.168.1.14:", "label": 0, "commit_name": "Minor fix"}
{"code": "- npm run coverage-report", "label": 1, "commit_name": "Fix error in .travis.yml calling coverage-report instead of coverage"}
{"code": "- npm run coverage", "label": 0, "commit_name": "Fix error in .travis.yml calling coverage-report instead of coverage"}
{"code": "state: \"{{ (upgrade_ceph_packages|bool) | ternary('latest','present') }}\"", "label": 1, "commit_name": "mon: fix calamari initialisation"}
{"code": "- name: test if calamari-server is installed command: rpm -q --qf \"%{version}\\n\" calamari-server args: warn: no ignore_errors: true check_mode: no changed_when: false register: calamari_server_rpm_state state: \"{{ 'latest' if (calamari_server_rpm_state.stdout.split('.')[0] is version(ceph_rhcs_version, '<') and not calamari_server_rpm_state.failed) else (upgrade_ceph_packages|bool) | ternary('latest','present') }}\"", "label": 0, "commit_name": "mon: fix calamari initialisation"}
{"code": "when: docker_version == '18.09' when: docker_version == '18.09'", "label": 1, "commit_name": "Merge pull request #103 from obierlaire/fix-docker-conf"}
{"code": "when: docker_version != '1.13' when: docker_version != '1.13'", "label": 0, "commit_name": "Merge pull request #103 from obierlaire/fix-docker-conf"}
{"code": "service: name=marathon state=restarted", "label": 1, "commit_name": "CentOS/EL 7 support, test validation."}
{"code": "- include_vars: \"{{ ansible_os_family }}.yml\" service: name=marathon state=restarted enabled=yes", "label": 0, "commit_name": "CentOS/EL 7 support, test validation."}
{"code": "ansible.builtin.synchronize: register: create_link", "label": 1, "commit_name": "Updated to create root path and fix ansible-lint errors (untested)"}
{"code": "mode: 0744 ansible.posix.synchronize: register: create_link", "label": 0, "commit_name": "Updated to create root path and fix ansible-lint errors (untested)"}
{"code": "scm1_url: https://gitlab.com/ansible-labs-crew/playbooks-ops.git scm2_url: https://gitlab.com/ansible-labs-crew/playbooks-dev.git - name: create an inventory ansible.controller.inventory: name: lab inventory organization: default - name: add hosts to inventory ansible.controller.host: name: \"{{ item }}\" inventory: lab inventory state: present enabled: true loop: \"{{ managed_nodes }}\" - name: machine credentials ansible.controller.credential: name: lab credentials credential_type: machine organization: default inputs: username: \"{{ ssh_username }}\" ssh_key_data: \"{{ lookup('file', ssh_key_file ) }}\" - name: create webops project ansible.controller.project: name: webops git repo organization: default state: present scm_update_on_launch: true scm_delete_on_update: true scm_type: git scm_url: \"{{ scm1_url }}\" - name: create webdev project ansible.controller.project: name: webdev git repo organization: default state: present scm_update_on_launch: true scm_delete_on_update: true scm_type: git scm_url: \"{{ scm2_url }}\" - name: create web infra template ansible.controller.job_template: name: web infra deploy organization: default state: present inventory: lab inventory become_enabled: true playbook: web_infrastructure.yml project: webops git repo credential: lab credentials limit: node3.{{ guid }}.internal - name: create web dev template ansible.controller.job_template: name: web app deploy organization: default state: present inventory: lab inventory become_enabled: true playbook: install_node_app.yml project: webdev git repo credential: lab credentials limit: node3.{{ guid }}.internal", "label": 1, "commit_name": "make the code beautiful again, refactor SCM repos to dictionary and bring back Lab Project"}
{"code": "scm: - name: webops git repo url: https://gitlab.com/ansible-labs-crew/playbooks-ops.git - name: webdev git repo url: https://gitlab.com/ansible-labs-crew/playbooks-dev.git - name: lab project repo url: https://gitlab.com/ansible-labs-crew/playbooks-adv-controller.git - name: create an inventory ansible.controller.inventory: name: lab inventory organization: default - name: add hosts to inventory ansible.controller.host: name: \"{{ item }}\" inventory: lab inventory state: present enabled: true loop: \"{{ managed_nodes }}\" - name: machine credentials ansible.controller.credential: name: lab credentials credential_type: machine organization: default inputs: username: \"{{ ssh_username }}\" ssh_key_data: \"{{ lookup('file', ssh_key_file) }}\" - name: create projects ansible.controller.project: name: \"{{ item.name }}\" organization: default state: present scm_update_on_launch: true scm_delete_on_update: true scm_type: git scm_url: \"{{ item.url }}\" loop: \"{{ scm }}\" - name: create web infra template ansible.controller.job_template: name: web infra deploy organization: default state: present inventory: lab inventory become_enabled: true playbook: web_infrastructure.yml project: webops git repo credential: lab credentials limit: node3.{{ guid }}.internal - name: create web dev template ansible.controller.job_template: name: web app deploy organization: default state: present inventory: lab inventory become_enabled: true playbook: install_node_app.yml project: webdev git repo credential: lab credentials limit: node3.{{ guid }}.internal", "label": 0, "commit_name": "make the code beautiful again, refactor SCM repos to dictionary and bring back Lab Project"}
{"code": "password: $6$3seunsh.v4f49/ec$6w61ug1ymibsysc3wdmz0hvrkouy.p8xvodb5m9iqczlebuh7et6bcnzptviz2/1sfqkm5tfytavruymenvfs1", "label": 1, "commit_name": "Add authorized key for ansible"}
{"code": "password: ! #password: $6$3seunsh.v4f49/ec$6w61ug1ymibsysc3wdmz0hvrkouy.p8xvodb5m9iqczlebuh7et6bcnzptviz2/1sfqkm5tfytavruymenvfs1 - name: ansible user authorized key authorized_key: user: ansible key: {{ ansible_pub_key }} state: present exclusive: true", "label": 0, "commit_name": "Add authorized key for ansible"}
{"code": "enablerepo: 'uspto_rhel_*_red_hat_enterprise_linux_*_server_rpms_x86_64_*server' enablerepo: 'uspto_rhel_8_red_hat_enterprise_linux_8_for_x86_64_-_baseos_rpms_x86_64_8,uspto_rhel_8_red_hat_enterprise_linux_8_for_x86_64_-_appstream_rpms_x86_64_8'", "label": 1, "commit_name": "Modified RAC Standardization play to use standard RedHat Repos"}
{"code": "enablerepo: 'rhel-*-server-rpms' enablerepo: 'rhel-*-baseos-rpms,rhel-*-appstream-rpms'", "label": 0, "commit_name": "Modified RAC Standardization play to use standard RedHat Repos"}
{"code": "- shell: ' echo $(htpasswd -nb admin {{ enter_password }}) | sed -e s/enterpasswordpls/\\\\$/g ./roles/traefik/files/docker-compose.yml '", "label": 1, "commit_name": "Add treafik2.2 bugs fixes 5"}
{"code": "- shell: ' sed -e s/enterpasswordpls/$(htpasswd -nb admin {{ enter_password }})/g ./roles/traefik/files/docker-compose.yml '", "label": 0, "commit_name": "Add treafik2.2 bugs fixes 5"}
{"code": "- name: \"[cultivator - pre-reqs] install base packages for tower cli\"", "label": 1, "commit_name": "Typo in name fix"}
{"code": "- name: \"install base packages for openshift\"", "label": 0, "commit_name": "Typo in name fix"}
{"code": "- name: adjust directory owener and group - name: create directory owener and group debug: msg=\"now generate a token with 'icingacli setup token create' and go at http://ip//icingaweb2/setup to continue the installation\"", "label": 1, "commit_name": "Fix some minor spelling errors"}
{"code": "- name: adjust directory owner and group - name: create directory owner and group debug: msg=\"now generate a token with 'icingacli setup token create' and visit http://serverip/icingaweb2/setup to continue the installation\"", "label": 0, "commit_name": "Fix some minor spelling errors"}
{"code": "name: [ toapk, apk-file, sudo, fa, shadow, tmux, coreutils, binutils, findutils, iproute2, mosh, ncdu, pass, hwinfo, inxi, iftop, nmap ]", "label": 1, "commit_name": "Add a slew of additional packages that were missed after provisioning my l203ma"}
{"code": "name: [ toapk, apk-file, sudo, fa, shadow, tmux, coreutils, binutils, findutils, iproute2, mosh, ncdu, pass, hwinfo, inxi, iftop, nmap, logrotate, tzdata, ncftp ]", "label": 0, "commit_name": "Add a slew of additional packages that were missed after provisioning my l203ma"}
{"code": "apt:", "label": 1, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "ansible.builtin.apt:", "label": 0, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "tags: tags: tags: tags: tags:", "label": 1, "commit_name": "mothball attacks"}
{"code": "tags: tags: tags: tags: tags:", "label": 0, "commit_name": "mothball attacks"}
{"code": "# - name: remove pkg conflicts for powerline fonts # become: true # community.general.pacman: # name: # - powerline-fonts # state: absent #- powerline # vim statusbar #- powerline-fonts # soft dep for powerline #- powerline-vim # soft dep for powerline - name: ensure no .zshrc file exists ansible.builtin.file: path: ~/.zshrc state: absent force: true - name: rebuild pkgfile cache - name: download/install (neo)vim plugins changed_when: true # note: no longer needed? # - name: set default browser via xdg-settings # ignore_errors: true # ansible.builtin.command: # cmd: xdg-settings set default-web-browser {{ default_browser_name }}.desktop", "label": 1, "commit_name": "fixed bugs"}
{"code": "- name: build pkgfile cache (first time only) creates: /var/cache/pkgfile/core.files - name: check if the plugins folder is empty changed_when: false ansible.builtin.find: file_type: any paths: ~/.vim/plugged/ register: plugin_files - name: download/install (neo)vim plugins (first time only) when: plugin_files.matched <= 0", "label": 0, "commit_name": "fixed bugs"}
{"code": "- smalls", "label": 1, "commit_name": "community: fix typo and add missing recipes"}
{"code": "- small", "label": 0, "commit_name": "community: fix typo and add missing recipes"}
{"code": "- ../audit", "label": 1, "commit_name": "Fix relative role not working when using a relative path."}
{"code": "- audit", "label": 0, "commit_name": "Fix relative role not working when using a relative path."}
{"code": "version: master", "label": 1, "commit_name": "Lock easyrsa to pull in fix"}
{"code": "## lock git checkout to pull in openssl fix ## https://github.com/openvpn/easy-rsa/issues/132 version: a138c0d83b0ff1feed385c5d2d7a1c25422fe04d", "label": 0, "commit_name": "Lock easyrsa to pull in fix"}
{"code": "yum: service: enabled: yes firewalld: permanent: yes - restart firewalld template: seboolean: state: yes persistent: yes", "label": 1, "commit_name": "Merge branch 'fix-ansible-lint' into 'main'"}
{"code": "ansible.builtin.yum: ansible.builtin.service: enabled: true ansible.posix.firewalld: permanent: true - restart firewalld ansible.builtin.template: ansible.posix.seboolean: state: true persistent: true", "label": 0, "commit_name": "Merge branch 'fix-ansible-lint' into 'main'"}
{"code": "update_password: true", "label": 1, "commit_name": "Always update password"}
{"code": "update_password: always", "label": 0, "commit_name": "Always update password"}
{"code": "failed_when: not (result.status != 200 or result.status == -1) failed_when: not (result.status != 200 or result.status == -1)", "label": 1, "commit_name": "fix verify 2"}
{"code": "failed_when: not (result.status == 200 or result.status == -1) failed_when: not (result.status == 200 or result.status == -1)", "label": 0, "commit_name": "fix verify 2"}
{"code": "k8s_containerd_variant: docker # can be docker (uses docker apt repo) or upstream (official github release)", "label": 1, "commit_name": "refactor: cleanup - remove old apt repo"}
{"code": "k8s_containerd_variant: docker # can be docker (uses docker apt repo) or github (official github upstream release)", "label": 0, "commit_name": "refactor: cleanup - remove old apt repo"}
{"code": "apt: file: path: \"{{ ansible_env.home }}/{{item}}\" template: mode: 0644 template: mode: 0644 template: mode: 0644 group: user:", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.apt: ansible.builtin.file: path: \"{{ ansible_env.home }}/{{ item }}\" mode: \"0755\" ansible.builtin.template: mode: \"0644\" ansible.builtin.template: mode: \"0644\" ansible.builtin.template: mode: \"0644\" ansible.builtin.group: ansible.builtin.user:", "label": 0, "commit_name": "refactor: lint"}
{"code": "- name: geerlingguy.homebrew - name: geerlingguy.mas", "label": 1, "commit_name": "Fixes #116: Switch from roles and dock tasks to geerlingguy.mac collection."}
{"code": "- name: elliotweiser.osx-command-line-tools collections: - name: geerlingguy.mac", "label": 0, "commit_name": "Fixes #116: Switch from roles and dock tasks to geerlingguy.mac collection."}
{"code": "loop: \"{{ [input_bootstrap_ssl_files_root_ca] + input_bootstrap_ssl_files_intermediates_ca }}\" intermediate_ca_path: \"{{ input_bootstrap_ssl_files_base_path }}/{{ intermediate_ca.cn | replace(' ', '-') }}\" root_ca_path: \"{{ input_bootstrap_ssl_files_base_path }}/{{ root_ca.cn | replace(' ', '-') }}\"", "label": 1, "commit_name": "fix CI 5"}
{"code": "loop: \"{{ [input_bootstrap_ssl_files__root_ca] + input_bootstrap_ssl_files__intermediates_ca }}\" intermediate_ca_path: \"{{ input_bootstrap_ssl_files__base_path }}/{{ intermediate_ca.cn | replace(' ', '-') }}\" root_ca_path: \"{{ input_bootstrap_ssl_files__base_path }}/{{ root_ca.cn | replace(' ', '-') }}\"", "label": 0, "commit_name": "fix CI 5"}
{"code": "name: \"/etc/php/7.0/fpm/pool.d/{{pool}}.conf\" name: \"/etc/munin/plugins/php_fpm_process_{{pool}}\" line: \"{{item}}: root\" - \"{{options.user |default(pool)}}\" - \"{{options.www_user |default('www-' ~ pool)}}\" name: \"{{options.www_user |default('www-' ~ pool)}}\" name: \"{{options.user |default(pool)}}\" name: \"{{options.wwwdir |default('/var/www/' ~ pool)}}\"", "label": 1, "commit_name": "Role php-fpm: fix linting errors"}
{"code": "name: \"/etc/php/7.0/fpm/pool.d/{{ pool }}.conf\" name: \"/etc/munin/plugins/php_fpm_process_{{ pool }}\" line: \"{{ item }}: root\" - \"{{ options.user |default(pool) }}\" - \"{{ options.www_user |default('www-' ~ pool) }}\" name: \"{{ options.www_user |default('www-' ~ pool) }}\" name: \"{{ options.user |default(pool) }}\" name: \"{{ options.wwwdir |default('/var/www/' ~ pool) }}\"", "label": 0, "commit_name": "Role php-fpm: fix linting errors"}
{"code": "notify: - validation of rkhunter configuration file", "label": 1, "commit_name": "moving validation task of configuration file from handlers to rkhunter task"}
{"code": "register: template_generation_status # validate rkhunter configuration file - name: validation of rkhunter configuration file command: /usr/bin/rkhunter -c --configfile /etc/rkhunter.conf when: template_generation_status.changed register: command_result failed_when: command_result.rc|int != 0", "label": 0, "commit_name": "moving validation task of configuration file from handlers to rkhunter task"}
{"code": "# - pulibrary.ansible-datadog", "label": 1, "commit_name": "Fix datadog linting"}
{"code": "- pulibrary.ansible-datadog", "label": 0, "commit_name": "Fix datadog linting"}
{"code": "community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw:", "label": 1, "commit_name": "Merge branch '116-deprecation-warning-wrong-use-of-internal-ref-for-ufw-module' into 'master'"}
{"code": "community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw:", "label": 0, "commit_name": "Merge branch '116-deprecation-warning-wrong-use-of-internal-ref-for-ufw-module' into 'master'"}
{"code": "purge_networks: true purge_networks: true", "label": 1, "commit_name": "refactor: Migrate to networks: strict from purge_networks"}
{"code": "comparisons: networks: strict comparisons: networks: strict", "label": 0, "commit_name": "refactor: Migrate to networks: strict from purge_networks"}
{"code": "name: \"{{ item }}\" with_items: \"{{ cups_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ cups_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "ignore_errors: true become: true with_items: '{{ satnogs_radio_blacklist_modules }}'", "label": 1, "commit_name": "satnogs-radio: Fix indentation error"}
{"code": "become: true with_items: '{{ satnogs_radio_blacklist_modules }}'", "label": 0, "commit_name": "satnogs-radio: Fix indentation error"}
{"code": "#- name: \"add prepequisite packages to curl nodejs repo\" # apt: # update_cache: yes # name: \"{{ item }}\" # state: present # with_items: # - curl # - python-software-properties # #- name: \"curl the 8.x nodejs repo\" # shell: curl -sl https://deb.nodesource.com/setup_8.x | sudo -e bash - # #- name: \"add nodejs 8.x package\" # apt: # update_cache: yes # name: \"{{ item }}\" # state: present # with_items: # - nodejs #- name: \"install every package included in package.json\" # npm: # path: \"{{ thesis_dest }}\" # state: present #- name: \"install packages from provided list \" # npm: # name: \"{{ item }}\" # path: \"{{ thesis_dest }}\" # state: present # global: yes # with_items: \"{{ npm_modules }}\"", "label": 1, "commit_name": "Uncomment code from ansible roles"}
{"code": "- name: \"add prepequisite packages to curl nodejs repo\" apt: update_cache: yes name: \"{{ item }}\" state: present with_items: - curl - python-software-properties - name: \"curl the 8.x nodejs repo\" shell: curl -sl https://deb.nodesource.com/setup_8.x | sudo -e bash - - name: \"add nodejs 8.x package\" apt: update_cache: yes name: \"{{ item }}\" state: present with_items: - nodejs - name: \"install every package included in package.json\" npm: path: \"{{ thesis_dest }}\" state: present - name: \"install packages from provided list \" npm: name: \"{{ item }}\" path: \"{{ thesis_dest }}\" state: present global: yes with_items: \"{{ npm_modules }}\"", "label": 0, "commit_name": "Uncomment code from ansible roles"}
{"code": "run_aptitude_safe_upgrade: yes", "label": 1, "commit_name": "Split security role tasks into separate tasks."}
{"code": "perform_aptitude_dist_upgrade: yes force_ssh_authentication: yes", "label": 0, "commit_name": "Split security role tasks into separate tasks."}
{"code": "- name: install vagrant {{ vagrant_version }}+dfsg-1ubuntu1 name: vagrant={{ vagrant_version }}", "label": 1, "commit_name": "Fix Vagrant"}
{"code": "- name: install vagrant {{ vagrant_version }} name: vagrant={{ vagrant_version }}+dfsg-1ubuntu1", "label": 0, "commit_name": "Fix Vagrant"}
{"code": "owner: vjuan group: staff", "label": 1, "commit_name": "Fixes"}
{"code": "owner: \"{{ ansible_user_id }}\" group: \"{{ ansible_user_gid }}\"", "label": 0, "commit_name": "Fixes"}
{"code": "extract_conditon_cmd: stat /home/xyoz/.cargo", "label": 1, "commit_name": "fixed typo in extract condition var"}
{"code": "extract_condition_cmd: stat /home/xyoz/.cargo", "label": 0, "commit_name": "fixed typo in extract condition var"}
{"code": "register: firewalld_tcp80_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_tcp80_exists.rc != 0 register: iptables_tcp80_exists failed_when: iptables_tcp80_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_tcp80_exists.stdout|int == 0 register: firewalld_tcp8080_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_tcp8080_exists.rc != 0 register: iptables_tcp8080_exists failed_when: iptables_tcp8080_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_tcp8080_exists.stdout|int == 0", "label": 1, "commit_name": "Multiple Fixes: Firewall and Ansible Lint"}
{"code": "register: firewalld_kibana_port_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_kibana_port_exists.rc != 0 register: iptables_kibana_port_exists failed_when: iptables_kibana_port_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_kibana_port_exists.stdout|int == 0 register: firewalld_elk_server_ssl_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_elk_server_ssl_exists.rc != 0 register: iptables_elk_server_ssl_exists failed_when: iptables_elk_server_ssl_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_elk_server_ssl_exists.stdout|int == 0", "label": 0, "commit_name": "Multiple Fixes: Firewall and Ansible Lint"}
{"code": "credentials: [ \"awx ssh key\", \"borgmatic password\" ] extra_vars: { awx_url: \"{{ awx_url }}\" }", "label": 1, "commit_name": "fix delegation in playbooks"}
{"code": "credential: \"awx root key\" credential: \"awx root key\" instance_groups: [\"awx server (custom runner)\"]", "label": 0, "commit_name": "fix delegation in playbooks"}
{"code": "hosts: consul", "label": 1, "commit_name": "refactor: restructure playbooks"}
{"code": "hosts: all", "label": 0, "commit_name": "refactor: restructure playbooks"}
{"code": "tags: line: '^cron_check=weekly'", "label": 1, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "tags: line: 'cron_check=weekly'", "label": 0, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "author: crazyusb license: license (gpl-2.0-or-later, mit, etc) min_ansible_version: 2.1", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "author: crazyusb license: license mit min_ansible_version: \"2.1\"", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "- name: run libvirt as non-root user lineinfile: path: /etc/libvirt/qemu.conf regexp: \"^user =\" line: \"user = {{ ansible_user }}\" - name: run libvirt as non-root user lineinfile: path: /etc/libvirt/qemu.conf regexp: \"^group =\" line: \"group = {{ ansible_user }}\" become: true systemd:", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "- name: add user to libvirt group ansible.builtin.user: name: \"{{ ansible_user }}\" groups: libvirt append: true #- name: run libvirt as non-root user # ansible.builtin.lineinfile: # path: /etc/libvirt/qemu.conf # regexp: \"^user =\" # line: \"user = {{ ansible_user }}\" # become: true # #- name: run libvirt as non-root user # ansible.builtin.lineinfile: # path: /etc/libvirt/qemu.conf # regexp: \"^group =\" # line: \"group = {{ ansible_user }}\" # become: true ansible.builtin.systemd:", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "path: \"{{ k8s_pki_cert_path }}\" register: kubeadm_ca when: groups.k8s_control_plane | flatten | first == inventory_hostname and not kubeadm_ca.stat.exists no_log: true", "label": 1, "commit_name": "fix: kubeadm run detection based on admin.conf"}
{"code": "path: /etc/kubernetes/admin.conf register: __k8s_kubeadm_conf when: groups.k8s_control_plane | flatten | first == inventory_hostname and not __k8s_kubeadm_conf.stat.exists # no_log: true", "label": 0, "commit_name": "fix: kubeadm run detection based on admin.conf"}
{"code": "~/bin/wp dotenv set wp_siteurl ${wp_home}/wp; \\ ~/bin/wp dotenv set db_charset utf8; \\ ~/bin/wp dotenv set db_collate utf8_unicode_ci\"", "label": 1, "commit_name": "Do not bother with charset and collation"}
{"code": "~/bin/wp dotenv set wp_siteurl ${wp_home}/wp\"", "label": 0, "commit_name": "Do not bother with charset and collation"}
{"code": "os_version: \"{{ ansible_lsb.release if ansible_lsb is defined else ansible_distribution_version }}\" os_version_major: \"{{ os_version | regex_replace('^([0-9]+)[^0-9]*.*', '\\\\\\\\1') }}\"", "label": 1, "commit_name": "Merge pull request #23 from ernestas-poskus/fix/os_version_major_parsing"}
{"code": "os_version_major: \"{{ ansible_distribution_major_version }}\"", "label": 0, "commit_name": "Merge pull request #23 from ernestas-poskus/fix/os_version_major_parsing"}
{"code": "- homebrew/php", "label": 1, "commit_name": "Issue #61: Remove outdated homebrew/php tap."}
{"code": "- php", "label": 0, "commit_name": "Issue #61: Remove outdated homebrew/php tap."}
{"code": "- name: audit | openscap | install ubuntu-scap git: repo: https://github.com/govready/ubuntu-scap.git accept_hostkey: true remote: github version: master dest: \"{{ oscap_policy_base }}\"", "label": 1, "commit_name": "Update to use official openscap SSGs instead of ubuntu-scap. Fixes #39"}
{"code": "- name: audit | openscap | get ssgs from openscap github get_url: url: \"{{ oscap_ssg_url }}\" dest: \"~/\" when: ansible_os_family == \"debian\" - name: audit | openscap | unarchive openscap ssgs unarchive: src: \"~/{{ oscap_ssg_archive }}\" dest: \"{{ oscap_policy_parent }}\" remote_src: true become: false", "label": 0, "commit_name": "Update to use official openscap SSGs instead of ubuntu-scap. Fixes #39"}
{"code": "repo: 'deb https://swupdate.openvpn.net/apt {{ ansible_lsb.codename }} main'", "label": 1, "commit_name": "Merge pull request #41 from senorsmile/easyrsa-openssl-fix"}
{"code": "repo: 'deb https://build.openvpn.net/debian/openvpn/stable {{ ansible_lsb.codename }} main'", "label": 0, "commit_name": "Merge pull request #41 from senorsmile/easyrsa-openssl-fix"}
{"code": "community.posgtresql.postgresql_copy:", "label": 1, "commit_name": "Fix typo"}
{"code": "community.postgresql.postgresql_copy:", "label": 0, "commit_name": "Fix typo"}
{"code": "# https://gitlab.com/eyeo/devops/ansible-role-gitlab", "label": 1, "commit_name": "Implement basic libvirt/host guest provisioning"}
{"code": "# https://gitlab.com/eyeo/devops/ansible-role-libvirt", "label": 0, "commit_name": "Implement basic libvirt/host guest provisioning"}
{"code": "connection: local \u2502 gather_facts: no \u2502 become: no", "label": 1, "commit_name": "Merge branch '8-syntax-error-in-satellite-instance-yml' into 'master'"}
{"code": "connection: local gather_facts: no become: no", "label": 0, "commit_name": "Merge branch '8-syntax-error-in-satellite-instance-yml' into 'master'"}
{"code": "es_version: \"5.1.2\"", "label": 1, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "es_version: \"5.2.2\"", "label": 0, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "- export git_ssl_cainfo=\"$ci_server_tls_ca_file\"", "label": 1, "commit_name": "freshen with latest unfurl-types and some ci tweaks"}
{"code": "- '[ -n \"$ci_server_tls_ca_file\" ] && export git_ssl_cainfo=\"$ci_server_tls_ca_file\"'", "label": 0, "commit_name": "freshen with latest unfurl-types and some ci tweaks"}
{"code": "regexp: ^%wheel\\s line: %wheel all=(all) all", "label": 1, "commit_name": "Another bugfix"}
{"code": "regexp: \"^%wheel\\s\" line: \"%wheel all=(all) all\"", "label": 0, "commit_name": "Another bugfix"}
{"code": "wait_timeout: 60 wait_sleep: 10 - name: pause for 30s seconds: 30", "label": 1, "commit_name": "fix: k8s upgrade role now works"}
{"code": "wait_timeout: 90 wait_sleep: 30 - name: pause for 60s seconds: 60", "label": 0, "commit_name": "fix: k8s upgrade role now works"}
{"code": "enabled: yes", "label": 1, "commit_name": "Added smoke test, firewalld setup, heapster, encrypting secrets at rest"}
{"code": "enabled: yes", "label": 0, "commit_name": "Added smoke test, firewalld setup, heapster, encrypting secrets at rest"}
{"code": "- name: install minio - name: add minio secret key for longhorn kubernetes.core.k8s: state: present template: minio-secret-longhorn.yml.j2 vars: accesskey: \"{{ lookup('env', 'minio_backblaze_access_key') }}\" secretkey: \"{{ lookup('env', 'minio_backblaze_secret_key') }}\" serviceendpoint: \"{{ lookup('env', 'minio_service_endpoint') }}\" changed_when: false when: inventory_hostname == master_node", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"minio: install\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "autoheal_container_image: '{{ autoheal_container_repo }}{{ \":\" + autoheal_container_tag }}'", "label": 1, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "autoheal_container_image: 'willfarrell/autoheal:{{ autoheal_container_tag }}'", "label": 0, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "name: \"{{ item }}\" with_items: \"{{ packages.snap.install }}\" name: \"{{ item }}\" with_items: \"{{ packages.classic_snap.install }}\" name: \"{{ item }}\" with_items: \"{{ packages.snaps.remove }}\" name: \"{{ item }}\" with_items: \"{{ packages.classic_snaps.remove }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ packages.snap.install }}\" name: \"{{ packages.classic_snap.install }}\" name: \"{{ packages.snaps.remove }}\" name: \"{{ packages.classic_snaps.remove }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "tags: tags: tags:", "label": 1, "commit_name": "mothball attacks"}
{"code": "tags: tags: tags:", "label": 0, "commit_name": "mothball attacks"}
{"code": "dependencies: - role: syslog", "label": 1, "commit_name": "Remove role's dependencies to avoid reexecuting these roles all the time"}
{"code": "dependencies: []", "label": 0, "commit_name": "Remove role's dependencies to avoid reexecuting these roles all the time"}
{"code": "- ansible-playbook /etc/ansible/roles/role_under_test/tests/test.yml --syntax-check - ansible-playbook /etc/ansible/roles/role_under_test/tests/test.yml", "label": 1, "commit_name": "Fix tests"}
{"code": "- ansible-playbook tests/test.yml --syntax-check - ansible-playbook tests/test.yml", "label": 0, "commit_name": "Fix tests"}
{"code": "# install/uninstall with chocolatey - name: ensure 7-zip is installed through chocolatey win_chocolatey: name: 7zip state: present - name: ensure 7-zip is not installed through chocolatey win_chocolatey: name: 7zip state: absent", "label": 1, "commit_name": "fix: modify "}
{"code": "--- - name: install with chocolatey hosts: all gather_facts: false tasks: - name: ping remote host ping: - name: ensure 7-zip is installed through chocolatey win_chocolatey: name: 7zip state: present", "label": 0, "commit_name": "fix: modify "}
{"code": "- name: download & install telegram dest: /usr/local/bin", "label": 1, "commit_name": "Fix errors on messengers role instalation"}
{"code": "- name: check if viber is installed command: dpkg -s \"viber\" register: viber_check ignore_errors: true when: viber_check.stderr.find('is not installed') != -1 become_user: \"{{ ansible_user }}\" when: viber_check.stderr.find('is not installed') != -1 become: true - name: check if what's up is installed command: dpkg -s \"whatsapp-webapp\" register: whatsapp_check ignore_errors: true when: whatsapp_check.stderr.find('is not installed') != -1 become_user: \"{{ ansible_user }}\" when: whatsapp_check.stderr.find('is not installed') != -1 become: yes - name: check if fb messenger is installed command: dpkg -s \"messengerfordesktop\" register: messenger_check ignore_errors: true - name: install deps for messenger apt: name: libappindicator1 become: yes when: messenger_check.stderr.find('is not installed') != -1 become_user: \"{{ ansible_user }}\" when: messenger_check.stderr.find('is not installed') != -1 become: yes - name: check if telegram is installed command: ls /usr/local/bin/telegram register: telegram_check ignore_errors: true - name: download & unarchive telegram dest: /home/{{ ansible_user }}/downloads become: yes when: telegram_check.stderr.find('/usr/local/bin/telegram') != -1 - name: install telegram shell: | cd /home/{{ ansible_user }}/downloads/telegram chown root:root telegram mv ./telegram telegram cp ./telegram /usr/local/bin when: telegram_check.stderr.find('/usr/local/bin/telegram') != -1", "label": 0, "commit_name": "Fix errors on messengers role instalation"}
{"code": "- name: configure secondary patroni roles ['consul_role', 'postgres_role'] gitlab_rails['auto_migrate'] = false repmgr['enable'] = false patroni['enable'] = false - name: configure secondary - name: stop application server and sidekiq command: gitlab-ctl stop puma && gitlab-ctl stop sidekiq gitlab_rails['auto_migrate'] = false repmgr['enable'] = false patroni['enable'] = true # after bootstrapping, enable this - name: restart postgresql command: gitlab-ctl restart postgresql - import_tasks: tasks/bootstrap/default/reconfigure.yml - import_tasks: tasks/bootstrap/default/fast_ssh_lookups.yml - name: copy gitlab secrets copy: src: /tmp/gitlab-secrets.json dest: /etc/gitlab/gitlab-secrets.json mode: 0600 - import_tasks: tasks/bootstrap/default/reconfigure.yml - command: gitlab-ctl restart", "label": 1, "commit_name": "Fixes to bootstrap patroni correctly on the primary and secondary"}
{"code": "- import_tasks: tasks/bootstrap/default/pgbouncer_write_pgpass.yml pgbouncer['admin_users'] = %w(pgbouncer gitlab-consul) 'gitlab-consul': { password: '{{ gitlab_consul_user_password }}' }, - name: configure secondary consul roles ['consul_role'] # after bootstrapping change roles line above to: # roles ['consul_role', 'patroni_role'] gitlab_rails['auto_migrate'] = false gitlab_rails['db_password'] = '{{ sql_user_password_plain }}' #gitlab_rails['db_host'] = '{{ groups.primary_pgbouncer_internal[0] }}' #gitlab_rails['db_port'] = 6432 - name: configure secondary gitlab instance - import_tasks: tasks/bootstrap/default/fast_ssh_lookups.yml - name: copy gitlab secrets copy: src: /tmp/gitlab-secrets.json dest: /etc/gitlab/gitlab-secrets.json mode: 0600 patroni['enable'] = true gitlab_rails['auto_migrate'] = false - command: gitlab-ctl restart - name: configure secondary patroni hosts: secondary_patronis become: yes become_method: sudo gather_facts: false vars_files: - vars/settings.yml tasks: - lineinfile: path: /etc/gitlab/gitlab.rb line: \"roles ['consul_role']\" state: absent - lineinfile: path: /etc/gitlab/gitlab.rb line: \"roles ['consul_role', 'patroni_role']\" state: present - import_tasks: tasks/bootstrap/default/reconfigure.yml", "label": 0, "commit_name": "Fixes to bootstrap patroni correctly on the primary and secondary"}
{"code": "- name: configure git hosts: all tasks: - name: set vim as the default git editor community.general.git_config: name: core.editor scope: global value: vim - name: set push.default to simple community.general.git_config: name: push.default scope: global value: simple", "label": 1, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "- name: set vim as the default git editor community.general.git_config: name: core.editor scope: global value: vim - name: set push.default to simple community.general.git_config: name: push.default scope: global value: simple", "label": 0, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "path: {{ data_dir }}", "label": 1, "commit_name": "Merge pull request #91 from obierlaire/fix-quotes"}
{"code": "path: \"{{ data_dir }}\"", "label": 0, "commit_name": "Merge pull request #91 from obierlaire/fix-quotes"}
{"code": "- instance", "label": 1, "commit_name": "Merge branch 'tomcat-force-rhel7' into 'master'"}
{"code": "- role: instance vars: ec2_image_name: \"rhel-7.9_hvm_ga*x86_64*\"", "label": 0, "commit_name": "Merge branch 'tomcat-force-rhel7' into 'master'"}
{"code": "# * \u00absocket_count\u00bb, \u00abcore_count\u00bb and \u00abthread_count\u00bb specify the number of cpu # sockets, cores and threads of the guest, # * \u00abram\u00bb specifies the ram of the guest (in mib), # * \u00abpool\u00bb specifies the storage pool of the guest, and # * \u00abpath\u00bb specifies the path to the qcow2 backing file-sytem image of the # * \u00abconnections\u00bb specifies the list of the network connections of the guest # as understood by the `-c` option of the `kvm_tool create machine`", "label": 1, "commit_name": "Fix code formatting in comment"}
{"code": "# * `\u00absocket_count\u00bb`, `\u00abcore_count\u00bb` and `\u00abthread_count\u00bb` specify the number # of cpu sockets, cores and threads of the guest, # * `\u00abram\u00bb` specifies the ram of the guest (in mib), # * `\u00abpool\u00bb` specifies the storage pool of the guest, and # * `\u00abpath\u00bb` specifies the path to the qcow2 backing file-sytem image of the # * `\u00abconnections\u00bb` specifies the list of the network connections of the # guest as understood by the `-c` option of the `kvm_tool create machine`", "label": 0, "commit_name": "Fix code formatting in comment"}
{"code": "hostname: \"{{ item.natip }}\" groupname: primary_nodes - \"{{ gce_primary.networkinterfaces[0].accessconfigs[0] }}\" - name: save primary host add_host: name: \"{{ gce_primary.networkinterfaces[0].accessconfigs[0].natip }}\" groups: primary_host host: \"{{ item.natip }}\" - \"{{ gce_primary.networkinterfaces[0].accessconfigs[0] }}\"", "label": 1, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "hostname: \"{{ item.networkinterfaces[0].accessconfigs[0].natip }}\" groups: - primary_nodes - primary_host - \"{{ gce_primary }}\" host: \"{{ item.networkinterfaces[0].accessconfigs[0].natip }}\" - \"{{ gce_primary }}\"", "label": 0, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "version: '3.6'", "label": 1, "commit_name": "feat: Move Docker registry as optional install, fix docker compose version"}
{"code": "version: '3.8'", "label": 0, "commit_name": "feat: Move Docker registry as optional install, fix docker compose version"}
{"code": "- \"travis_wait 30 ansible-playbook --extra-vars 'configure_sudoers: false' main.yml\"", "label": 1, "commit_name": "Issue #63: Try a different method of quoting the YAML extra-vars."}
{"code": "- 'travis_wait 30 ansible-playbook --extra-vars \"configure_sudoers: false\" main.yml'", "label": 0, "commit_name": "Issue #63: Try a different method of quoting the YAML extra-vars."}
{"code": "when: \"gpg_key.rc == 0\" when: \"gpg_key.rc == 0\"", "label": 1, "commit_name": "refactor: start lint"}
{"code": "when: gpg_key.rc == 0 when: gpg_key.rc == 0", "label": 0, "commit_name": "refactor: start lint"}
{"code": "ansible.builtin.pacman: - xorg # gui - marker # markdown editor - ripgrep # fast, recursive grep searcher - fd # faster `find` command", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "- name: check if kernel needs update ansible.builtin.shell: # when the local kernel version does not match the remote version, # the kernel will need to be updated and a reboot will be required cmd: \"[[ $(pacman -q linux | awk '{print $2}') != $(pacman -s --info linux | grep -e '[0-9].arch' | awk '{print $3}') ]]\" register: kernel_needs_update changed_when: false - ansible.builtin.fail: msg: - \"kernel versions are mismatched (local version vs. remote version)\" - \"to mitigate strange errors with package or module versions...\" - \"update keyring, system, and reboot:\" - \"sudo bash -c 'pacman -sy --noconfirm archlinux-keyring && pacman -syyu --noconfirm && reboot'\" when: kernel_needs_update.rc != 0 - name: update keyring become: true community.general.pacman: name: archlinux-keyring state: latest - name: gather the package facts ansible.builtin.package_facts: manager: auto - name: avoid pkg conflict ('acpilight' overwrites *xbacklight* from 'xorg') become: true ansible.builtin.package: name: xorg # desktop gui state: present when: \"'acpilight' not in ansible_facts.packages\" community.general.pacman: - ghostwriter # markdown editor - bluez # bluetooth - bluez-utils # bluetooth utils - pulseaudio-bluetooth # pulseaudio dep for bluetooth - xf86-input-synaptics # touchpad - android-file-transfer # access files from android device state: present - name: enable services become: true ansible.builtin.service: name: '{{ item }}' enabled: true state: started loop: - bluetooth - name: disable bluetooth on boot become: true vars: bluetooth_enabled: 'false' ansible.builtin.lineinfile: backup: true backrefs: true path: /etc/bluetooth/main.conf regexp: '^#\\s*(autoenable)=.*$' line: '\\1={{ bluetooth_enabled }}' state: present - name: set default systemd service timeout become: true ansible.builtin.blockinfile: path: /etc/systemd/system.conf marker: \"# {mark} systemd_timeout\" create: true state: present mode: '0644' block: | defaulttimeoutstopsec=15s - name: set chromium to use gtk theme ignore_errors: true ansible.builtin.lineinfile: backup: true backrefs: true path: ~/.config/chromium/default/preferences regexp: '(.*)\"system_theme\":0(.*)' line: '\\1 \"system_theme\":1 \\2' state: present # https://wiki.archlinux.org/title/touchpad_synaptics#frequently_used_options - name: configure touchpad to use sane defaults become: true ansible.builtin.copy: remote_src: false src: files/70-synaptics.conf dest: /etc/x11/xorg.conf.d/ mode: '0644' owner: root group: root - name: change default sudo prompt timeout become: true ansible.builtin.lineinfile: path: /etc/sudoers.d/sudo_prompt_timeout line: defaults timestamp_timeout=15 create: true validate: 'visudo -csf %s' mode: '0440' owner: root group: root", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "k8s_unattended_upgrades_state: present", "label": 1, "commit_name": "fix: typo"}
{"code": "k8s_prepull_images: true k8s_unattended_upgrades_state: present", "label": 0, "commit_name": "fix: typo"}
{"code": "apt: file: get_url: mode: 0700 get_url: mode: 0700 shell: gpg2 --keyserver hkps://keyserver.ubuntu.com --recv-keys b541d55301270e0bcf15ca5d8170b4726d7198de file: shell: | debug: shell: force=1 bash <(curl -fssl https://get.jetpack.io/devbox)", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.apt: ansible.builtin.file: mode: \"0755\" ansible.builtin.get_url: mode: \"0700\" ansible.builtin.get_url: mode: \"0700\" ansible.builtin.command: gpg2 --keyserver hkps://keyserver.ubuntu.com --recv-keys b541d55301270e0bcf15ca5d8170b4726d7198de ansible.builtin.file: mode: \"0755\" ansible.builtin.command: | ansible.builtin.debug: ansible.builtin.command: force=1 bash <(curl -fssl https://get.jetpack.io/devbox)", "label": 0, "commit_name": "refactor: lint"}
{"code": "apt: file: path: \"{{ ansible_env.home }}/{{item}}\" get_url: command: command:", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.apt: ansible.builtin.file: path: \"{{ ansible_env.home }}/{{ item }}\" mode: \"0755\" ansible.builtin.get_url: mode: \"0755\" ansible.builtin.command: ansible.builtin.command:", "label": 0, "commit_name": "refactor: lint"}
{"code": "when: \"('not registered' in subscribed.stdout or 'current' not in subscribed.stdout) and rhsm_user is defined and rhsm_user\"", "label": 1, "commit_name": "Merge pull request #933 from ghyde/fix-host-registration"}
{"code": "when: \"'not registered' in subscribed.stdout and rhsm_user is defined and rhsm_user\"", "label": 0, "commit_name": "Merge pull request #933 from ghyde/fix-host-registration"}
{"code": "command: \"az keyvault secret set --vault-name {{ keyvault_name }} --name k8s_kube_config-{{ inventory_dir | basename | replace(' ', '-') }} --value {{ internal_k8s_kubeconfig | to_nice_yaml | b64encode }} \"", "label": 1, "commit_name": "fix: kubeadm secret upload name & role tags"}
{"code": "command: \"az keyvault secret set --vault-name {{ keyvault_name }} --name k8s-kube-config-{{ inventory_dir | basename | replace(' ', '-') | replace('_', '-') }} --value {{ internal_k8s_kubeconfig | to_nice_yaml | b64encode }} \"", "label": 0, "commit_name": "fix: kubeadm secret upload name & role tags"}
{"code": "mount: name=/media/ src=/dev/sr0 fstype=iso9660 opts=ro state=mounted command: cobbler import --arch=x86_64 --path=/media/ --name={{ distro_name }} command: cobbler profile edit --name={{ distro_name }}-x86_64 --kickstart=/var/lib/cobbler/kickstarts/{{ distro_name }}.ks command: cobbler system add --name=anscob-einon --profile={{ distro_name }}-x86_64 --interface=eth0 --mac={{ pxe_mac }} --ip-address={{ pxe_ip }} --netboot-enabled=1 --static=1", "label": 1, "commit_name": "Adding further tweaks to make production installs easier"}
{"code": "mount: name={{ distro_mnt }} src={{ distro_iso }} fstype=iso9660 opts=ro state=mounted ignore_errors: yes command: cobbler import --arch={{ distro_arch }} --path={{ distro_mnt }} --name={{ distro_name }} command: cobbler profile edit --name={{ distro_name }}-{{ distro_arch }} --kickstart=/var/lib/cobbler/kickstarts/{{ distro_name }}.ks command: cobbler system add --name={{ system_name }} --profile={{ distro_name }}-{{ distro_arch }} --interface=eth0 --mac={{ pxe_mac }} --ip-address={{ pxe_ip }} --netboot-enabled=1 --static=1 - name: unmount distro mount: name={{ distro_mnt }} src={{ distro_iso }} fstype=iso9660 opts=ro state=unmounted ignore_errors: yes become: true", "label": 0, "commit_name": "Adding further tweaks to make production installs easier"}
{"code": "satnogs_radio_flowgraphs_version: '1.2.2-1'", "label": 1, "commit_name": "satnogs-radio: Pin versions of 'satnogs-flowgraphs' dependencies (fixes #89)"}
{"code": "satnogs_radio_flowgraphs_version: '{{ default_satnogs_radio_flowgraphs_version }}'", "label": 0, "commit_name": "satnogs-radio: Pin versions of 'satnogs-flowgraphs' dependencies (fixes #89)"}
{"code": "- name: create ca config template: src: \"{{ item['src'] }}\" dest: \"{{ item['dest'] }}\" owner: nginx group: nginx mode: 0640 with_items: - { src: \"gentoo/etc/laprassl/config.lua.j2\", dest: \"/etc/laprassl/config.lua\" } notify: - restart nginx - name: bootstrap ca shell: \"source /etc/profile && lua /usr/share/webapps/laprassl/9999/bootstrap.lua\" args: creates: \"./data/{{ inventory_hostname }}.crt.pem\" chdir: \"/usr/share/webapps/laprassl/9999\" - name: create nginx config template: src: \"{{ item['src'] }}\" dest: \"{{ item['dest'] }}\" owner: root group: root mode: 0640 with_items: - { src: \"gentoo/etc/nginx/conf.d/laprassl.conf.j2\", dest: \"/etc/nginx/conf.d/laprassl.conf\" } notify: - restart nginx", "label": 1, "commit_name": "laprassl: refactor role and cleanup bootrstrap method"}
{"code": "- dev-python/requests - dev-python/cryptography - dev-lua/luarocks - name: create ssl group group: name: ssl system: yes state: present - name: loop laprassl configuration include: ssl.yml until: laprasslcafile.stat.exists == true retries: 2", "label": 0, "commit_name": "laprassl: refactor role and cleanup bootrstrap method"}
{"code": "name: postgresql-9.6 name: postgresql-9.6", "label": 1, "commit_name": "Fix install PostgreSQL"}
{"code": "# \u0437\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u044c \u0438 \u043f\u043e\u043c\u0435\u0441\u0442\u0438\u0442\u044c \u0432 \u0430\u0432\u0442\u043e\u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0443 name: \"{{ postgres.version.9.6.service }}\" # \u043f\u0435\u0440\u0435\u0437\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u044c name: \"{{ postgres.version.9.6.service }}\" # \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u044c \u0438 \u0443\u0434\u0430\u043b\u0438\u0442\u044c \u0438\u0437 \u0430\u0432\u0442\u043e\u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 - name: stop postgresql become: yes service: name: \"{{ postgres.version.9.6.service }}\" stats: stopped enabled: no", "label": 0, "commit_name": "Fix install PostgreSQL"}
{"code": "script: create_tsdb_tables.py", "label": 1, "commit_name": "fix: use relative file path"}
{"code": "script: ../files/create_tsdb_tables.py", "label": 0, "commit_name": "fix: use relative file path"}
{"code": "when: ceph_stable_release not in ceph_stable_releases when: ceph_stable_release in ceph_stable_releases mode: 600 cephx and ceph_stable_release not in ceph_stable_releases cephx and ceph_stable_release in ceph_stable_releases ansible_distribution == \"ubuntu\" and ceph_stable_release not in ceph_stable_releases ansible_distribution == \"ubuntu\" and ceph_stable_release not in ceph_stable_releases ansible_distribution != \"ubuntu\" and ceph_stable_release not in ceph_stable_releases ansible_distribution != \"ubuntu\" and ceph_stable_release not in ceph_stable_releases", "label": 1, "commit_name": "Fix condition logic for infernalis in restapi"}
{"code": "when: is_ceph_infernalis when: not is_ceph_infernalis mode: 0600 cephx and is_ceph_infernalis cephx and not is_ceph_infernalis ansible_distribution == \"ubuntu\" and is_ceph_infernalis ansible_distribution == \"ubuntu\" and not is_ceph_infernalis ansible_distribution != \"ubuntu\" and is_ceph_infernalis ansible_distribution != \"ubuntu\" and not is_ceph_infernalis", "label": 0, "commit_name": "Fix condition logic for infernalis in restapi"}
{"code": "- libapache2-mod-defensible - libapache2-mod-fcgid shell: sudo openssl dhparam -rand /dev/urandom -out /etc/nginx/dhparams.pem > /dev/null", "label": 1, "commit_name": "Typo in OpenSSL DH parameter generation. Updated PHP packet selection for webserver paybooks."}
{"code": "- php-gmp shell: openssl dhparam -rand /dev/urandom -out /etc/nginx/dhparams.pem 4096 > /dev/null", "label": 0, "commit_name": "Typo in OpenSSL DH parameter generation. Updated PHP packet selection for webserver paybooks."}
{"code": "dmcrytpt_journal_collocation: false # backward compatibility with stable-2.2, will disappear in stable 3.1 dmcrypt: \"{{ true if dmcrytpt_journal_collocation or dmcrypt_dedicated_journal else false }}\" # backward compatibility with stable-2.2, will disappear in stable 3.1 osd_scenario: \"{{ 'collocated' if journal_collocation or dmcrytpt_journal_collocation else 'non-collocated' if raw_multi_journal or dmcrypt_dedicated_journal else 'dummy' }}\" # backward compatibility with stable-2.2, will disappear in stable 3.1", "label": 1, "commit_name": "osd: fix a typo in roles/ceph-osd/defaults/main.yml"}
{"code": "dmcrypt_journal_collocation: false # backward compatibility with stable-2.2, will disappear in stable 3.1 dmcrypt: \"{{ true if dmcrypt_journal_collocation or dmcrypt_dedicated_journal else false }}\" # backward compatibility with stable-2.2, will disappear in stable 3.1 osd_scenario: \"{{ 'collocated' if journal_collocation or dmcrypt_journal_collocation else 'non-collocated' if raw_multi_journal or dmcrypt_dedicated_journal else 'dummy' }}\" # backward compatibility with stable-2.2, will disappear in stable 3.1", "label": 0, "commit_name": "osd: fix a typo in roles/ceph-osd/defaults/main.yml"}
{"code": "extra_vars: { awx_url: \"{{ awx_url }}\", awx_token: \"{{ master_token }}\", mailgun_api_token: \"{{ mailgun_api_token }}\", mailgun_domain_name: \"{{ mailgun_domain_name }}\", \"admin_email\": \"{{ admin_email }}\" }", "label": 1, "commit_name": "add SCM update to workflows, update error report plabook"}
{"code": "extra_vars: { host_awx_url: \"{{ awx_url }}\", awx_token: \"{{ master_token }}\", mailgun_api_token: \"{{ mailgun_api_token }}\", mailgun_domain_name: \"{{ mailgun_domain_name }}\", \"admin_email\": \"{{ admin_email }}\" }", "label": 0, "commit_name": "add SCM update to workflows, update error report plabook"}
{"code": "- ../vars/main.yml url: https://packagecloud.io/install/repositories/coanda/public/script.deb.sh", "label": 1, "commit_name": "refactor: move playbooks"}
{"code": "- ../vars/init.yml url: https://packagecloud.io/install/repositories/coanda/public/script.deb.sh", "label": 0, "commit_name": "refactor: move playbooks"}
{"code": "backup: yes backup: yes - dnf update cache", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "backup: true backup: true - dnf update cache", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "- name: include snmp-targets include_vars: file: vars/snmp-targets.yml when: include_snmp_targets dest: \"{{snmp_exporter_home}}/snmp.yml\" owner: \"{{snmp_exporter_username}}\" group: \"{{snmp_exporter_username}}\"", "label": 1, "commit_name": "fixes in ansible syntax. using more default values and making environment deployment easier."}
{"code": "dest: \"{{ snmp_exporter_home }}/snmp.yml\" owner: \"{{ snmp_exporter_username }}\" group: \"{{ snmp_exporter_username }}\"", "label": 0, "commit_name": "fixes in ansible syntax. using more default values and making environment deployment easier."}
{"code": "- name: copy config file to home dir - cp /etc/kubernetes/admin.conf ~{{ansible_remote_user }}/admin.conf - chown {{ ansible_remote_user }}:{{ ansible_remote_user }} ~{{ansible_remote_user }}/admin.conf - chmod 0400 ~{{ansible_remote_user }}/admin.conf - name: write kubeconfgig to bashrc lineinfile: dest=\"~{{ansible_remote_user }}/.bashrc\" line=\"{{item}}\" with_items: - \"export kubeconfig=$home/admin.conf\"", "label": 1, "commit_name": "Updated destination file based on kubeadm documentation. No longer need line in bashrc"}
{"code": "- name: copy config file to home/.kube dir - mkdir -p ~{{ansible_remote_user }}/.kube - cp /etc/kubernetes/admin.conf ~{{ansible_remote_user }}/.kube/config - chown -r {{ ansible_remote_user }}:{{ ansible_remote_user }} ~{{ansible_remote_user }}/.kube - chmod 0400 ~{{ansible_remote_user }}/.kube/config", "label": 0, "commit_name": "Updated destination file based on kubeadm documentation. No longer need line in bashrc"}
{"code": "- emacs-nox - nano - vim", "label": 1, "commit_name": "clean some old and unused code"}
{"code": "# vim: ft=yaml.ansible : - neovim", "label": 0, "commit_name": "clean some old and unused code"}
{"code": "sudo: yes", "label": 1, "commit_name": "Fixing permissions errors with Dashboard & Website.."}
{"code": "sudo: no sudo: yes sudo: yes sudo: yes sudo: yes", "label": 0, "commit_name": "Fixing permissions errors with Dashboard & Website.."}
{"code": "- hosts: all tasks: - name: setup idm server redhat.rhel_idm.ipaserver: ipaadmin_password: \"%testpassword%\" name: idm.idhaoui.ansible-labs.de", "label": 1, "commit_name": "fix calling the role"}
{"code": "- name: deploy idm server hosts: all roles: - role: redhat.rhel_idm.ipaserver state: present", "label": 0, "commit_name": "fix calling the role"}
{"code": "# default is ext4, change to xfs for performance sake.. defaultfstype: xfs defaultdatapath: /tmp/longhorn", "label": 1, "commit_name": "Add wireguard, do some cleanups, utilize wireguard for microk8s and fix a glaring omission with longhorn using the /tmp folder - meaning upon host reboot everything was lost"}
{"code": "defaultfstype: ext4 defaultdatapath: /opt/longhorn", "label": 0, "commit_name": "Add wireguard, do some cleanups, utilize wireguard for microk8s and fix a glaring omission with longhorn using the /tmp folder - meaning upon host reboot everything was lost"}
{"code": "count=$(grep targethost2 log/simple_svc_recipe2/stdout | grep -c -s -v skipping|| [[ $?==1 ]] ) count=$(grep targethost2 log/simple_svc_recipe3/stdout | grep -c -s -v skipping || [[ $?==1 ]] )", "label": 1, "commit_name": "[FIX] wrong service name and log management"}
{"code": "count=$(grep targethost2 log/test_a714_runner/simple_svc_recipe2/stdout | grep -c -s -v skipping|| [[ $?==1 ]] ) count=$(grep targethost2 log/test_a714_runner/simple_svc_recipe3/stdout | grep -c -s -v skipping || [[ $?==1 ]] )", "label": 0, "commit_name": "[FIX] wrong service name and log management"}
{"code": "roles: - ansible-marathon # tasks: # ansible does not recommend checking for service status as a test # need to find a rest endpoint to curl instead", "label": 1, "commit_name": "CentOS/EL 7 support, test validation."}
{"code": "tasks: - name: wait for marathon to be up wait_for: host=\"{{ansible_default_ipv4.address}}\" port=8080 state=started delay=3 timeout=5 - name: test for marathon ... endpoint get_url: url=\"http://{{ansible_default_ipv4.address}}:8080/v2/info\" dest=/tmp/marathon-info force=yes register: status failed_when: \"'ok' not in status.msg\"", "label": 0, "commit_name": "CentOS/EL 7 support, test validation."}
{"code": "os_keypair: name=nightfall public_key_file=/home/lynx/.ssh/id_rsa.pub", "label": 1, "commit_name": "Typo in OpenSSL DH parameter generation. Updated PHP packet selection for webserver paybooks."}
{"code": "os_keypair: name=openstack public_key_file=/home/lynx/.ssh/id_openstack.pub", "label": 0, "commit_name": "Typo in OpenSSL DH parameter generation. Updated PHP packet selection for webserver paybooks."}
{"code": "name: \"{{ item }}\" with_items: ['cifs-utils', 'samba']", "label": 1, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "name: ['cifs-utils', 'samba']", "label": 0, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "- name: init metastore schema - name: add mysql user 'hiveuser'", "label": 1, "commit_name": "Fix PostgreSQL install. [ci skip]"}
{"code": "- name: init hive metastore schema - name: add and grant mysql user 'hiveuser'", "label": 0, "commit_name": "Fix PostgreSQL install. [ci skip]"}
{"code": "name: \"{{ item }}\" with_items: ['apt-transport-https', 'ca-certificates', 'dirmngr', 'gnupg'] name: \"{{ item }}\" with_items: ['nginx', 'libnginx-mod-http-passenger']", "label": 1, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "name: ['apt-transport-https', 'ca-certificates', 'dirmngr', 'gnupg'] name: ['nginx', 'libnginx-mod-http-passenger']", "label": 0, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "- name: \"bootstrap ssl files\" hosts: \"all\" remote_user: root strategy: free bootstrap_ssl_files_user: \"{{ input_bootstrap_ssl_files_user }}\" bootstrap_ssl_files_base_path: \"{{ input_bootstrap_ssl_files_base_path }}\" bootstrap_ssl_files_ca_validity: \"{{ input_bootstrap_ssl_files_ca_validity }}\" bootstrap_ssl_files_key_size: \"{{ input_bootstrap_ssl_files_key_size }}\" bootstrap_ssl_files_root_ca: \"{{ input_bootstrap_ssl_files_root_ca }}\" bootstrap_ssl_files_intermediates_ca: \"{{ input_bootstrap_ssl_files_intermediates_ca }}\" bootstrap_ssl_files_end_certs: \"{{ input_bootstrap_ssl_files_end_certs }}\" bootstrap_ssl_files_cert_validity: \"{{ input_bootstrap_ssl_files_cert_validity }}\"", "label": 1, "commit_name": "force CI"}
{"code": "- name: \"bootstrap ansible ssl files\" hosts: \"{{ tower_env | default([]) }}\" bootstrap_ssl_files__user: \"{{ inv_bootstrap_ssl_files__user }}\" bootstrap_ssl_files__base_path: \"{{ inv_bootstrap_ssl_files__base_path }}\" bootstrap_ssl_files__ca_validity: \"{{ inv_bootstrap_ssl_files__ca_validity }}\" bootstrap_ssl_files__key_size: \"{{ inv_bootstrap_ssl_files__key_size }}\" bootstrap_ssl_files__root_ca: \"{{ inv_bootstrap_ssl_files__root_ca }}\" bootstrap_ssl_files__intermediates_ca: \"{{ inv_bootstrap_ssl_files__intermediates_ca }}\" bootstrap_ssl_files__end_certs: \"{{ inv_bootstrap_ssl_files__end_certs }}\" bootstrap_ssl_files__cert_validity: \"{{ inv_bootstrap_ssl_files__cert_validity }}\"", "label": 0, "commit_name": "force CI"}
{"code": "- restart mariadb - restart firewalld", "label": 1, "commit_name": "fix some ansible-lint errors"}
{"code": "- restart mariadb - restart firewalld", "label": 0, "commit_name": "fix some ansible-lint errors"}
{"code": "update_cache=yes url=\"http://{{rancher_server}}:{{rancher_port}}/v1/projects\" return_content=yes url=\"http://{{rancher_server}}:{{rancher_port}}/v1/registrationtokens?projectid={{project_id.json['data'][0]['id']}}\" return_content=yes", "label": 1, "commit_name": "rancher fixes"}
{"code": "url=\"http://{{rancher_server}}:{{rancher_port}}/v2/projects\" return_content=yes url=\"http://{{rancher_server}}:{{rancher_port}}/v2/registrationtokens?projectid={{project_id.json['data'][0]['id']}}\" return_content=yes restart_policy: always", "label": 0, "commit_name": "rancher fixes"}
{"code": "tags:", "label": 1, "commit_name": "mothball attacks"}
{"code": "--- tags:", "label": 0, "commit_name": "mothball attacks"}
{"code": "systemd: daemon_reload: yes", "label": 1, "commit_name": "Merge pull request #3 from arunderwood/fixes"}
{"code": "#- name: config_openldap | restart slapd # systemd: # name: slapd # enabled: yes # daemon_reload: yes # state: restarted # when: > # admin_password is defined and # admin_password service: #daemon_reload: yes", "label": 0, "commit_name": "Merge pull request #3 from arunderwood/fixes"}
{"code": "uid: \"{{uid}}\" gid: \"{{gid}}\" - lpadmin - sambashare", "label": 1, "commit_name": "Bugfixes: Removed unused groups, fixed uid/gid variable."}
{"code": "uid: 1000 gid: 1000", "label": 0, "commit_name": "Bugfixes: Removed unused groups, fixed uid/gid variable."}
{"code": "#vault_secrets_path: core/ansible-service #vault_shared_secrets_path: core/shared/aws_deploy_credentials ...", "label": 1, "commit_name": "Fix yaml lintting"}
{"code": "# vault_secrets_path: core/ansible-service # vault_shared_secrets_path: core/shared/aws_deploy_credentials ...", "label": 0, "commit_name": "Fix yaml lintting"}
{"code": "- name: check if swap file exists - name: set variable for existing swap file size - name: turn swap off if the size is less than 16gb - name: create a new swapfile of 16gb - name: set the correct permissions for the swapfile - name: format the swapfile - name: turn on swap", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"swap: check if file exists\" - name: \"swap: set variable for existing file size\" - name: \"swap: turn off swap if the size is less than 16gb\" - name: \"swap: create a new swapfile of 16gb\" - name: \"swap: set the correct permissions for the swapfile\" - name: \"swap: format the swapfile\" - name: \"swap: turn on swap\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "command: chdir={{ __tmp_dir }}/cnx", "label": 1, "commit_name": "Fix bugs"}
{"code": "# changed for shell for ccm shell: | mkdir -p /opt/ibm/ctemp export iatempdir=/opt/ibm/ctemp export check_disk_space=off environment: iatempdir: \"/opt/ibm/ctemp\"", "label": 0, "commit_name": "Fix bugs"}
{"code": "scripts/a714-runner --file tests/${srvname}.yml --output-dir log/test_a714_runner --no-ansible-output; - scripts/a714-runner --file tests/simple_backup_test.yml --output-dir log/test_backup_system --mode backup --verbosity 2;", "label": 1, "commit_name": "[IMP] reduce verbosity for tests"}
{"code": "scripts/a714-runner --file tests/${srvname}.yml --output-dir log/test_a714_runner --verbosity 1; - scripts/a714-runner --file tests/simple_backup_test.yml --output-dir log/test_backup_system --mode backup --verbosity 1;", "label": 0, "commit_name": "[IMP] reduce verbosity for tests"}
{"code": "copy: src=files/munins/{{ item }} dest={{ munin_plugin_dest_path }} src=files/munins/{{ item[0] }}", "label": 1, "commit_name": "fix up path and make files executable"}
{"code": "copy: src=munins/{{ item }} dest={{ munin_plugin_dest_path }} mode=0755 src=munins/{{ item[0] }} mode=0755", "label": 0, "commit_name": "fix up path and make files executable"}
{"code": "command: [\"--experimental --mtu=1440\"]", "label": 1, "commit_name": "Revert \"Fix Gitlab runner error\""}
{"code": "command: [\"--experimental\"]", "label": 0, "commit_name": "Revert \"Fix Gitlab runner error\""}
{"code": "selected_theme: adwaita-dark - name: '[qt5/6] use gtk2 themes' export qt_qpa_platformtheme=gtk2 export qt_style_override=gtk2 - qt5-styleplugins - qt6gtk2", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "selected_theme: dracula - name: '[qt5/6] use gtk themes' vars: gtk_version: gtk2 export qt_qpa_platformtheme={{ gtk_version }} export qt_style_override={{ gtk_version }} - dracula-gtk-theme # dark theme - qt5-styleplugins # gui framework - qt6gtk2 # gui framework", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "key: \"{{ hostvars['main_backup_node']['nodes_public_keys']['public_key'] }}\"", "label": 1, "commit_name": "[FIX] main backup node is not correct in preparation playbook"}
{"code": "key: \"{{ hostvars[service_backup_node]['nodes_public_keys']['public_key'] }}\"", "label": 0, "commit_name": "[FIX] main backup node is not correct in preparation playbook"}
{"code": "repo: '{{ repo_url }}'", "label": 1, "commit_name": "Fix bug: repo_url variable is visible across tasks"}
{"code": "repo: '{{ homeshick_repo_url }}'", "label": 0, "commit_name": "Fix bug: repo_url variable is visible across tasks"}
{"code": "to_ip: '{{ radicale_addr }}'", "label": 1, "commit_name": "roles/radicale: correct permissions for htpasswd file, use public listening address"}
{"code": "group: radicale", "label": 0, "commit_name": "roles/radicale: correct permissions for htpasswd file, use public listening address"}
{"code": "yum: name={{ item }} state=present lineinfile: dest=/etc/sysconfig/iptables create=yes state=present regexp=\"{{ httpd_port }}\" insertafter=\"^:output \" line=\"-a input -p tcp --dport {{ httpd_port }} -j accept\" service: name=httpd state=started enabled=yes seboolean: name=httpd_can_network_connect_db state=true persistent=yes", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "yum: name: \"{{ item }}\" state: present lineinfile: dest: /etc/sysconfig/iptables create: yes state: present regexp: \"{{ httpd_port }}\" insertafter: \"^:output \" line: \"-a input -p tcp --dport {{ httpd_port }} -j accept\" service: name: httpd state: started enabled: yes seboolean: name: httpd_can_network_connect_db state: true persistent: yes", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "inv_install_haproxy_cert_bundles:", "label": 1, "commit_name": "refacto, iptables, fixes"}
{"code": "inv_haproxy_cert_bundles:", "label": 0, "commit_name": "refacto, iptables, fixes"}
{"code": "dest: ~/.env", "label": 1, "commit_name": "fix: path"}
{"code": "dest: ~/.env/ansible", "label": 0, "commit_name": "fix: path"}
{"code": "until: operator_source_result.rc == 0", "label": 1, "commit_name": "fix the wrong file"}
{"code": "until: catalog_source_result.rc == 0", "label": 0, "commit_name": "fix the wrong file"}
{"code": "win-ping:", "label": 1, "commit_name": "fix:  win_ping is not win-ping"}
{"code": "win_ping:", "label": 0, "commit_name": "fix:  win_ping is not win-ping"}
{"code": "when: nginxconfig['profiles']['dirlisting'] is defined - name: create certificate file shell: \"cat {{ inventory_hostname }}.pem rootca.pem > /etc/ssl/{{ inventory_hostname }}-nginx.pem\" args: chdir: /var/lib/cfssl when: - sslhostcert.changed == true - inventory_hostname not in groups['cfssl'] notify: - restart nginx", "label": 1, "commit_name": "nginx: fix condition for dirlisting profile"}
{"code": "when: ((nginxconfig | default({}))['profiles'] | default({}))['dirlisting'] is defined", "label": 0, "commit_name": "nginx: fix condition for dirlisting profile"}
{"code": "- hosts: k8s", "label": 1, "commit_name": "fix: typo"}
{"code": "- hosts: localhost k8s_version: 1.28.4 - debug: msg: \"k8s version {{ k8s_version }} type: {{ k8s_version | type_debug }}\"", "label": 0, "commit_name": "fix: typo"}
{"code": "- name: ensure yay is installed become: true ignore_errors: true changed_when: false community.general.pacman: name: yay-bin state: present register: is_yay_installed ansible.builtin.pacman: - name: cleanup `{{ passwordless_sudo_user }}` user from `{{ passwordless_sudo_file }}` create: true mode: 0440", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "- name: ensure yay is installed become: true ignore_errors: true changed_when: false community.general.pacman: name: yay-bin state: present register: is_yay_installed community.general.pacman: - name: === [aur_function_end] cleanup `{{ passwordless_sudo_user }}` user from `{{ passwordless_sudo_file }}` ===", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "- include: force_ssh_authentication.yml when: force_ssh_authentication is defined and force_ssh_authentication", "label": 1, "commit_name": "Adjust order of security roles to make sure new user created before forcing SSH for that user."}
{"code": "- include: force_ssh_authentication.yml when: force_ssh_authentication is defined and force_ssh_authentication", "label": 0, "commit_name": "Adjust order of security roles to make sure new user created before forcing SSH for that user."}
{"code": "- macvim", "label": 1, "commit_name": "Issue #82: Remove macvim so tests can pass again - from the right place."}
{"code": "- licecap", "label": 0, "commit_name": "Issue #82: Remove macvim so tests can pass again - from the right place."}
{"code": "- restart firewalld mode: 0666", "label": 1, "commit_name": "fix some ansible-lint errors"}
{"code": "- restart firewalld mode: \"0666\"", "label": 0, "commit_name": "fix some ansible-lint errors"}
{"code": "- name: download proton ge build ansible.builtin.get_url: url: '{{ proton_ge_url }}' dest: '{{ download_location }}'", "label": 1, "commit_name": "mitigate differing kernel versions, proton install, and setting default browser"}
{"code": "- name: download proton ge build ansible.builtin.get_url: url: '{{ proton_ge_url }}' dest: '{{ download_location }}'", "label": 0, "commit_name": "mitigate differing kernel versions, proton install, and setting default browser"}
{"code": "name: \"{{pl_security_group_name}}\" - name: allow_ssh protocol: tcp destination_port_range: 22 access: allow priority: 100", "label": 1, "commit_name": "Updating security groups"}
{"code": "name: \"{{item.security_group_name}}\" - name: \"{{item.rule_name}}\" protocol: \"{{item.protocol}}\" source_address_prefix: \"{{item.source_address_prefix}}\" description: \"{{item.description}}\" priority: \"{{item.priority}}\" source_port_range: \"{{item.source_port}}\" destination_port_range: \"{{item.destination_port}}\" access: allow with_items: - { \"security_group_name\" : \"{{pl_security_group_name}}\", \"description\" : \"inbound ssh access\", \"rule_name\" : \"allow_ssh\", \"source_address_prefix\" : \"0.0.0.0/0\", \"protocol\" : \"tcp\", \"source_port\" : \"0-65535\", \"destination_port\" : \"22\", \"priority\" : \"100\" }", "label": 0, "commit_name": "Updating security groups"}
{"code": "- name: create trackingdb-1 on secondary cluster name: \"{{ secondary_instance }}-trackingdb-1\" device_name: \"disk-instance-secondary-trackingdb-1-{{ prefix_name }}\" disk_name: \"disk-instance-secondary-trackingdb-1-{{ prefix_name }}\" register: gce_trackingdb1_secondary - name: create trackingdb-2 on secondary cluster gcp_compute_instance: name: \"{{ secondary_instance }}-trackingdb-2\" machine_type: \"{{ machine_type }}\" disks: - auto_delete: true boot: true device_name: \"disk-instance-secondary-trackingdb-2-{{ prefix_name }}\" initialize_params: disk_name: \"disk-instance-secondary-trackingdb-2-{{ prefix_name }}\" disk_size_gb: 30 disk_type: pd-ssd source_image: \"{{ image }}\" network_interfaces: - access_configs: - name: external nat type: one_to_one_nat zone: \"{{ zone }}\" project: \"{{ project_id }}\" auth_kind: serviceaccount service_account_file: \"{{ credentials_file }}\" state: present tags: items: - geo-ansible register: gce_trackingdb2_secondary - name: create trackingdb-3 on secondary cluster gcp_compute_instance: name: \"{{ secondary_instance }}-trackingdb-3\" machine_type: \"{{ machine_type }}\" disks: - auto_delete: true boot: true device_name: \"disk-instance-secondary-trackingdb-3-{{ prefix_name }}\" initialize_params: disk_name: \"disk-instance-secondary-trackingdb-3-{{ prefix_name }}\" disk_size_gb: 30 disk_type: pd-ssd source_image: \"{{ image }}\" network_interfaces: - access_configs: - name: external nat type: one_to_one_nat zone: \"{{ zone }}\" project: \"{{ project_id }}\" auth_kind: serviceaccount service_account_file: \"{{ credentials_file }}\" state: present tags: items: - geo-ansible register: gce_trackingdb3_secondary", "label": 1, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "- name: create tracking database instances on secondary cluster name: \"{{ secondary_instance }}-{{ item }}\" device_name: \"disk-instance-secondary-{{ item }}-{{ prefix_name }}\" disk_name: \"disk-instance-secondary-{{ item }}-{{ prefix_name }}\" with_items: - trackingdb-1 - trackingdb-2 - trackingdb-3 register: gce_trackingdb_secondary async: 300 poll: 2", "label": 0, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "tags: - users", "label": 1, "commit_name": "forgot to set root password on new primary node. selinux is not working, no time to fix it now."}
{"code": "- name: set selinux in permissive mode until issues are resolved ansible.posix.selinux: state: permissive policy: targeted - name: set mysql root password mysql_user: name: root password: \"{{ mariadb_root_password }}\" state: present login_unix_socket: \"{{ mariadb_unix_socket }}\" when: bootstrap_mariadb_primary | default(false) | bool", "label": 0, "commit_name": "forgot to set root password on new primary node. selinux is not working, no time to fix it now."}
{"code": "- default_browser: /usr/bin/librewolf - name: === .profile block === - name: template ~/.profile path: ~/.profile marker: '# {mark} profile_config' export browser={{ default_browser }} text/html={{ default_browser }} x-scheme-handler/http={{ default_browser }} x-scheme-handler/https={{ default_browser }} x-scheme-handler/ftp={{ default_browser }} x-scheme-handler/chrome={{ default_browser }} application/x-extension-htm={{ default_browser }} application/x-extension-html={{ default_browser }} application/x-extension-shtml={{ default_browser }} application/xhtml+xml={{ default_browser }} application/x-extension-xhtml={{ default_browser }} application/x-extension-xht={{ default_browser }} image/jpeg={{ default_browser }} image/png={{ default_browser }}", "label": 1, "commit_name": "fix default browser"}
{"code": "- default_browser_name: librewolf - default_browser_fullpath: /usr/bin/{{ default_browser_name }} - name: === /etc/environment block === - name: template /etc/environment become: true path: /etc/environment marker: '# {mark} environment_config' export browser={{ default_browser_fullpath }} owner: root group: root text/html={{ default_browser_fullpath }} x-scheme-handler/http={{ default_browser_fullpath }} x-scheme-handler/https={{ default_browser_fullpath }} x-scheme-handler/ftp={{ default_browser_fullpath }} x-scheme-handler/chrome={{ default_browser_fullpath }} application/x-extension-htm={{ default_browser_fullpath }} application/x-extension-html={{ default_browser_fullpath }} application/x-extension-shtml={{ default_browser_fullpath }} application/xhtml+xml={{ default_browser_fullpath }} application/x-extension-xhtml={{ default_browser_fullpath }} application/x-extension-xht={{ default_browser_fullpath }} image/jpeg={{ default_browser_fullpath }} image/png={{ default_browser_fullpath }} - name: set default browser via xdg-settings ansible.builtin.command: cmd: xdg-settings set default-web-browser {{ default_browser_name }}.desktop", "label": 0, "commit_name": "fix default browser"}
{"code": "gitlab_runner_baseurl: 'https://packages.gitlab.com/runner/gitlab-runner/el/7/$basearch' - 'https://packages.gitlab.com/runner/gitlab-runner/gpgkey/runner-gitlab-runner-366915f31b487241.pub.gpg'", "label": 1, "commit_name": "gitlab-runner: Fix repository key, add URL based on release major version"}
{"code": "gitlab_runner_baseurl: 'https://packages.gitlab.com/runner/gitlab-runner/el/$releasever/$basearch' - 'https://packages.gitlab.com/runner/gitlab-runner/gpgkey/runner-gitlab-runner-4c80fb51394521e9.pub.gpg'", "label": 0, "commit_name": "gitlab-runner: Fix repository key, add URL based on release major version"}
{"code": "name: \"{{ hostvars[item].inventory_hostname }}\" folder: \"{{ openshift_cloudprovider_vsphere_datacenter }}/vm/{{ openshift_cloudprovider_vsphere_folder }}\" folder: \"{{ openshift_cloudprovider_vsphere_datacenter }}/vm/{{ openshift_cloudprovider_vsphere_folder }}\"", "label": 1, "commit_name": "mend"}
{"code": "name: \"{{ hostvars[item].inventory_hostname }}\" folder: \"{{ openshift_cloudprovider_vsphere_datacenter }}/vm/{{ openshift_cloudprovider_vsphere_folder }}\" folder: \"{{ openshift_cloudprovider_vsphere_datacenter }}/vm/{{ openshift_cloudprovider_vsphere_folder }}\"", "label": 0, "commit_name": "mend"}
{"code": "name: \"{{ item }}\" with_items: \"{{ packages.pip.install }}\" name: \"{{ item }}\" with_items: \"{{ packages.pip.remove }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ packages.pip.install }}\" name: \"{{ packages.pip.remove }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "- name: \"include labocbz.deploy_pihole playbook\" - \"labocbz.deploy_pihole\"", "label": 1, "commit_name": "fix tags"}
{"code": "- name: \"include labocbz.deploy_redis playbook\" - \"labocbz.deploy_redis\"", "label": 0, "commit_name": "fix tags"}
{"code": "borg_repo_ssh_host: \"{{ hostvars[groups['meta-type_borg_server'][0]]['ansible_eth0']['ipv4']['address'] }}\" borg_client_hostname: \"{{ ansible_hostname }}\" borg_repo_ssh_priv_key: \"{{ lookup('env', 'borg_repo_ssh_priv_key')}}\"", "label": 1, "commit_name": "Merge branch 'borg-security-fixes' into 'master'"}
{"code": "pre_tasks: - name: create dir for ssh_keys file: state: dir mode: 700 path: \"~/ansible_borg/ssh_keys\" delegate_to: localhost - name: generate keypair community.crypto.openssh_keypair: path: \"~/ansible_borg/ssh_keys/{{ ansible_hostname }}_deploy_key\" register: ssh_key_pair delegate_to: localhost - name: register private key contents set_fact: ssh_private_key: \"{{ lookup('file', ssh_key_pair.filename) }}\" delegate_to: localhost borg_repo_ssh_priv_key: \"{{ ssh_private_key }}\" borg_repo_ssh_pub_key: \"{{ ssh_key_pair.public_key }}\"", "label": 0, "commit_name": "Merge branch 'borg-security-fixes' into 'master'"}
{"code": "- name: install brave browser", "label": 1, "commit_name": "Fix brave browser mutliple tasks"}
{"code": "- name: add brave repo - name: install brave browser", "label": 0, "commit_name": "Fix brave browser mutliple tasks"}
{"code": "apt: pkg=nginx state=latest update_cache=false", "label": 1, "commit_name": "Fix apt module package installation"}
{"code": "apt: name: nginx state: latest update_cache: true", "label": 0, "commit_name": "Fix apt module package installation"}
{"code": "- repos", "label": 1, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "# \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 postgresql 9.6 - set_repos tags: - postgresql tags: - postgresql tags: - postgresql - set_passwords tags: - postgresql tags: - postgresql", "label": 0, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "satnogs_network_api_url: 'https://network-dev.satnogs.org/api/'", "label": 1, "commit_name": "Change example API URL to point to production network (fixes #24)"}
{"code": "satnogs_network_api_url: 'https://network.satnogs.org/api/'", "label": 0, "commit_name": "Change example API URL to point to production network (fixes #24)"}
{"code": "path: \"{{ flink_install_dir }}\"", "label": 1, "commit_name": "flink: fix role"}
{"code": "path: \"{{ flink_install_dir }}/flink-{{ flink_version }}\"", "label": 0, "commit_name": "flink: fix role"}
{"code": "mode: 0644 - name: \"copy {{ mopidy.conf.src }}\" mode: 0664", "label": 1, "commit_name": "Fix created dir permissions"}
{"code": "mode: 0755 - name: \"copy mopidy configuration file\" mode: 0644", "label": 0, "commit_name": "Fix created dir permissions"}
{"code": "notify: fail on change", "label": 1, "commit_name": "fix some ansible-lint errors"}
{"code": "notify: fail on change", "label": 0, "commit_name": "fix some ansible-lint errors"}
{"code": "- post", "label": 1, "commit_name": "fix: Do not add the skipped tags to the graph"}
{"code": "- pre_task_tags", "label": 0, "commit_name": "fix: Do not add the skipped tags to the graph"}
{"code": "yum: name={{ item }} state=present seboolean: name=mysql_connect_any state=true persistent=yes template: src=my.cnf.j2 dest=/etc/my.cnf service: name=mysqld state=started enabled=yes mysql_db: name={{ dbname }} state=present mysql_user: name={{ dbuser }} password={{ upassword }} priv=*.*:all host='%' state=present", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "yum: name: \"{{ item }}\" state: present seboolean: name: mysql_connect_any state: true persistent: yes template: src: my.cnf.j2 dest: /etc/my.cnf service: name: mysqld state: started enabled: yes mysql_db: name: \"{{ dbname }}\" state: present mysql_user: name: \"{{ dbuser }}\" password: \"{{ upassword }}\" priv: \"*.*:all\" host: '%' state: present", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "when: nginx is defined or (nginx.default_site | default(true))", "label": 1, "commit_name": "nginx: Fix enabling of default site"}
{"code": "when: nginx is defined and (nginx.default_site | default(true))", "label": 0, "commit_name": "nginx: Fix enabling of default site"}
{"code": "--- - name: deploy and encrypted file to servers hosts: all become: no gather_facts: no vars: file_src: ./files/file-to-copy.txt file_dest: \"/tmp/{{ inventory_hostname }}.txt\" tasks: - name: decrypt and deploy file to servers copy: src: \"{{ file_src }}\" dest: \"{{ file_dest }}\"", "label": 1, "commit_name": "Also use an encrypted playbook now"}
{"code": "$ansible_vault;1.1;aes256 36306366333231323564333365613532353630653434343566636365386631666163313032353031 3732613339653661373731376633383130353134613334310a343661663830366638653666393537 39343530323066613933303930386539363162356664303863313034643462343333636130323763 3562326330386139320a393939323465643238316532343634623563636366343039666234356663 61363164383763333964326237336531346332353435396162393537323735313434323063643361 36623731373065313031316632346630316562396333646563323561663934363435326236646439 31346236323735643132333037663036663430626461376630303833393031616437373034616136 33326565626331343261383036653736646362653362623235383830613037623536303639353039 30636236623432613135356361353033383234636537323437333436663634393731316531653730 35656338303266393862633337356338353134343765366361396463653830323638396437386431 32333733303138373662383434656132333738643964623139353535613461616263626336376264 37626433323835636665333266633034633430393836373364363562666232363865663039343163 37396638653132356466346639353435653731316566613965653633386561353361353235346163 31393464636232636366336262303833356234666261366536653932383430636331343834386631 35363632356130623738303937613062313334303439336365663439373731373035356335346333 64643266366362386433303034656533343037313565376630656334643934313837313961316230 37373632366266383563646233393336383631303039356465616337656330353033316634623335 31356234316666356334373461613235323935326266333465633834316437636236643865323832 34373863396465353133306539303835653630646137393339343732386239316633363935616233 38333066616463393735", "label": 0, "commit_name": "Also use an encrypted playbook now"}
{"code": "name: \"{{ item }}\" with_items: \"{{ develop_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ develop_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "#- name: install qutebrowser spell packages # become: yes # become_user: user # ansible.builtin.raw: which qutebrowser # loop: # - en-us # - pt-br # when: # ansible_facts['distribution'] == \"nixos\"", "label": 1, "commit_name": "fix: qutebrowser dicts"}
{"code": "- name: install qutebrowser spell packages become: yes become_user: user ansible.builtin.raw: $(find $(nix-store --query --outputs $(which qutebrowser)) -iname '*dictcli.py*' | head -1) list install {{ item }} loop: - en-us - pt-br when: ansible_facts['distribution'] == \"nixos\"", "label": 0, "commit_name": "fix: qutebrowser dicts"}
{"code": "name: {{ \"packages\" }}", "label": 1, "commit_name": "Fix double quote position"}
{"code": "name: \"{{ packages }}\"", "label": 0, "commit_name": "Fix double quote position"}
{"code": "command: [\"--experimental\"]", "label": 1, "commit_name": "Fix Gitlab runner error"}
{"code": "command: [\"--experimental --mtu=1440\"]", "label": 0, "commit_name": "Fix Gitlab runner error"}
{"code": "changed_when: false - name: upgrade system become: true community.general.pacman: update_cache: true", "label": 1, "commit_name": "fix Molecule bugs"}
{"code": "- name: update package caches changed_when: false become: true ansible.builtin.shell: cmd: \"pacman -f --refresh --refresh\" changed_when: false # - name: upgrade system # become: true # community.general.pacman: # update_cache: true", "label": 0, "commit_name": "fix Molecule bugs"}
{"code": "yum: name={{ item }} state=present copy: src=epel.repo dest=/etc/yum.repos.d/epel.repo copy: src=rpm-gpg-key-epel-6 dest=/etc/pki/rpm-gpg yum: name={{ item }} state=present yum: name=ntp state=present template: src=ntp.conf.j2 dest=/etc/ntp.conf service: name=ntpd state=started enabled=yes template: src=iptables.j2 dest=/etc/sysconfig/iptables", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "yum: name: \"{{ item }}\" state: present copy: src: epel.repo dest: /etc/yum.repos.d/epel.repo copy: src: rpm-gpg-key-epel-6 dest: /etc/pki/rpm-gpg yum: name: \"{{ item }}\" state: present yum: name: ntp state: present template: src: ntp.conf.j2 dest: /etc/ntp.conf service: name: ntpd state: started enabled: yes template: src: iptables.j2 dest: /etc/sysconfig/iptables", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "galera:", "label": 1, "commit_name": "Fix to default variable name"}
{"code": "galera_conf:", "label": 0, "commit_name": "Fix to default variable name"}
{"code": "when: dns_result.rc = 0 and nameserver_ipv4 is defined when: dns_configure.rc = 0 when: dns_apply.rc = 0 when: dns_reload.rc = 0 when: dns_restart.rc = 0 when: dns_result.rc = 0", "label": 1, "commit_name": "Bugfix flags"}
{"code": "when: nameserver_ipv4 is defined when: dns_configure.rc == 0 when: dns_apply.rc == 0 when: dns_reload.rc == 0 when: dns_restart.rc == 0 when: dns_result.rc == 0 register: kinit_result - name: destroy kerberos ticket ansible.builtin.command: cmd: \"kdestroy -a\" when: kinit_result is defined tags: - register", "label": 0, "commit_name": "Bugfix flags"}
{"code": "- name: install needed os pkgs become: true community.general.pacman: name: - docker - docker-compose state: present - name: enable docker service become: true ansible.builtin.service: name: docker enabled: true state: started - name: add `{{ ansible_user }}` to docker group become: true ansible.builtin.user: name: '{{ ansible_user }}' groups: docker append: true state: present", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "- name: install needed os pkgs become: true community.general.pacman: name: - docker - docker-compose state: present - name: enable docker service become: true ansible.builtin.service: name: docker enabled: true state: started - name: add `{{ ansible_user }}` to docker group become: true ansible.builtin.user: name: '{{ ansible_user }}' groups: docker append: true state: present", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "- name: do a reboot. local_action: wait_for port=22", "label": 1, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "- name: do a reboot if system requires it. local_action: wait_for ### set vim as default editor ### see http://www.bufferbloat.net/projects/codel/wiki for further # information. ### improves quality of /dev/random output.", "label": 0, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "chdir: \"{{ easy_rsa_ca_dir }}\" creates: \"{{ easy_rsa_ca_dir }}/ca.key\" chdir: \"{{ easy_rsa_ca_dir }}\" creates: \"{{ easy_rsa_key_dir }}/{{ openvpn_server }}.key\"", "label": 1, "commit_name": "fixes, tags added"}
{"code": "tags: install tags: configure tags: configure tags: configure tags: configure tags: easy_rsa chdir: \"{{ openvpn_rsa_ca_dir }}\" creates: \"{{ openvpn_rsa_ca_dir }}/ca.key\" chdir: \"{{ openvpn_rsa_ca_dir }}\" creates: \"{{ openvpn_rsa_ca_dir }}/{{ openvpn_server }}.key\"", "label": 0, "commit_name": "fixes, tags added"}
{"code": "# - prometheus-node # - nginx-le", "label": 1, "commit_name": "fix: blocked ssh for gitlab runner"}
{"code": "- prometheus-node - nginx-le", "label": 0, "commit_name": "fix: blocked ssh for gitlab runner"}
{"code": "name: {{ user.name }}", "label": 1, "commit_name": "mothball attacks"}
{"code": "name: \"{{ user.name }}\"", "label": 0, "commit_name": "mothball attacks"}
{"code": "- import_tasks: ruby.yml", "label": 1, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "# - import_tasks: ruby.yml", "label": 0, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "order: \"{{ sort_method | default(\"inventory\") }}\"", "label": 1, "commit_name": "Fix wrong syntax for value of order"}
{"code": "order: '{{ sort_method | default(\"inventory\") }}'", "label": 0, "commit_name": "Fix wrong syntax for value of order"}
{"code": "privs: '{{ item.privs | d(omit) }}'", "label": 1, "commit_name": "Fix privileges on roles"}
{"code": "privs: '{{ item.privs | d(item.privileges) | d(omit) }}'", "label": 0, "commit_name": "Fix privileges on roles"}
{"code": "zookeeper_id: 1 zookeeper_id: 2", "label": 1, "commit_name": "fix"}
{"code": "zookeeper_id: \"1\" zookeeper_id: \"2\"", "label": 0, "commit_name": "fix"}
{"code": "- cp ./molecule/$scenario/templates/* ./molecule/$scenario/roles/labocbz.add_apache_confs/templates/\" - cp ./molecule/$scenario/templates/* ./roles/labocbz.add_apache_confs/templates/\"", "label": 1, "commit_name": "fix j2 3"}
{"code": "- \"cp ./molecule/$scenario/templates/* ./molecule/$scenario/roles/labocbz.add_apache_confs/templates/\" - \"cp ./molecule/$scenario/templates/* ./roles/labocbz.add_apache_confs/templates/\"", "label": 0, "commit_name": "fix j2 3"}
{"code": "web_srv: hosts: nginx1: ansible_host: 35.242.217.177 nginx2: ansible_host: 35.242.243.0 vars: ansible_user: suslov", "label": 1, "commit_name": "hosts file modification + README"}
{"code": "all: children: web_srv: hosts: nginx1: ansible_host: 35.242.217.177 nginx2: ansible_host: 35.242.243.0 vars: ansible_user: suslov", "label": 0, "commit_name": "hosts file modification + README"}
{"code": "name: \"{{item}}\" become_user: \"{{service}}\"", "label": 1, "commit_name": "Fix creation of directories for datesfaciles when directories exist"}
{"code": "name: \"~{{service}}/{{item}}\" owner: \"{{service}}\" group: \"{{service}}\"", "label": 0, "commit_name": "Fix creation of directories for datesfaciles when directories exist"}
{"code": "creates: \"/var/lib/ambari-server/resources/mpacks/{{ mpack_filename | regex_replace('.tar.gz$','') }}\"", "label": 1, "commit_name": "Fix for HDP Search mpack installation."}
{"code": "creates: \"/var/lib/ambari-server/resources/mpacks/solr-ambari-mpack-{{ hdpsearch_version }}\"", "label": 0, "commit_name": "Fix for HDP Search mpack installation."}
{"code": "append: yes become: yes mode: '0755' become: yes become: yes - { name: 'bash', repo: 'https://gitlab.com/dotfiles1/dotfiles-bash.git' } - { name: 'screen', repo: 'https://gitlab.com/dotfiles1/dotfiles-screen.git' } - { name: 'vim', repo: 'https://gitlab.com/dotfiles1/dotfiles-vim.git' } - { name: 'git', repo: 'https://gitlab.com/dotfiles1/dotfiles-git.git' } - { name: 'motd', repo: 'https://gitlab.com/dotfiles1/dotfiles-motd.git' } become: yes loop: become: yes remote_src: yes become: yes backup: yes become: yes become: yes become: yes become: yes", "label": 1, "commit_name": "Fix yamllint and ansible-lint errors"}
{"code": "append: true become: true mode: 0755 become: true become: true version: master # yamllint disable rule:line-length - {name: 'bash', repo: 'https://gitlab.com/dotfiles1/dotfiles-bash.git'} - {name: 'screen', repo: 'https://gitlab.com/dotfiles1/dotfiles-screen.git'} - {name: 'vim', repo: 'https://gitlab.com/dotfiles1/dotfiles-vim.git'} - {name: 'git', repo: 'https://gitlab.com/dotfiles1/dotfiles-git.git'} - {name: 'motd', repo: 'https://gitlab.com/dotfiles1/dotfiles-motd.git'} # yamllint enable rule:line-length become: true loop: changed_when: false become: true remote_src: true become: true backup: true become: true become: true become: true become: true", "label": 0, "commit_name": "Fix yamllint and ansible-lint errors"}
{"code": "- name: install gettext dependency", "label": 1, "commit_name": "Fixed typo"}
{"code": "- name: install dash to dock gnome extension", "label": 0, "commit_name": "Fixed typo"}
{"code": "become_method: sudo yum: name={{ item }} state=present tags: [utils]", "label": 1, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "yum: name: \"{{ item }}\" state: present tags: - utils", "label": 0, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "entry: ansible-lint . --force-color -v -p", "label": 1, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "entry: ansible-lint", "label": 0, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "path: \"/etc/networkmanager/system-connections/wired connection 1.nmconnection\" interface-name=enp4s0", "label": 1, "commit_name": "chore(gamechanger-totem): trying to fix NM iface handling"}
{"code": "- name: configure networkmanager to manage any connection blockinfile: path: \"/etc/networkmanager/conf.d/10-globally-managed-devices.conf\" create: yes mode: 644 owner: root block: | [keyfile] unmanaged-devices=*,except:type:wifi,except:type:gsm,except:type:cdma,except:type:ethernet path: \"/etc/networkmanager/system-connections/wired-connections.nmconnection\"", "label": 0, "commit_name": "chore(gamechanger-totem): trying to fix NM iface handling"}
{"code": "- name: check gcp mandatory variables", "label": 1, "commit_name": "adjust GCP variable check for provisioning and deprovisioning"}
{"code": "- name: check gcp mandatory variables during provisioning when: not remove | bool - name: check gcp mandatory variables during deprovisioning ansible.builtin.assert: that: \"{{ item }} is defined\" fail_msg: \"{{ item }} is not defined\" loop: - gcp_project - gcp_region - gcp_zone", "label": 0, "commit_name": "adjust GCP variable check for provisioning and deprovisioning"}
{"code": "- name: openvpn client - installing packages {{ovpnc_inst_packages}} when: ovpnc_conf_gen == true and rc_ovpnc_client_conf.stat.exists == false #- debug: msg='{{rc_date.stdout_lines}}'", "label": 1, "commit_name": "Final source re-arrangements before second code review"}
{"code": "- name: installing packages {{ovpnc_inst_packages}} when: ovpnc_conf_gen == true", "label": 0, "commit_name": "Final source re-arrangements before second code review"}
{"code": "quiet: yes quiet: yes", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "quiet: true quiet: true", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "ansible.builtin.command:", "label": 1, "commit_name": "linting fixes"}
{"code": "ansible.builtin.command: scrolling: # how many lines of scrollback to keep, # '0' will disable scrolling. history: 10000 # number of lines the viewport will move for every line # scrolled when scrollback is enabled (history > 0). multiplier: 3 # faux scrolling # # the `faux_multiplier` setting controls the number # of lines the terminal should scroll when the alternate # screen buffer is active. this is used to allow mouse # scrolling for applications like `man`. # # to disable this completely, set `faux_multiplier` to 0. faux_multiplier: 3", "label": 0, "commit_name": "linting fixes"}
{"code": "register: username_on_the_host", "label": 1, "commit_name": "code cleanup"}
{"code": "register: logged_in_user", "label": 0, "commit_name": "code cleanup"}
{"code": "- command: java -version 2>&1 | grep openjdk changed_when: false", "label": 1, "commit_name": "fix the check for the openjdk"}
{"code": "- shell: java -version 2>&1 | grep openjdk ignore_errors: yes changed_when: false", "label": 0, "commit_name": "fix the check for the openjdk"}
{"code": "dotfiles_castle: \"{{ repo_url | urlsplit('path') | basename | splitext | first }}\"", "label": 1, "commit_name": "Fix bug: repo_url variable is visible across tasks"}
{"code": "dotfiles_castle: \"{{ dotfiles_repo_url | urlsplit('path') | basename | splitext | first }}\"", "label": 0, "commit_name": "Fix bug: repo_url variable is visible across tasks"}
{"code": "- name: copy frr daemons file connection: local become: true copy: src: daemons dest: /etc/frr/daemons backup: yes force: yes notify: restart frr - name: l4 hash policy sysctl: name: net.ipv4.fib_multipath_hash_policy value: 1 state: present", "label": 1, "commit_name": "Error /etc/network does not exist"}
{"code": "#- name: copy frr daemons file # become: yes # copy: # src: daemons # dest: /etc/frr/ # backup: yes # force: yes # notify: restart frr # #- name: l4 hash policy # sysctl: # name: net.ipv4.fib_multipath_hash_policy # value: 1 # state: present #", "label": 0, "commit_name": "Error /etc/network does not exist"}
{"code": "- include: install/redhat.yml", "label": 1, "commit_name": "Fix the way the Redhat installation is included"}
{"code": "- include: redhat.yml", "label": 0, "commit_name": "Fix the way the Redhat installation is included"}
{"code": "password: ! key: {{ ansible_pub_key }}", "label": 1, "commit_name": "Fixed some errors"}
{"code": "password: '!' key: \"{{ ansible_pub_key }}\"", "label": 0, "commit_name": "Fixed some errors"}
{"code": "name: wait for instances to listen on port 22", "label": 1, "commit_name": "ansible fix"}
{"code": "- name: wait for instances to listen on port 22", "label": 0, "commit_name": "ansible fix"}
{"code": "# generated by https://gitlab.com/eyeo/devops/ansible-playbooks/provision-icinga-servers-agents.yml", "label": 1, "commit_name": "Get rid of obsolete variable icinga_server_name & Fix typo"}
{"code": "# generated by https://gitlab.com/eyeo/devops/ansible-playbooks/provision-icinga-servers.yml", "label": 0, "commit_name": "Get rid of obsolete variable icinga_server_name & Fix typo"}
{"code": "- name: wait at least 10 min for the vms to start before we can configre. wait_for_connection: connect_timeout: 20 sleep: 5 delay: 5 timeout: 600 - name: configure selinux to targeted and enforcing selinux: policy: targeted state: enforcing - name: \"install base packages for openshift\" yum: name: \"{{ ocp311_base_packages }}\" state: present become: true when: - ocp_ver == 3.11 - name: install ansible openshift packages for openshift 3.11 yum: name: - atomic-openshift-utils state: present when: - ocp_ver != 3.11 - name: install ansible openshift packages for openshift 3.11 yum: name: - openshift-ansible state: present when: - ocp_ver == 3.11 - name: upgrade all packages yum: name: '*' state: latest register: task_result - name: reboot immediately if there was a change. shell: \"sleep 5 && reboot\" async: 1 poll: 0 when: task_result is changed - name: wait for the reboot to complete if there was a change. wait_for_connection: connect_timeout: 20 sleep: 5 delay: 5 timeout: 300 when: task_result is changed", "label": 1, "commit_name": "Bug fixing"}
{"code": "- include: wait.yml - include: selinux.yml - include: packages.yml", "label": 0, "commit_name": "Bug fixing"}
{"code": "key_name: your_ssh_key", "label": 1, "commit_name": "Typo in OpenSSL DH parameter generation. Updated PHP packet selection for webserver paybooks."}
{"code": "key_name: openstack", "label": 0, "commit_name": "Typo in OpenSSL DH parameter generation. Updated PHP packet selection for webserver paybooks."}
{"code": "- name: install needed os pkgs become: true community.general.pacman: name: - vagrant - libvirt - qemu - virt-manager - nfs-utils - dnsmasq - dmidecode state: present - name: install needed pip3 pkgs ansible.builtin.pip: name: - paramiko # ssh-like library used for dynamic inventory - name: enable libvirtd service become: true ansible.builtin.service: name: libvirtd enabled: true state: started - name: '`nfs.conf` enable vers3' become: true ansible.builtin.lineinfile: path: /etc/nfs.conf regexp: '^#\\s*vers3.*$' line: vers3=y state: present - name: '`nfs.conf` enable udp' become: true ansible.builtin.lineinfile: path: /etc/nfs.conf regexp: '^#\\s*udp=.*$' line: udp=y state: present - name: enable nfs-server service become: true ansible.builtin.service: name: nfs-server enabled: true state: restarted - name: check if libvirt plugin is installed ansible.builtin.command: cmd: vagrant plugin list register: output_vagrant_plugin_list changed_when: output_vagrant_plugin_list.rc != 0 - name: show vagrant plugin list ansible.builtin.debug: msg: - \"=== start :: vagrant plugin list output ===\" - \"{{ output_vagrant_plugin_list.stdout }}\" - \"=== end :: vagrant plugin list output ===\" - name: install libvirt plugin for vagrant, if absent ansible.builtin.command: cmd: vagrant plugin install vagrant-libvirt when: output_vagrant_plugin_list.stdout is not regex(\".*vagrant-libvirt.*\") - name: add '{{ ansible_user }}' to libvirt group become: true ansible.builtin.user: name: '{{ ansible_user }}' groups: libvirt append: true state: present", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "- name: install needed os pkgs become: true community.general.pacman: name: - vagrant - libvirt - qemu - virt-manager - nfs-utils - dnsmasq - dmidecode state: present - name: install needed pip3 pkgs ansible.builtin.pip: name: - paramiko # ssh-like library used for dynamic inventory - name: enable libvirtd service become: true ansible.builtin.service: name: libvirtd enabled: true state: started - name: '`nfs.conf` enable vers3' become: true ansible.builtin.lineinfile: path: /etc/nfs.conf regexp: '^#\\s*vers3.*$' line: vers3=y state: present - name: '`nfs.conf` enable udp' become: true ansible.builtin.lineinfile: path: /etc/nfs.conf regexp: '^#\\s*udp=.*$' line: udp=y state: present - name: enable nfs-server service become: true ansible.builtin.service: name: nfs-server enabled: true state: restarted - name: check if libvirt plugin is installed ansible.builtin.command: cmd: vagrant plugin list register: output_vagrant_plugin_list changed_when: output_vagrant_plugin_list.rc != 0 - name: show vagrant plugin list ansible.builtin.debug: msg: - \"=== start :: vagrant plugin list output ===\" - \"{{ output_vagrant_plugin_list.stdout }}\" - \"=== end :: vagrant plugin list output ===\" - name: install libvirt plugin for vagrant, if absent ansible.builtin.command: cmd: vagrant plugin install vagrant-libvirt when: output_vagrant_plugin_list.stdout is not regex(\".*vagrant-libvirt.*\") - name: add '{{ ansible_user }}' to libvirt group become: true ansible.builtin.user: name: '{{ ansible_user }}' groups: libvirt append: true state: present", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "when: atlassian_extras_old is defined", "label": 1, "commit_name": "jira install error fixed"}
{"code": "when: need_patching", "label": 0, "commit_name": "jira install error fixed"}
{"code": "- 'ruby -e \"$(curl -fssl https://raw.githubusercontent.com/homebrew/install/master/uninstall)\"'", "label": 1, "commit_name": "Issue #61: Answer yes to uninstall confirmation."}
{"code": "- yes '' | 'ruby -e \"$(curl -fssl https://raw.githubusercontent.com/homebrew/install/master/uninstall)\"'", "label": 0, "commit_name": "Issue #61: Answer yes to uninstall confirmation."}
{"code": "#no_log: true #no_log: true", "label": 1, "commit_name": "various fixes"}
{"code": "ssl_mode: verify-full ca_cert: /etc/ssl/certs/ca-certificates.crt no_log: true ssl_mode: verify-full ca_cert: /etc/ssl/certs/ca-certificates.crt no_log: true", "label": 0, "commit_name": "various fixes"}
{"code": "- name: install napari from conda - name: define miniconda as default syst\u00e8me python syst\u00e8me", "label": 1, "commit_name": "Fix typo in name and README.md"}
{"code": "- name: install napari from conda - name: define miniconda as default python (add command to .bashrc)", "label": 0, "commit_name": "Fix typo in name and README.md"}
{"code": "hosts: tomcat", "label": 1, "commit_name": "remove parameters which require root and fix the hosts filter"}
{"code": "hosts: all", "label": 0, "commit_name": "remove parameters which require root and fix the hosts filter"}
{"code": "- name: install gpsd name: 'gpsd' state: 'present' become: true register: res until: res is success retries: '{{ package_retries }}' delay: '{{ package_delay }}' - name: install gpsd clients package: name: 'gpsd-clients'", "label": 1, "commit_name": "gpsd: Optimize installation of packages"}
{"code": "- name: install gpsd and clients name: - 'gpsd' - 'gpsd-clients'", "label": 0, "commit_name": "gpsd: Optimize installation of packages"}
{"code": "register: logrotate_installed failed_when: \"logrotate_installed.rc > 1\" when: ansible_os_family == \"debian\" and logrotate_installed.rc == 0 when: ansible_os_family == \"debian\" and logrotate_installed.rc == 0", "label": 1, "commit_name": "Merge branch 'fix-logrotate-conditional-check' into 'development'"}
{"code": "register: logrotate_install_check failed_when: \"logrotate_install_check.rc > 1\" when: ansible_os_family == \"debian\" and logrotate_install_check.rc == 0 when: ansible_os_family == \"debian\" and logrotate_installed is defined", "label": 0, "commit_name": "Merge branch 'fix-logrotate-conditional-check' into 'development'"}
{"code": "become: true", "label": 1, "commit_name": "Updated to create root path and fix ansible-lint errors (untested)"}
{"code": "--- - name: create local games directory ansible.builtin.file: path: \"{{ folder_path }}\" state: directory mode: 0755 mode: 0770 mode: 0644 become: true", "label": 0, "commit_name": "Updated to create root path and fix ansible-lint errors (untested)"}
{"code": "- ansible - zsh - apt-transport-https - zsh-syntax-highlighting - bat - bat - sudo - sudo - tar - zsh - btop - neovim - ansible-core - ansible-collection-community-general - ncdu - lsof", "label": 1, "commit_name": "fixed mc db error and added support for lxc"}
{"code": "- ansible - apt-transport-https - bat - ripgrep - g++ - zsh - bat - ansible-core - ansible-collection-community-general - btop - g++ - lsof - ncdu - neovim - ripgrep - sudo - tar - zsh", "label": 0, "commit_name": "fixed mc db error and added support for lxc"}
{"code": "become_user: root login_host: 'localhost' login_user: 'root'", "label": 1, "commit_name": "Fixed the MySQL Auth problem"}
{"code": "login_user: root login_unix_socket: \"/var/lib/mysql/mysql.sock\" template: src: \"templates/my.cnf.j2\" dest: \"/root/.my.cnf\" owner: root group: root mode: 0640", "label": 0, "commit_name": "Fixed the MySQL Auth problem"}
{"code": "apiversion: k3s.cattle.io/v1 name: cert-manager chart: stable/cert-manager set: webhook.enabled: \"false\"", "label": 1, "commit_name": "Upgrade k3s to version 0.6.1; Refactor roles & plays"}
{"code": "apiversion: helm.cattle.io/v1 name: kube-metrics-server chart: stable/metrics-server targetnamespace: kube-system", "label": 0, "commit_name": "Upgrade k3s to version 0.6.1; Refactor roles & plays"}
{"code": "author: crazyusb min_ansible_version: 2.1", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "author: crazyusb min_ansible_version: \"2.1\"", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "__this_version: \"{{ cnx_version | default('6.0.0.0_20180927_0113') }}\" __version_check: \"installed com.ibm.connections.6.0.0.0_20180927_0113\" - { app: 'forums', name: \"{{ forums_db.name | default('forums') }}\", server: '{{ forums_db.server | default( __db_hostname ) }}', port: '{{ forums_db.port | default( __db_port ) }}', jdbc_file: '{{ forums_db.jdbc_file | default( __db_jdbc_file ) }}', type: '{{ forums_db.type | default( __db_type ) }}', user: '{{ forums_db.user | default( __db_username ) }}', pw: '{{ forums_db.pw | default( __db_password ) }}' }", "label": 1, "commit_name": "Fix bugs"}
{"code": "__this_version: \"{{ cnx_version | default('6.0.0.0_20190131_2215') }}\" __version_check: \"installed com.ibm.connections.6.0.0.0_20190131_2215\" - { app: 'forums', name: \"{{ forums_db.name | default('forum') }}\", server: '{{ forums_db.server | default( __db_hostname ) }}', port: '{{ forums_db.port | default( __db_port ) }}', jdbc_file: '{{ forums_db.jdbc_file | default( __db_jdbc_file ) }}', type: '{{ forums_db.type | default( __db_type ) }}', user: '{{ forums_db.user | default( __db_username ) }}', pw: '{{ forums_db.pw | default( __db_password ) }}' } __cnx_version_cr3: \"6.0.0.0_20180927_0113\" __cnx_version_check_cr3: \"installed com.ibm.connections.6.0.0.0_20180927_0113\"", "label": 0, "commit_name": "Fix bugs"}
{"code": "vpc_id: \"{{vpcid}}\"", "label": 1, "commit_name": "new code is added to playbook13"}
{"code": "vpc_id: \"{{vpcoutid}}\"", "label": 0, "commit_name": "new code is added to playbook13"}
{"code": "name: \"{{ item }}\" with_items: \"{{ homeassistant_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ homeassistant_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "# this playbook deploys two simple applications to jboss server. # optionally, (re)deploy jboss here", "label": 1, "commit_name": "Fix ansible-lint reported issues in:"}
{"code": "# this playbook deploys two simple applications to jboss server. # optionally, (re)deploy jboss here.", "label": 0, "commit_name": "Fix ansible-lint reported issues in:"}
{"code": "ec2_instance_type: t2.micro ec2_ami_id: ami-0023b746ecfab8fa3 # ec2_ami_id: ami-0a49229a76aed9553 # ec2_instance_type: t4g.nano ec2_security_group: base-enablement ec2_name_tag: meta-rpm ec2_contact_tag: ansible_deploy ec2_app_tag: meta-rpm", "label": 1, "commit_name": "[Fixes] Added some parameter fixes"}
{"code": "# ec2_instance_type: t2.micro # ec2_ami_id: ami-0023b746ecfab8fa3 ec2_ami_id: ami-0a49229a76aed9553 ec2_instance_type: t4g.nano #ec2_security_group: base-enablement ec2_security_group: default ec2_name_tag: meta-rpm ec2_contact_tag: ansible_deploy ec2_app_tag: meta-rpm", "label": 0, "commit_name": "[Fixes] Added some parameter fixes"}
{"code": "become: yes", "label": 1, "commit_name": "Merge branch '13-broken-playbook-to-copy-and-paste-error' into 'main'"}
{"code": "become: true", "label": 0, "commit_name": "Merge branch '13-broken-playbook-to-copy-and-paste-error' into 'main'"}
{"code": "# as understood by the `kvm_tool create machine` command (see # https://levigo.de/stash/projects/lc/repos/kvm.kvm_tool).", "label": 1, "commit_name": "Try to fix link in README"}
{"code": "# as understood by the `kvm_tool create machine` command (see the # [_kvm.kvm_tool_ git # repository](https://levigo.de/stash/projects/lc/repos/kvm.kvm_tool/)).", "label": 0, "commit_name": "Try to fix link in README"}
{"code": "version: 2.1.10", "label": 1, "commit_name": "requirements.yml: Fix tag version for go role"}
{"code": "version: v2.1.10", "label": 0, "commit_name": "requirements.yml: Fix tag version for go role"}
{"code": "when: not tmuxcon.stat.exists", "label": 1, "commit_name": "tmux: fix typo"}
{"code": "when: not tmuxconf.stat.exists", "label": 0, "commit_name": "tmux: fix typo"}
{"code": "become: yes", "label": 1, "commit_name": "Bug in Ansible 2.4.2 that doesn't allow resetting of SSH connection."}
{"code": "become: yes become: yes become: yes become: yes become: yes become: yes register: user_task # - user: name={{ansible_user}} groups=input # become: yes # - name: reset ssh connection to allow user changes to affect current login user - bugged in 2.4.2 # meta: reset_connection", "label": 0, "commit_name": "Bug in Ansible 2.4.2 that doesn't allow resetting of SSH connection."}
{"code": "name: \"{{ sudo_group }}\" regexp: \"^%{{ sudo_group }}\" line: \"%{{ sudo_group }} all=(all) nopasswd: all\" - \"{{ sudo_group }}\" register: playbook_copied when: not playbook_copied.stat.exists", "label": 1, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "name: \"root\" regexp: \"^%root\" line: \"%root all=(all) nopasswd: all\" - root register: system_playbook_copied when: not system_playbook_copied.stat.exists", "label": 0, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "connection: local \u2502 gather_facts: no \u2502", "label": 1, "commit_name": "fix typo"}
{"code": "connection: local gather_facts: no", "label": 0, "commit_name": "fix typo"}
{"code": "when: inventory_hostname != main_server", "label": 1, "commit_name": "5046 mds install fixes"}
{"code": "vars: mds_name: mds_server.name", "label": 0, "commit_name": "5046 mds install fixes"}
{"code": "connect_timeout: 20 sleep: 5 delay: 5 timeout: 300", "label": 1, "commit_name": "Syntax bug"}
{"code": "connect_timeout: 20 sleep: 5 delay: 5 timeout: 300", "label": 0, "commit_name": "Syntax bug"}
{"code": "cmd: source ~/.bashrc && conda create -n napari-env -y python=3.7", "label": 1, "commit_name": "Correct bug in create napari environment task"}
{"code": "cmd: conda create -n napari-env -y python=3.7 chdir: ~/miniconda3/bin", "label": 0, "commit_name": "Correct bug in create napari environment task"}
{"code": "# you can limit this deployment blueprint to environments that match this type, e.g.:", "label": 1, "commit_name": "update documentation"}
{"code": "# you can set the \"cloud\" property to restrict the deployment blueprint # so that it can only be deployed on environments that have been configured to use that cloud provider. # for example, uncomment one of these lines: # cloud: unfurl.relationships.connectsto.googlecloudproject # cloud: unfurl.relationships.connectsto.awsaccount # cloud: unfurl.relationships.connectsto.digitalocean # cloud: unfurl.relationships.connectsto.computemachines", "label": 0, "commit_name": "update documentation"}
{"code": "name: instance_initializer_role", "label": 1, "commit_name": "Fix indentation in main.yml"}
{"code": "name: instance_initializer_role", "label": 0, "commit_name": "Fix indentation in main.yml"}
{"code": "36306366333231323564333365613532353630653434343566636365386631666163313032353031 3732613339653661373731376633383130353134613334310a343661663830366638653666393537 39343530323066613933303930386539363162356664303863313034643462343333636130323763 3562326330386139320a393939323465643238316532343634623563636366343039666234356663 61363164383763333964326237336531346332353435396162393537323735313434323063643361 36623731373065313031316632346630316562396333646563323561663934363435326236646439 31346236323735643132333037663036663430626461376630303833393031616437373034616136 33326565626331343261383036653736646362653362623235383830613037623536303639353039 30636236623432613135356361353033383234636537323437333436663634393731316531653730 35656338303266393862633337356338353134343765366361396463653830323638396437386431 32333733303138373662383434656132333738643964623139353535613461616263626336376264 37626433323835636665333266633034633430393836373364363562666232363865663039343163 37396638653132356466346639353435653731316566613965653633386561353361353235346163 31393464636232636366336262303833356234666261366536653932383430636331343834386631 35363632356130623738303937613062313334303439336365663439373731373035356335346333 64643266366362386433303034656533343037313565376630656334643934313837313961316230 37373632366266383563646233393336383631303039356465616337656330353033316634623335 31356234316666356334373461613235323935326266333465633834316437636236643865323832 34373863396465353133306539303835653630646137393339343732386239316633363935616233 38333066616463393735", "label": 1, "commit_name": "Add vault id encryption and test no_log"}
{"code": "66346263646631396664363139633863623961383632376233613761653930636639303464383461 3038356632386334323464626230653135326561633731650a313466343132653064323630316466 36323638303365633538663766386239613062653530613834323365363730623331303361383435 6565656631626362340a306433616538383234366134333134386666366635346136316138393936 36636632323965323933346638623733613563373935643062653133646563306364363333373565 39346330656565313566636530363031383261373139333364396636333535316164346338616463 35663133656461376236636562646432633033346339326363396331626236306436616431323465 33643162333531623163323064316130393838343835323234353938656237623637323938306337 65626437393830666132613666383635656438643866373431333162366636623631366533373765 65643364633565363064353466373933343338383962346566383363346430313637666232323930 65663539653766343964393634616663376264336535353431343934666361306330623736356533 62646436663339363831636464336637326631386535336465343634316531666135663634656361 66333431633738316535303166343365366337663964383136333563613739353538346233343364 61306135316162383364666661626363306661343366373864323463653832313639366661356263 30316235623736393031343239343939653336633761353838316535356463663566316337393431 36313662323333356533333238393638306335633037373065383266323166313462373165396630 65373338386161363163373763313466353935373166386532393037346236656333336631373161 33306639646236616239396434656538356434383662353730633830633931363862356463366563 32323663613265393063373465643136336537306637633530626534356133336161643336346637 38306334333433336133373438383264333133336533643961616438323238316233373338663734 3137", "label": 0, "commit_name": "Add vault id encryption and test no_log"}
{"code": "username: severi", "label": 1, "commit_name": "fix sudoers bug"}
{"code": "username: rocky", "label": 0, "commit_name": "fix sudoers bug"}
{"code": "mysql_root_password: test mysql_root_user: root password: test1 #need to store in vault password: test3 #need to store in vault pass: verystrong", "label": 1, "commit_name": "add integration with hcl vault, move passwords to vault, remove unnecessary dirs, fix some style typos"}
{"code": "mysql_root_password: \"{{ lookup('hashi_vault', 'secret=ansible/data/mariadb:root_password') }}\" mysql_root_user: \"{{ lookup('hashi_vault', 'secret=ansible/data/mariadb:root_user') }}\" password: \"{{ lookup('hashi_vault', 'secret=ansible/data/mariadb:testuser1_password') }}\" password: \"{{ lookup('hashi_vault', 'secret=ansible/data/mariadb:testuser3_password') }}\" password: \"{{ lookup('hashi_vault', 'secret=ansible/data/mariadb:replica_user_password') }}\"", "label": 0, "commit_name": "add integration with hcl vault, move passwords to vault, remove unnecessary dirs, fix some style typos"}
{"code": "- kubelet - kubeadm - kubectl - name: delete /etc/containerd/config.toml file: path: /etc/containerd/config.toml state: absent notify: - restart service containerd - name: restart service containerd ansible.builtin.systemd: state: restarted name: containerd", "label": 1, "commit_name": "-> fix the version of kubernetes=1.23.6-00\u2705"}
{"code": "- kubelet=1.23.6-00 - kubeadm=1.23.6-00 - kubectl=1.23.6-00 force: yes # # solve issue with kubernetes=v1.24 # - name: delete /etc/containerd/config.toml # file: # path: /etc/containerd/config.toml # state: absent # notify: # - restart service containerd # # solve issue with kubernetes=v1.24 # - name: restart service containerd # ansible.builtin.systemd: # state: restarted # name: containerd", "label": 0, "commit_name": "-> fix the version of kubernetes=1.23.6-00\u2705"}
{"code": "name: \"standalone_certbot\" name: \"custom/openssl\"", "label": 1, "commit_name": "Fix container names in shared certificate task"}
{"code": "name: \"custom-certbot\" name: \"custom-openssl\"", "label": 0, "commit_name": "Fix container names in shared certificate task"}
{"code": "src: \"backgrounds\"", "label": 1, "commit_name": "refactor: start lint"}
{"code": "src: backgrounds", "label": 0, "commit_name": "refactor: start lint"}
{"code": "copy: src: \"{{item}}\" copy:", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.copy: src: \"{{ item }}\" ansible.builtin.copy: mode: \"0755\"", "label": 0, "commit_name": "refactor: lint"}
{"code": "ignore_errors: true", "label": 1, "commit_name": "replace ignore_errors to failed_when to supress ugly error warnings for 'remove suid/sgid' task"}
{"code": "failed_when: false", "label": 0, "commit_name": "replace ignore_errors to failed_when to supress ugly error warnings for 'remove suid/sgid' task"}
{"code": "type: unfurl.nodes.traefikdockercomputehost type: unfurl.nodes.dockercomputehost # the primary resource type node_type: unfurl.nodes.webapp", "label": 1, "commit_name": "freshen with latest unfurl-types and some ci tweaks"}
{"code": "type: unfurl.nodes.httpsproxycontainercomputehost type: unfurl.nodes.containercomputehost primarydeploymentblueprint: gcp node: the_app outputs: # nb: the app's url attribute will not be computed unless this is declared url: value: eval: ::the_app::url node_templates: the_app: type: unfurl.nodes.webapp", "label": 0, "commit_name": "freshen with latest unfurl-types and some ci tweaks"}
{"code": "# https://github.com/sadsfae/ansible-nagios copy: src=idrac_2.2rc4 dest=/usr/lib64/nagios/plugins/idrac_2.2rc4 copy: src=idrac-smiv2.mib dest={{snmp_mib_path}}/", "label": 1, "commit_name": "Fix perms on iDRAC check + Dell MiB."}
{"code": "copy: src=idrac_2.2rc4 dest=/usr/lib64/nagios/plugins/idrac_2.2rc4 mode=\"a+x\" copy: src=idrac-smiv2.mib dest={{snmp_mib_path}}/ mode=0755", "label": 0, "commit_name": "Fix perms on iDRAC check + Dell MiB."}
{"code": "- hosts: puppet puppet:", "label": 1, "commit_name": "fix: Ansible playbook run"}
{"code": "- name: 'puppet run' hosts: puppet - name: 'run puppet on target boxes' community.general.puppet:", "label": 0, "commit_name": "fix: Ansible playbook run"}
{"code": "shell: /usr/local/rvm/scripts/rvm install 2.1.5", "label": 1, "commit_name": "Fixing typo"}
{"code": "shell: /usr/local/rvm/scripts/rvm install 2.1.5", "label": 0, "commit_name": "Fixing typo"}
{"code": "become_method: sudo # webui_repo: \"https://github/jtschichold/minemeld-webui.git\"", "label": 1, "commit_name": "fixed a typo and updated to remove items deprecated as of ansible 2.4.1.0"}
{"code": "# webui_repo: \"https://github.com/jtschichold/minemeld-webui.git\"", "label": 0, "commit_name": "fixed a typo and updated to remove items deprecated as of ansible 2.4.1.0"}
{"code": "- name: update system\"", "label": 1, "commit_name": "Fix several task names"}
{"code": "- name: update system", "label": 0, "commit_name": "Fix several task names"}
{"code": "url: \"https://dl.k8s.io/{{ lookup('url', 'https://dl.k8s.io/release/stable.txt') }}/bin/linux/amd64/kubectl\" checksum: \"sha256:{{ lookup('url', 'https://dl.k8s.io/' + lookup('url', 'https://dl.k8s.io/release/stable.txt') + '/bin/linux/amd64/kubectl.sha256') }}\"", "label": 1, "commit_name": "refactor: start lint"}
{"code": "url: https://dl.k8s.io/{{ lookup('url', 'https://dl.k8s.io/release/stable.txt') }}/bin/linux/amd64/kubectl checksum: sha256:{{ lookup('url', 'https://dl.k8s.io/' + lookup('url', 'https://dl.k8s.io/release/stable.txt') + '/bin/linux/amd64/kubectl.sha256') }}", "label": 0, "commit_name": "refactor: start lint"}
{"code": "dest: /etc/systemd/system/multi-user.target.wants/nginx.service", "label": 1, "commit_name": "nginx-passenger: fix location of systemd service"}
{"code": "dest: /etc/systemd/system/nginx.service", "label": 0, "commit_name": "nginx-passenger: fix location of systemd service"}
{"code": "patroni['postgresql']['max_wal_senders'] = 10 postgresql['md5_auth_cidr_addresses'] = [ '{{ groups.primary_patronis_internal[0] }}/32', '{{ groups.primary_patronis_internal[1] }}/32', '{{ groups.primary_patronis_internal[2] }}/32', '{{ groups.secondary_patronis_internal[0] }}/32', '{{ groups.secondary_patronis_internal[1] }}/32', '{{ groups.secondary_patronis_internal[2] }}/32', '{{ groups.primary_pgbouncer_internal[0] }}/32', '{{ groups.secondary_pgbouncer_internal[0] }}/32', '{{ groups.primary_host_internal[0] }}/32', '{{ groups.secondary_host_internal[0] }}/32', 'localhost' repmgr['enable'] = false postgresql['max_replication_slots'] = 10 # patroni needs one extra when doing backup restore, so always use ammount of slots * 2 postgresql['md5_auth_cidr_addresses'] = [ '{{ groups.primary_patronis_internal[0] }}/32', '{{ groups.primary_patronis_internal[1] }}/32', '{{ groups.primary_patronis_internal[2] }}/32', '{{ groups.secondary_patronis_internal[0] }}/32', '{{ groups.secondary_patronis_internal[1] }}/32', '{{ groups.secondary_patronis_internal[2] }}/32', '{{ groups.primary_pgbouncer_internal[0] }}/32', '{{ groups.secondary_pgbouncer_internal[0] }}/32', '{{ groups.primary_host_internal[0] }}/32', '{{ groups.secondary_host_internal[0] }}/32', 'localhost'", "label": 1, "commit_name": "Refactor postgresql authentication configuration"}
{"code": "patroni['postgresql']['max_wal_senders'] = 10 # patroni needs one extra slot when doing backup restore, so always use ammount of slots * 2 postgresql['md5_auth_cidr_addresses'] = %w[ {% for host in groups.primary_patronis_internal %}{{ host }}/32 {% endfor %} {% for host in groups.secondary_patronis_internal %}{{ host }}/32 {% endfor %} {{ groups.primary_pgbouncer_internal[0] }}/32 {{ groups.primary_host_internal[0] }}/32 {{ groups.secondary_host_internal[0] }}/32 localhost # patroni needs one extra slot when doing backup restore, so always use ammount of slots * 2 postgresql['md5_auth_cidr_addresses'] = %w[ {% for host in groups.primary_patronis_internal %}{{ host }}/32 {% endfor %} {% for host in groups.secondary_patronis_internal %}{{ host }}/32 {% endfor %} {{ groups.primary_pgbouncer_internal[0] }}/32 {{ groups.secondary_pgbouncer_internal[0] }}/32 {{ groups.primary_host_internal[0] }}/32 {{ groups.secondary_host_internal[0] }}/32 localhost", "label": 0, "commit_name": "Refactor postgresql authentication configuration"}
{"code": "get_url: file: path: \"{{ ansible_env.home }}/{{item}}\"", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.get_url: ansible.builtin.file: path: \"{{ ansible_env.home }}/{{ item }}\" mode: \"0700\"", "label": 0, "commit_name": "refactor: lint"}
{"code": "- name: elasticsearch package tests #plugins installed for this test are specified in .kitchen.yml under suite", "label": 1, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "- name: elasticsearch package test intiial es_version: \"5.1.2\" es_plugins: - plugin: ingest-geoip #tests the plugins have been correctly removed and es can be upgraded between minor versions. all plugins will be removed and re-installed. - name: elasticsearch package test modify hosts: localhost roles: - { role: elasticsearch, es_config: { \"http.port\": 9200, \"transport.tcp.port\":9300, discovery.zen.ping.unicast.hosts: \"localhost:9300\" }, es_instance_name: \"node1\" } vars: es_scripts: true es_templates: true es_version: \"5.2.2\" es_heap_size: \"1g\" es_api_port: 9200 es_plugins: - plugin: ingest-attachment - plugin: ingest-geoip", "label": 0, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "debug: msg=\"*** edit the /etc/motd , /etc/issue and /etc/issue.net files and remove any lines containing \\m , \\r , \\s or \\v\"", "label": 1, "commit_name": "Section 11.2: Fix minor punctuation error"}
{"code": "debug: msg=\"*** edit the /etc/motd, /etc/issue and /etc/issue.net files and remove any lines containing \\m, \\r, \\s or \\v\"", "label": 0, "commit_name": "Section 11.2: Fix minor punctuation error"}
{"code": "- name: homebrew/cask - name: koekeishiya/formulae - name: thoughtbot/formulae", "label": 1, "commit_name": "Use default filter to remove task duplication"}
{"code": "- homebrew/cask - koekeishiya/formulae - thoughtbot/formulae", "label": 0, "commit_name": "Use default filter to remove task duplication"}
{"code": "- import_playbook: nomadhosts.yml", "label": 1, "commit_name": "fix k8shosts playbook import"}
{"code": "- import_playbook: k8shosts.yml", "label": 0, "commit_name": "fix k8shosts playbook import"}
{"code": "- name: get system python 3 version # noqa 306 - name: get virtualenv python version # noqa 306", "label": 1, "commit_name": "ansible-lint: Fix and ignore some errors"}
{"code": "- name: get system python 3 version # noqa risky-shell-pipe - name: get virtualenv python version # noqa risky-shell-pipe", "label": 0, "commit_name": "ansible-lint: Fix and ignore some errors"}
{"code": "service: name=mysqld state=restarted service: name=iptables state=restarted", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "service: name: mysqld state: restarted service: name: iptables state: restarted", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "- php", "label": 1, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "- php", "label": 0, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "firewalld_backend is defined and", "label": 1, "commit_name": "firewall: Fix typo on newly introduced variable"}
{"code": "firewall_backend is defined and", "label": 0, "commit_name": "firewall: Fix typo on newly introduced variable"}
{"code": "that: student_name != {{ item }} - admin - learnfest - root", "label": 1, "commit_name": "Merge branch 'fix-create-user-checks' into 'main'"}
{"code": "that: student_name != \"{{ item }}\" - \"admin\" - \"learnfest\" - \"root\"", "label": 0, "commit_name": "Merge branch 'fix-create-user-checks' into 'main'"}
{"code": "- name: test postfix configuration failed_when: res.stderr != '' # noqa empty-string-compare", "label": 1, "commit_name": "ansible-lint: Fix some errors"}
{"code": "- name: test postfix configuration # noqa empty-string-compare failed_when: res.stderr != ''", "label": 0, "commit_name": "ansible-lint: Fix some errors"}
{"code": "url: https://deb.nodesource.com/setup_8.x dest: \"/home/{{ application.nodejs.username }}/setup-nodejs\" shell: \"/home/{{ application.nodejs.username }}/setup-nodejs\" name: \"{{ item }}\" with_items: ['nodejs', 'build-essential']", "label": 1, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "url: https://deb.nodesource.com/setup_10.x dest: \"/var/lib/jenkins/setup-nodejs\" shell: \"/var/lib/jenkins/setup-nodejs\" name: ['build-essential', 'nodejs']", "label": 0, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "- \"[ -f \\\"./molecule/$scenario/requirements.yml\\\" ] && cp ./molecule/$scenario/templates/* ./molecule/$scenario/roles/*/templates/\" - \"[ -f \\\"./molecule/$scenario/requirements.yml\\\" ] && cp ./molecule/$scenario/templates/* ./roles/*/templates/\"", "label": 1, "commit_name": "fix j2 2"}
{"code": "- cp ./molecule/$scenario/templates/* ./molecule/$scenario/roles/labocbz.add_apache_confs/templates/\" - cp ./molecule/$scenario/templates/* ./roles/labocbz.add_apache_confs/templates/\"", "label": 0, "commit_name": "fix j2 2"}
{"code": "- name: run puppet-agent cmd: puppet agent --test", "label": 1, "commit_name": "Add full LXC provisioning, add lxd hosts"}
{"code": "- name: run puppet-agent (network) cmd: puppet agent --test --tags network register: agent_result retries: 5 failed_when: agent_result.rc not in (0, 2) - name: upgrade system packages ansible.builtin.apt: update_cache: true upgrade: full - name: reboot ansible.builtin.reboot: reboot_command: systemctl reboot reboot_timeout: 180", "label": 0, "commit_name": "Add full LXC provisioning, add lxd hosts"}
{"code": "community.aws.ec2_instance_info:", "label": 1, "commit_name": "fix password module"}
{"code": "amazon.aws.ec2_instance_info:", "label": 0, "commit_name": "fix password module"}
{"code": "# handler for the webtier: handlers are called by other plays. # see http://docs.ansible.com/playbooks_intro.html for more information about handlers. service: name=firewalld state=restarted", "label": 1, "commit_name": "Merge branch 'fix-ansible-lint' into 'main'"}
{"code": "ansible.builtin.service: name: firewalld state: restarted", "label": 0, "commit_name": "Merge branch 'fix-ansible-lint' into 'main'"}
{"code": "name: [ xorg-server, xf86-input-keyboard, xf86-input-mouse, xf86-video-modesetting, xf86-video-intel, dbus-x11, polkit, consolekit2, xfce4, xfwm4, libxfce4ui, libxfce4ui-gtk3, lightdm, lightdm-gtk-greeter, network-manager-applet, xfce4-notifyd, xfce4-settings, xfce4-whiskermenu-plugin, xfce4-appfinder, xfce4-power-manager, xfce4-screensaver, xfce4-terminal, xfce4-session, xfce4-panel, xfce-polkit, xfce4-pulseaudio-plugin, xfce4-battery-plugin, xfce4-screenshooter, arc-dark, arc-darker, arc-lighter, papirus-icon-theme, font-iosevka-nerd, ttf-freefont, ttf-cantarell, font-noto, alsaconf, alsa-utils, alsa-tools, alsa-plugins, alsa-plugins-pulse, pulseaudio, pulseaudio-alsa, pulseaudio-jack, pulseaudio-utils, pavucontrol, networkmanager, networkmanager-openvpn, networkmanager-l2tp, iwd, wpa_supplicant, wireless-tools, dmenu, xrandr, arandr, thunar, firefox, virt-manager ]", "label": 1, "commit_name": "Add a slew of additional packages that were missed after provisioning my l203ma"}
{"code": "name: [ xorg-server, xf86-input-keyboard, xf86-input-mouse, xf86-video-modesetting, xf86-video-intel, dbus-x11, polkit, consolekit2, xfce4, xfwm4, libxfce4ui, libxfce4ui-gtk3, lightdm, lightdm-gtk-greeter, network-manager-applet, xfce4-notifyd, xfce4-settings, xfce4-whiskermenu-plugin, xfce4-appfinder, xfce4-power-manager, xfce4-screensaver, xfce4-terminal, xfce4-session, xfce4-panel, xfce-polkit, xfce4-pulseaudio-plugin, xfce4-battery-plugin, xfce4-screenshooter, arc-dark, arc-darker, arc-lighter, papirus-icon-theme, font-iosevka-nerd, ttf-freefont, ttf-cantarell, font-noto, alsaconf, alsa-utils, alsa-tools, alsa-plugins, alsa-plugins-pulse, pulseaudio, pulseaudio-alsa, pulseaudio-jack, pulseaudio-utils, pavucontrol, networkmanager, networkmanager-openvpn, networkmanager-l2tp, iwd, wpa_supplicant, wireless-tools, dmenu, xrandr, arandr, thunar, firefox, virt-manager, peek ]", "label": 0, "commit_name": "Add a slew of additional packages that were missed after provisioning my l203ma"}
{"code": "radicale_addr: 127.0.0.1", "label": 1, "commit_name": "roles/radicale: correct permissions for htpasswd file, use public listening address"}
{"code": "radicale_addr: 0.0.0.0", "label": 0, "commit_name": "roles/radicale: correct permissions for htpasswd file, use public listening address"}
{"code": "docker_compose_version: \"v2.24\"", "label": 1, "commit_name": "fix: Fix docker compose check"}
{"code": "docker_compose_version: \"v2.24.1\"", "label": 0, "commit_name": "fix: Fix docker compose check"}
{"code": "import_tasks: tasks.yml", "label": 1, "commit_name": "fix: Do not add the skipped tags to the graph"}
{"code": "import_tasks: tasks/tasks.yml", "label": 0, "commit_name": "fix: Do not add the skipped tags to the graph"}
{"code": "mode: 0644 - name: change user's shell to zsh user:", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "mode: \"0644\" - name: change user's shell to zsh ansible.builtin.user:", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "prepare_host__users: \"{{ inv_install_elasticsearch__prepare_host__users }}\" prepare_host__users: \"{{ inv_install_logstash__prepare_host__users }}\" prepare_host__users: \"{{ inv_install_kibana__prepare_host__users }}\"", "label": 1, "commit_name": "fix playbook"}
{"code": "prepare_host__system_users: \"{{ inv_prepare_host__elasticsearch_system_users }}\" prepare_host__system_users: \"{{ inv_prepare_host__logstash_system_users }}\" prepare_host__system_users: \"{{ inv_prepare_host__kibana_system_users }}\"", "label": 0, "commit_name": "fix playbook"}
{"code": "haskell_src_dir: /home/urbanslug/src/haskell generic_src_dir: /home/urbanslug/src/generic dotfiles_dir: /home/urbanslug/src/generic/dotfiles urbanslug_home_dir: /home/urbanslug zsh_dir: /home/urbanslug/.zsh githubuser: urbanslug", "label": 1, "commit_name": "Make it open source-able"}
{"code": "urbanslug_home_dir: \"/home/urbanslug\" dotfiles_dir: \"{{ urbanslug_home_dir }}/src/generic/dotfiles\" generic_src_dir: \"{{ urbanslug_home_dir }}/src/generic\" zsh_dir: \"{{ dotfiles_dir }}/.zsh\" dirs: - \"{{ urbanslug_home_dir }}/.config\" packages: - znc - python-virtualenvwrapper symlinks: \"{{ dotfiles_dir }}/.zsh\": \"{{ urbanslug_home_dir }}/.zsh\" \"{{ dotfiles_dir }}/.zshrc\": \"{{ urbanslug_home_dir }}/.zshrc\" \"{{ dotfiles_dir }}/.tmux.conf\": \"{{ urbanslug_home_dir }}/.tmux.conf\" \"{{ dotfiles_dir }}/.config/git\": \"{{ urbanslug_home_dir }}/.config/git\"", "label": 0, "commit_name": "Make it open source-able"}
{"code": "- name: ceate second virtual network resource_group: \"{{ resource_group }}\" virtual_network: \"{{ vnet_name1 }}\"", "label": 1, "commit_name": "fix typo in vnet_peering doc (#66)"}
{"code": "- name: create second virtual network resource_group: \"{{ resource_group_secondary }}\" virtual_network: \"{{ vnet_name1 }}\" state: absent", "label": 0, "commit_name": "fix typo in vnet_peering doc (#66)"}
{"code": "mode: '0750' url: \"https://packages.microsoft.com/keys/microsoft.asc\" src: \"vscode.list\" dest: \"/etc/apt/sources.list.d/vscode.list\" mode: '0644' command: \"fc-cache -f\" command: \"/usr/bin/code --install-extension {{ vscode_extensions | join(' --install-extension ') }}\" file: template: mode: '0644'", "label": 1, "commit_name": "refactor: start lint"}
{"code": "mode: \"0750\" url: https://packages.microsoft.com/keys/microsoft.asc src: vscode.list dest: /etc/apt/sources.list.d/vscode.list mode: \"0644\" mode: \"0644\" command: fc-cache -f command: /usr/bin/code --install-extension {{ vscode_extensions | join(' --install-extension ') }} ansible.builtin.file: mode: \"0755\" ansible.builtin.template: mode: \"0644\"", "label": 0, "commit_name": "refactor: start lint"}
{"code": "inv_logrotate_configurations_apache:", "label": 1, "commit_name": "fix logs"}
{"code": "inv_logrotate_apache_configurations:", "label": 0, "commit_name": "fix logs"}
{"code": "all: vagrant: ansible_host: localhost ansible_port: 2222", "label": 1, "commit_name": "fix: mount the virtualbox drive from /dev/sdc"}
{"code": "odroid: vagrant: hosts: virtualbox: ansible_host: localhost ansible_port: 2222 vars: pop_ssd: /dev/sdc pop_ssd_mount: /dev/sdc1", "label": 0, "commit_name": "fix: mount the virtualbox drive from /dev/sdc"}
{"code": "- '{{ owncloud_php5_pool }}' - '{{ owncloud_nginx_server }}' - '{{ owncloud_nginx_upstream_php5 }}'", "label": 1, "commit_name": "Fix role-dependent configuration vars in owncloud playbook"}
{"code": "- '{{ owncloud__php5__pool }}' - '{{ owncloud__nginx__servers }}' - '{{ owncloud__nginx__upstream_php5 }}'", "label": 0, "commit_name": "Fix role-dependent configuration vars in owncloud playbook"}
{"code": "- mysql - name: create mysql db 'metastore' mysql_db: name=metastore state=present login_user=root login_password=hive_{{ site_name }} tags: - mysql - hive - name: init hive metastore schema shell: mysql -uroot -phive_{{ site_name }} metastore < /usr/lib/hive/scripts/metastore/upgrade/mysql/hive-schema-0.10.0.mysql.sql tags: - mysql - hive - name: add and grant mysql user 'hiveuser' mysql_user: name=hiveuser host=localhost password=hive_{{ site_name }} priv=metastore.*:all state=present login_user=root login_password=hive_{{ site_name }} tags: - mysql - hive", "label": 1, "commit_name": "Fix postgres script. [ci skip]"}
{"code": "- mysql", "label": 0, "commit_name": "Fix postgres script. [ci skip]"}
{"code": "- pip install --upgradable pip - pip install --upgradable ansible", "label": 1, "commit_name": ".travis.yml: Fix typo in `pip' command option"}
{"code": "- pip install --upgrade pip - pip install --upgrade ansible", "label": 0, "commit_name": ".travis.yml: Fix typo in `pip' command option"}
{"code": "- name: install redis cluster from helm", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"cluster-redis: install redis cluster\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "when: gpg_key.rc != 0 when: gpg_key.rc != 0", "label": 1, "commit_name": "refactor: yml to yaml"}
{"code": "when: \"gpg_key.rc == 0\" when: \"gpg_key.rc == 0\"", "label": 0, "commit_name": "refactor: yml to yaml"}
{"code": "ansible_connection: local kubernetes: apiserver_advertise_address: 192.168.1.144 cmd_join_cluster: ''", "label": 1, "commit_name": "-> Solve issue \ud83d\udca1:"}
{"code": "# ansible_connection: local master_user: wi11i4m", "label": 0, "commit_name": "-> Solve issue \ud83d\udca1:"}
{"code": "name: [pm-utils, tlp, powertop, xset, cpufreqd ]", "label": 1, "commit_name": "Add a slew of additional packages that were missed after provisioning my l203ma"}
{"code": "name: [pm-utils, tlp, powertop, xset, cpufreqd, acpi ]", "label": 0, "commit_name": "Add a slew of additional packages that were missed after provisioning my l203ma"}
{"code": "source: https://aaphub-server-1.redhat.local/api/galaxy/content/published/ source: https://aaphub-server-1.redhat.local/api/galaxy/content/published/", "label": 1, "commit_name": "Fix collections/requirements.yml"}
{"code": "source: https://aaphub-demo-1.apps.ocp4cluster.ocp4.cfernand.com/api/galaxy/content/published/ source: https://aaphub-demo-1.apps.ocp4cluster.ocp4.cfernand.com/api/galaxy/content/published/", "label": 0, "commit_name": "Fix collections/requirements.yml"}
{"code": "state: present", "label": 1, "commit_name": "check if parcellite directory conf exists"}
{"code": "- name: check parcellite conf folder exists stat: path: \"/home/{{ user }}/.config/parcellite/\" register: parcellite_conf_folder - name: create parcellite conf folder if not exists file: path: \"/home/{{ user }}/.config/parcellite/\" state: directory when: not parcellite_conf_folder.stat.exists state: present", "label": 0, "commit_name": "check if parcellite directory conf exists"}
{"code": "- name: remove pkg conflicts for powerline fonts become: true community.general.pacman: name: - powerline-fonts state: absent - default_browser: /usr/bin/librewolf - texlive-most # latex generator dep for vim-latex-live-preview - name: ensure no .zshrc file exists ansible.builtin.file: path: ~/.zshrc state: absent - name: overwrite current shell_rc with skeleton, original version become: true ansible.builtin.copy: backup: true force: true remote_src: true src: '/etc/skel/{{ item }}' dest: '~/{{ item }}' owner: '{{ ansible_user }}' group: '{{ ansible_user }}' mode: '0644' loop: - .bashrc marker: \"# {mark} shell_rc\" block: \"{{ lookup('file', '../files/shell_rc') }}\" - .bashrc - name: copy custom shell_rc to root force: true - .bashrc - name: download/install (neo)vim plugins changed_when: true - name: === .profile block === - name: template ~/.profile path: ~/.profile create: true state: present mode: '0644' export browser={{ default_browser }} block: | [default applications] text/html={{ default_browser }} x-scheme-handler/http={{ default_browser }} x-scheme-handler/https={{ default_browser }} x-scheme-handler/ftp={{ default_browser }} x-scheme-handler/chrome={{ default_browser }} application/x-extension-htm={{ default_browser }} application/x-extension-html={{ default_browser }} application/x-extension-shtml={{ default_browser }} application/xhtml+xml={{ default_browser }} application/x-extension-xhtml={{ default_browser }} application/x-extension-xht={{ default_browser }} image/jpeg={{ default_browser }} image/png={{ default_browser }}", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "- default_browser_name: librewolf - default_browser_fullpath: /usr/bin/{{ default_browser_name }} - python - python-pip - python-setuptools - zsh-completions # zsh command completions - zsh-syntax-highlighting # zsh syntax highlighting - zsh-autosuggestions # finish commands from history - zsh-history-substring-search # autosearch via history - grml-zsh-config # zsh config used in archiso (liveboot iso) - pkgfile # command not found - zoxide # smarter cd - fzf # fuzzy finder - ripgrep # fast, recursive grep searcher - fd # faster `find` command - socat # dep for powerline - xorg-xrandr # dep for powerline - ansible-lint # linter for ansible # - texlive-most # latex generator dep for vim-latex-live-preview # https://wiki.archlinux.org/title/powerline # https://powerline.readthedocs.io/en/master/installation.html - pygit2 # soft dep for powerline marker: \"# {mark} zsh_rc\" block: \"{{ lookup('file', '../files/zsh_rc') }}\" # - .bashrc - name: copy custom zsh_rc to root # - .bashrc - name: build pkgfile cache (first time only) become: true ansible.builtin.command: cmd: pkgfile --update creates: /var/cache/pkgfile/core.files - name: === spaceship prompt block === block: - name: copy spaceship config ansible.builtin.copy: remote_src: false src: files/spaceship_rc dest: ~/.spaceshiprc.zsh force: true mode: '0644' - name: check if the plugins folder is empty changed_when: false ansible.builtin.find: file_type: any paths: ~/.vim/plugged/ register: plugin_files - name: download/install (neo)vim plugins (first time only) when: plugin_files.matched <= 0 scrolling: # how many lines of scrollback to keep, # '0' will disable scrolling. history: 10000 # number of lines the viewport will move for every line # scrolled when scrollback is enabled (history > 0). multiplier: 3 # faux scrolling # # the `faux_multiplier` setting controls the number # of lines the terminal should scroll when the alternate # screen buffer is active. this is used to allow mouse # scrolling for applications like `man`. # # to disable this completely, set `faux_multiplier` to 0. faux_multiplier: 3 - name: === /etc/environment block === - name: template /etc/environment become: true path: /etc/environment marker: '# {mark} environment_config' export browser={{ default_browser_fullpath }} create: true state: present mode: '0644' owner: root group: root # https://stackoverflow.com/a/64850938 marker: '# {mark} mimeapps_list_config' block: | [default applications] text/html={{ default_browser_name }}.desktop x-scheme-handler/http={{ default_browser_name }}.desktop x-scheme-handler/https={{ default_browser_name }}.desktop x-scheme-handler/ftp={{ default_browser_name }}.desktop x-scheme-handler/chrome={{ default_browser_name }}.desktop application/x-extension-htm={{ default_browser_name }}.desktop application/x-extension-html={{ default_browser_name }}.desktop application/x-extension-shtml={{ default_browser_name }}.desktop application/xhtml+xml={{ default_browser_name }}.desktop application/x-extension-xhtml={{ default_browser_name }}.desktop application/x-extension-xht={{ default_browser_name }}.desktop image/jpeg={{ default_browser_name }}.desktop image/png={{ default_browser_name }}.desktop", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "state: \"{{ 'present' if terraform.eks.cluster.create == 'true' else 'absent' }}\" # variables: # cluster_name: \"{{ terraform.eks.cluster_name }}\" # cluster_version: \"{{ terraform.eks.cluster_version}}\" # cluster_vpc_id: \"{{ terraform.eks.cluster_vpc_id }}\" # cluster_subnet_ids: \"{{ terraform.eks.cluster_subnet_ids | to_json }}\"", "label": 1, "commit_name": "refactor"}
{"code": "state: \"{{ 'present' if terraform.eks.cluster.create == true else 'absent' }}\"", "label": 0, "commit_name": "refactor"}
{"code": "user: '{{ item.0.username }}'", "label": 1, "commit_name": "Add full support of authorized keys module"}
{"code": "comment: '{{ item.1.comment | default(omit) }}' exclusive: '{{ item.1.exclusive | default(omit) }}' key_options: '{{ item.1.key_options | default(omit) }}' manage_dir: '{{ item.1.manage_dir | default(omit) }}' path: '{{ item.1.path | default(omit) }}' user: '{{ item.0.name }}' validate_certs: '{{ item.1.validate_certs | default(omit) }}'", "label": 0, "commit_name": "Add full support of authorized keys module"}
{"code": "register: firewalld_tcp80_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_tcp80_exists.rc != 0 register: iptables_tcp5666_exists failed_when: iptables_tcp5666_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_tcp5666_exists.stdout|int == 0", "label": 1, "commit_name": "Many fixes here:"}
{"code": "register: firewalld_nrpe_tcp_port_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_nrpe_tcp_port_exists.rc != 0 register: iptables_nrpe_tcp_port_exists failed_when: iptables_nrpe_tcp_port_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_nrpe_tcp_port_exists.stdout|int == 0", "label": 0, "commit_name": "Many fixes here:"}
{"code": "tags: postgres - name: create postgresql db 'metastore' sudo: true sudo_user: postgres postgresql_db: name=metastore tags: - postgres - hive - name: add postgresql user 'hiveuser' sudo: true sudo_user: postgres postgresql_user: db=metastore name=hiveuser password=hive_{{ site_name }} priv=connect tags: - postgres - hive - name: init hive metastore schema sudo: true sudo_user: postgres shell: psql --dbname=metastore --file=/usr/lib/hive/scripts/metastore/upgrade/postgres/hive-schema-0.10.0.postgres.sql tags: - postgres - hive - name: grant postgresql user 'hiveuser' sudo: true sudo_user: postgres shell: psql --dbname=metastore --command=\"grant all on all tables in schema public to hiveuser;\" tags: - postgres - hive", "label": 1, "commit_name": "Fix postgres script. [ci skip]"}
{"code": "tags: postgres", "label": 0, "commit_name": "Fix postgres script. [ci skip]"}
{"code": "with_items: groups.monitoring with_items: groups.lbservers with_items: groups.lbservers with_items: groups.monitoring", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "with_items: \"{{ groups.monitoring }}\" with_items: \"{{ groups.lbservers }}\" with_items: \"{{ groups.lbservers }}\" with_items: \"{{ groups.monitoring }}\"", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "- hosts: all - web - web - web", "label": 1, "commit_name": "Add README, update test setup and fix the Apache handlers (for realsies)."}
{"code": "- hosts: aegir2 - aegir2", "label": 0, "commit_name": "Add README, update test setup and fix the Apache handlers (for realsies)."}
{"code": "dependencies: - role: monitoring-tools - role: firewall", "label": 1, "commit_name": "Remove role's dependencies to avoid reexecuting these roles all the time"}
{"code": "dependencies: []", "label": 0, "commit_name": "Remove role's dependencies to avoid reexecuting these roles all the time"}
{"code": "- app-crypt/cfssl url: \"{{ sslconfig['url'] }}\"", "label": 1, "commit_name": "module: fix dict issues on laprassl module"}
{"code": "- dev-python/requests url: \"https://{{ sslconfig['url'] }}\"", "label": 0, "commit_name": "module: fix dict issues on laprassl module"}
{"code": "- name: start supervisor supervisorctl: name={{ application_name }} state=started", "label": 1, "commit_name": "Updated README, change start supervisor to restart supervisor as supervisor throws an error if it's already started."}
{"code": "- name: restart supervisor supervisorctl: name={{ application_name }} state=restarted", "label": 0, "commit_name": "Updated README, change start supervisor to restart supervisor as supervisor throws an error if it's already started."}
{"code": "- lvm_volumes is defined - devices is defined", "label": 1, "commit_name": "lvm: fix condition when selecting which scenario to run"}
{"code": "- lvm_volumes|length > 0 - devices|length > 0", "label": 0, "commit_name": "lvm: fix condition when selecting which scenario to run"}
{"code": "- { role: security, tags: ['security'] }", "label": 1, "commit_name": "Remove \"security\" tag."}
{"code": "- security", "label": 0, "commit_name": "Remove \"security\" tag."}
{"code": "- name: debug apt update debug: var=debug.stdout_lines debug: var=debug2.stdout_lines", "label": 1, "commit_name": "fix modules"}
{"code": "debug: var=debug.stdout_lines - name: debug nginx status debug: var=debug2", "label": 0, "commit_name": "fix modules"}
{"code": "root_ca_name: \"{{ input_bootstrap_ssl_files_root_ca.cn | replace(' ', '-') }}\" root_ca_path: \"{{ input_bootstrap_ssl_files_base_path }}/{{ input_bootstrap_ssl_files_root_ca.cn | replace(' ', '-') }}\" loop: \"{{ input_bootstrap_ssl_files_intermediates_ca }}\" loop: \"{{ input_bootstrap_ssl_files_end_certs }}\"", "label": 1, "commit_name": "fix CI"}
{"code": "root_ca_name: \"{{ input_bootstrap_ssl_files__root_ca.cn | replace(' ', '-') }}\" root_ca_path: \"{{ input_bootstrap_ssl_files__base_path }}/{{ input_bootstrap_ssl_files__root_ca.cn | replace(' ', '-') }}\" loop: \"{{ input_bootstrap_ssl_files__intermediates_ca }}\" loop: \"{{ input_bootstrap_ssl_files__end_certs }}\"", "label": 0, "commit_name": "fix CI"}
{"code": "name: \"{{ item }}\" with_items: \"{{ motion_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ motion_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "- name: ensure gunicorn is installed", "label": 1, "commit_name": "Updated README, change start supervisor to restart supervisor as supervisor throws an error if it's already started."}
{"code": "- name: ensure gunicorn is installed", "label": 0, "commit_name": "Updated README, change start supervisor to restart supervisor as supervisor throws an error if it's already started."}
{"code": "name: ['unzip', 'tar', 'wget']", "label": 1, "commit_name": "Fix bugs"}
{"code": "name: ['unzip', 'tar', 'wget','libgtk-2_0-0']", "label": 0, "commit_name": "Fix bugs"}
{"code": "molecule_test_debian_12: <<: *molecule_test variables: scenario: \"cicd-debian-12\" rules: - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' molecule_test_ubuntu_22: scenario: \"cicd-ubuntu-22\" allow_failure: true molecule_test_debian_11: <<: *molecule_test variables: scenario: \"cicd-debian-11\" allow_failure: true rules: - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' - \"molecule_test_debian_12\"", "label": 1, "commit_name": "fix CI"}
{"code": "#molecule_test_debian_12: # <<: *molecule_test # variables: # scenario: \"cicd-debian-12\" # rules: # - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' molecule_test_docker_dind: scenario: \"cicd-docker-dind\" #molecule_test_ubuntu_22: # <<: *molecule_test # variables: # scenario: \"cicd-ubuntu-22\" # allow_failure: true # rules: # - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' #molecule_test_debian_11: # <<: *molecule_test # variables: # scenario: \"cicd-debian-11\" # allow_failure: true # rules: # - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' - \"molecule_test_docker_dind\"", "label": 0, "commit_name": "fix CI"}
{"code": "# todo: completely rewrite the documentation. the data structures and order of # execution have changed, and it is less that i schedule the creation of kvm # guests, and more that i ensure the kvm guests exist as desired. # ======== # ensure that a unique instance of each kvm guest in a list of domains exists # -- with parameters as specified in the ansible inventory -- on some kvm host # in the list of domains. for each guest that does not yet exist, schedule the # host that currently offers the most memory to create the guest that requests # the most memory. # the ansible inventory _may_ assign a string to the `domain` variable for a # machine. the call # in the root of the ansible directory tree executes this ansible playbook on # each machine in the ansible directory that has a value for the `domain` # variable such that the value is one of `\u00abdomain\u2081\u00bb` ... `\u00abdomain\u2099\u00bb`. call a # machine with such a `domain` value *selected*. # each selected kvm guests _must_ have the ansible inventory parameters # * `\u00absocket_count\u00bb` specifies the number of cpu sockets the guest has, # * `\u00abcore_count\u00bb` specifies the number of cores per socket the guest has, # * `\u00abthread_count\u00bb` specifies the number of threads per core the guest has, # * `\u00abram\u00bb` specifies the ram the guest has (in mib), and # * `\u00abbacking_path\u00bb` specifies a path to the backing file-sytem image of the # guest # as understood by the `kvm_tool create machine` command (see the # [_kvm.kvm_tool_ git # repository](https://levigo.de/stash/projects/lc/repos/kvm.kvm_tool/)). # connections: \u00abconnections\u00bb # * `\u00abconnections\u00bb` specifies the list of the network connections of the # guest as understood by the `-c` option of the `kvm_tool create machine` # command, and # * `\u00abstate\u00bb` specifies the state of the guest, either `shut off`, `running` # or `paused` (the guest has state `shut off` if the parameter is not set). # * `\u00abautostart\u00bb` is true iff the the guest is marked for autostart (the # guest is not marked if the parameter is not set). # memory requests and offers # -------------------------- # guest creation schedule # ----------------------- # hosts to create selected kvm guests that do not yet exist. # on each existent selected kvm host, record in the host fact `state` the # result of running a shell script that tries to write the yaml # --- # host: # memtotal: '\u00abmemtotal\u00bb' # memavailable: '\u00abmemavailable\u00bb' # guests: # \u00abguest_name\u2081\u00bb: # domain_socket_count: '\u00abdomain_socket_count\u2081\u00bb' # domain_core_count: '\u00abdomain_core_count\u2081\u00bb' # domain_thread_count: '\u00abdomain_thread_count\u2081\u00bb' # domain_ram: '\u00abdomain_ram\u2081\u00bb' # domain_ram_unit: '\u00abdomain_ram_unit\u2081\u00bb' # domain_ram_kib: '\u00abdomain_ram_kib\u2081\u00bb' # domain_state '\u00abdomain_state\u2081\u00bb' # domain_autostart: '\u00abdomain_autostart\u2081\u00bb' # volume_path: '\u00abvolume_path\u2081\u00bb' # volume_backing_path: '\u00abvolume_backing_path\u2081\u00bb' # \u22ee # \u00abguest_name\u2098\u00bb: # domain_socket_count: '\u00abdomain_socket_count\u2098\u00bb' # domain_core_count: '\u00abdomain_core_count\u2098\u00bb' # domain_thread_count: '\u00abdomain_thread_count\u2098\u00bb' # domain_ram: '\u00abdomain_ram\u2098\u00bb' # domain_ram_unit: '\u00abdomain_ram_unit\u2098\u00bb' # domain_ram_kib: '\u00abdomain_ram_kib\u2098\u00bb' # domain_state '\u00abdomain_state\u2098\u00bb' # domain_autostart: '\u00abdomain_autostart\u2098\u00bb' # volume_path: '\u00abvolume_path\u2098\u00bb' # volume_backing_path: '\u00abvolume_backing_path\u2098\u00bb' # ... # \u00abmemtotal\u00bb is the total amount of physical ram the host has (in kib),\u2020 # # \u00abmemavailable\u00bb is an estimate of how much memory is available to the host # for starting new applications without swapping (in kib),\u2020 # \u00abguest_name\u2081\u00bb, \u2026 , \u00abguest_name\u2098\u00bb are the libvirt names of the kvm guests # (not necessarily selected) of the host, and # for each \u00abguest_name\u1d64\u00bb in \u00abguest_name\u2081\u00bb, ..., \u00abguest_name\u2098\u00bb, # \u00abdomain_socket_count\u1d64\u00bb is the number of cpu sockets \u00abguest_name\u1d64\u00bb has, # \u00abdomain_core_count\u1d64\u00bb is the number of cores per socket \u00abguest_name\u1d64\u00bb # has, # \u00abdomain_thread_count\u1d64\u00bb is the number of threads per core \u00abguest_name\u1d64\u00bb # \u00abdomain_ram\u1d64\u00bb is the ram \u00abguest_name\u1d64\u00bb has (in \u00abdomain_ram_unit\u1d64\u00bb), # \u00abdomain_ram_kib\u1d64\u00bb is the ram \u00abguest_name\u1d64\u00bb has (in kib) if # \u00abdomain_ram_unit\u1d64\u00bb is kib, mib, gib or tib, the empty string otherwise, # \u00abdomain_state\u1d64\u00bb is the state of \u00abguest_name\u1d64\u00bb, # \u00abdomain_autostart\u1d64\u00bb is true iff \u00abguest_name\u1d64\u00bb is configured to be # automatically started at boot, # \u00abvolume_path\u1d64\u00bb is the file-system path of the storage volume of # \u00abguest_name\u1d64\u00bb, and # \u00abvolume_backing_path\u1d64\u00bb is the file-system path of the backing storage # volume of the storage volume. # # \u2020: these values are extracted from the `/proc/meminfo` file of the host. # notice that, while the values are given as kilobytes in `/proc/meminfo`, # they are in fact kibibytes -- see [proc: meminfo: replace kb with kib in - name: \"capture the state of each selected kvm host and each of its kvm guests as yaml\" \"memavailable:\"*) line=\"${line#memavailable: }\" prefix=\"${line%%[^ ]*}\" ; line=\"${line#${prefix}}\" ; line=\"${line% kb}\" ; echo \" memavailable: '${line}'\" ; ;; - name: \"schedule the creation of each non-existent selected kvm guest\" # on the local host, construct a data structure `kvm` of the form # \u23a7 \u23a7 \u23a7 \u23a7 'memtotal': \u00abmemtotal\u2081\u00bb \u23ab \u23ab \u23ab \u23ab # \u23aa \u23aa \u23aa 'state': \u23a8 \u23ac \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23a9 'memavailable': \u00abmemavailable\u2081\u00bb \u23ad \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23a7 \u23a7 \u23a7 'domain_socket_count': \u00abdomain_socket_count\u2081\u208a\u2081\u00bb \u23ab \u23ab \u23ab \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_core_count': \u00abdomain_core_count\u2081\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_thread_count': \u00abdomain_thread_count\u2081\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram': \u00abdomain_ram\u2081\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u00abguest_name\u2081\u208a\u2081\u00bb: \u23a8 'state': \u23a8 'domain_ram_unit': \u00abdomain_ram_unit\u2081\u208a\u2081\u00bb \u23ac \u23ac \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram_kib': \u00abdomain_ram_kib\u2081\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_state': \u00abdomain_state\u2081\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_autostart': \u00abdomain_autostart\u2081\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u00abhost_name\u2081\u00bb: \u23a8 \u23aa \u23aa \u23aa 'volume_path': \u00abvolume_path\u2081\u208a\u2081\u00bb \u23aa \u23aa \u23ac \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23a9 \u23a9 'volume_backing_path': \u00abvolume_backing_path\u2081\u208a\u2081\u00bb \u23ad \u23ad \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa 'guests': \u23a8 \u22ee \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23a7 \u23a7 'domain_socket_count': \u00abdomain_socket_count\u2081\u208a\u2092\u208d\u2081\u208e\u00bb \u23ab \u23ab \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_core_count': \u00abdomain_core_count\u2081\u208a\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_thread_count': \u00abdomain_thread_count\u2081\u208a\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram': \u00abdomain_ram\u2081\u208a\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u00abguest_name\u2081\u208a\u2092\u208d\u2081\u208e\u00bb: \u23a8 'state': \u23a8 'domain_ram_unit': \u00abdomain_ram_unit\u2081\u208a\u2092\u208d\u2081\u208e\u00bb \u23ac \u23ac \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram_kib': \u00abdomain_ram_kib\u2081\u208a\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_state': \u00abdomain_state\u2081\u208a\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_autostart': \u00abdomain_autostart\u2081\u208a\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'volume_path': \u00abvolume_path\u2081\u208a\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23a9 \u23a9 \u23a9 \u23a9 'volume_backing_path': \u00abvolume_backing_path\u2081\u208a\u2092\u208d\u2081\u208e\u00bb \u23ad \u23ad \u23ad \u23ad \u23aa \u23aa # \u23aa 'hosts': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23aa \u23a7 \u23a7 'memtotal': \u00abmemtotal\u2098\u00bb \u23ab \u23ab \u23aa \u23aa # \u23aa \u23aa \u23aa 'state': \u23a8 \u23ac \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23a9 'memavailable': \u00abmemavailable\u2098\u00bb \u23ad \u23aa \u23aa \u23aa # 'kvm': \u23a8 \u23aa \u23aa \u23aa \u23aa \u23ac # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23a7 \u23a7 \u23a7 'domain_socket_count': \u00abdomain_socket_count\u2098\u208a\u2081\u00bb \u23ab \u23ab \u23ab \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_core_count': \u00abdomain_core_count\u2098\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_thread_count': \u00abdomain_thread_count\u2098\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram': \u00abdomain_ram\u2098\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u00abguest_name\u2098\u208a\u2081\u00bb: \u23a8 'state': \u23a8 'domain_ram_unit': \u00abdomain_ram_unit\u2098\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram_kib': \u00abdomain_ram_kib\u2098\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_state': \u00abdomain_state\u2098\u208a\u2081\u00bb \u23ac \u23ac \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_autostart': \u00abdomain_autostart\u2098\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u00abhost_name\u2098\u00bb: \u23a8 \u23aa \u23aa \u23aa 'volume_path': \u00abvolume_path\u2098\u208a\u2081\u00bb \u23aa \u23aa \u23aa \u23ac \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23a9 \u23a9 'volume_backing_path': \u00abvolume_backing_path\u2098\u208a\u2081\u00bb \u23ad \u23ad \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa 'guests': \u23a8 \u22ee \u23ac \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23a7 \u23a7 'domain_socket_count': \u00abdomain_socket_count\u2098\u208a\u2092\u208d\u2098\u208e\u00bb \u23ab \u23ab \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_core_count': \u00abdomain_core_count\u2098\u208a\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_thread_count': \u00abdomain_thread_count\u2098\u208a\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram': \u00abdomain_ram\u2098\u208a\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u00abguest_name\u2098\u208a\u2092\u208d\u2098\u208e\u00bb: \u23a8 'state': \u23a8 'domain_ram_unit': \u00abdomain_ram_unit\u2098\u208a\u2092\u208d\u2098\u208e\u00bb \u23ac \u23ac \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram_kib': \u00abdomain_ram_kib\u2098\u208a\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_state': \u00abdomain_state\u2098\u208a\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_autostart': \u00abdomain_autostart\u2098\u208a\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'volume_path': \u00abvolume_path\u2098\u208a\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23a9 \u23a9 \u23a9 \u23a9 \u23a9 'volume_backing_path': \u00abvolume_backing_path\u2098\u208a\u2092\u208d\u2098\u208e\u00bb \u23ad \u23ad \u23ad \u23ad \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abguest_name\u2081\u00bb:\uff5b 'hosts': \uff3b \u00abhost_name\u2081\u208a\u2081\u00bb, \u2026 , \u00abhost_name\u2081\u208a\u209a\u208d\u2081\u208e\u00bb \uff3d\uff5d\u23ab \u23aa # \u23aa 'guests': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abguest_name\u2099\u00bb:\uff5b 'hosts': \uff3b \u00abhost_name\u2099\u208a\u2081\u00bb, \u2026 , \u00abhost_name\u2099\u208a\u209a\u208d\u2099\u208e\u00bb \uff3d\uff5d\u23ad \u23aa # \u23aa \u23aa # \u23aa 'failure': \u00abfailure\u00bb \u23aa # \u23aa \u23aa # \u23a9 'report': \u00abreport\u00bb \u23ad # \u00abhost_name\u2081\u00bb, ..., \u00abhost_name\u2098\u00bb are the names of the existent selected # kvm hosts;\u2020 # for each \u00abhost_name\u1d64\u00bb in \u00abhost_name\u2081\u00bb, ..., \u00abhost_name\u2098\u00bb, # \u00abmemtotal\u1d64\u00bb is the total amount of physical ram \u00abhost_name\u1d64\u00bb has (in # kib), # \u00abmemavailable\u1d64\u00bb is an estimate of how much memory is available to # \u00abhost_name\u1d64\u00bb for starting new applications without swapping (in kib), # \u00abguest_name\u1d64\u208a\u2081\u00bb, ..., \u00abguest_name\u1d64\u208a\u2092\u208d\u1d64\u208e\u00bb are the names of the kvm # guests (not necessarily selected) of \u00abhost_name\u1d64\u00bb, and # for each \u00abguest_name\u1d64\u208a\u1d65\u00bb in \u00abguest_name\u1d64\u208a\u2081\u00bb, ..., \u00abguest_name\u1d64\u208a\u2092\u208d\u1d64\u208e\u00bb, # \u00abdomain_socket_count\u1d64\u208a\u1d65\u00bb is the number of cpu sockets \u00abguest_name\u1d64\u208a\u1d65\u00bb # has, # \u00abdomain_core_count\u1d64\u208a\u1d65\u00bb is the number of cores per socket # \u00abguest_name\u1d64\u208a\u1d65\u00bb has, # \u00abdomain_thread_count\u1d64\u208a\u1d65\u00bb is the number of threads per core # \u00abguest_name\u1d64\u208a\u1d65\u00bb has, # \u00abdomain_ram\u1d64\u208a\u1d65\u00bb is the ram \u00abguest_name\u1d64\u208a\u1d65\u00bb has (in # \u00abdomain_ram_unit\u1d64\u208a\u1d65\u00bb), # \u00abdomain_ram_kib\u1d64\u208a\u1d65\u00bb is the ram \u00abguest_name\u1d64\u208a\u1d65\u00bb has (in kib) if # \u00abdomain_ram_unit\u1d64\u208a\u1d65\u00bb is kib, mib, gib or tib, the empty string # otherwise, # \u00abdomain_state\u1d64\u208a\u1d65\u00bb is the state of \u00abguest_name\u1d64\u208a\u1d65\u00bb, # \u00abdomain_autostart\u1d64\u208a\u1d65\u00bb is true iff \u00abguest_name\u1d64\u208a\u1d65\u00bb is configured to be # automatically started at boot, # \u00abvolume_path\u1d64\u208a\u1d65\u00bb is the file-system path of the storage volume of # \u00abguest_name\u1d64\u208a\u1d65\u00bb, and # \u00abvolume_backing_path\u1d64\u208a\u1d65\u00bb is the file-system path of the backing # storage volume of the storage volume. # \u00abguest_name\u2081\u00bb, ..., \u00abguest_name\u2099\u00bb are the names of the kvm guests (not # necessarily selected) of some selected kvm host; # for each \u00abguest_name\u1d64\u00bb in \u00abguest_name\u2081\u00bb, ..., \u00abguest_name\u2099\u00bb, # # \u00abhost_name\u1d64\u208a\u2081\u00bb, ..., \u00abhost_name\u1d64\u208a\u209a\u208d\u1d64\u208e\u00bb are the names of the selected # kvm hosts that host a kvm guest with name \u00abguest_name\u1d64\u00bb; # # \u00abfailure\u00bb is true iff two or more selected kvm hosts each have a selected # kvm guest such that the guests have the same name, indicated by a # selected guest in kvm['guests'] having a `hosts` list with more than one # item; and # # \u00abreport\u00bb is a string that reports instances of two or more selected kvm # hosts each having a selected kvm guest such that the guests have the same # name. # # note, even though `kvm` may contain data about unselected guests (we use # this information later), only selected guests can cause a failure here -- a # schedule of selected kvm guest creation can proceed even if unselected kvm # guests have conflicting names. # \u2020: extracted from the kvm state information that each existent selected kvm # host wrote to its `state` fact during the previous play. # on the local host, construct a data structure `inv` of the form # \u23a7 \u23a7 \u23a7 \u23a7 'socket_count': \u00absocket_count\u2081\u00bb \u23ab \u23ab \u23ab \u23ab # \u23aa \u23aa \u23aa \u23aa 'core_count': \u00abcore_count\u2081\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'thread_count': \u00abthread_count\u2081\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u00abguest_name\u2081\u00bb: \u23a8 'parameters': \u23a8 'ram': \u00abram\u2081\u00bb \u23ac \u23ac \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'backing_path': \u00abbacking_path\u2081\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'connections': \u00abconnections\u2081\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23a9 \u23a9 'state': \u00abstate\u2081\u00bb \u23ad \u23ad \u23aa \u23aa # \u23aa 'guests': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23aa \u23a7 \u23a7 'socket_count': \u00absocket_count\u2098\u00bb \u23ab \u23ab \u23aa \u23aa # 'inv': \u23a8 \u23aa \u23aa \u23aa 'core_count': \u00abcore_count\u2098\u00bb \u23aa \u23aa \u23aa \u23ac # \u23aa \u23aa \u23aa \u23aa 'thread_count': \u00abthread_count\u2098\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u00abguest_name\u2098\u00bb: \u23a8 'parameters': \u23a8 'ram': \u00abram\u2098\u00bb \u23ac \u23ac \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'backing_path': \u00abbacking_path\u2098\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'connections': \u00abconnections\u2098\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23a9 \u23a9 \u23a9 'state': \u00abstate\u2098\u00bb \u23ad \u23ad \u23ad \u23aa # \u23aa \u23aa # \u23aa 'failure': \u00abfailure\u00bb \u23ab \u23aa # \u23aa \u23ac \u23aa # \u23a9 'report': \u00abreport\u00bb \u23ad \u23ad # \u00abguest_name\u2081\u00bb, ..., \u00abguest_name\u2098\u00bb are the names of the selected kvm # guests;\u2020 # for each \u00abguest_name\u1d64\u00bb in \u00abguest_name\u2081\u00bb, ..., \u00abguest_name\u2098\u00bb, # \u00absocket_count\u1d64\u00bb specifies the number of cpu sockets of \u00abguest_name\u1d64\u00bb, # \u00abcore_count\u1d64\u00bb specifies the number of cores per socket of # \u00abguest_name\u1d64\u00bb, # \u00abthread_count\u1d64\u00bb specifies the number of threads per core of # \u00abguest_name\u1d64\u00bb, # \u00abram\u1d64\u00bb specifies the ram of \u00abguest_name\u1d64\u00bb (in mib), # \u00abbacking_path\u1d64\u00bb specifies a path to the backing file-sytem image of # \u00abguest_name\u1d64\u00bb, # \u00abconnections\u1d64\u00bb specifies the list of the network connections of # \u00abguest_name\u1d64\u00bb, and # \u00abstate\u1d64\u00bb is the state of \u00abguest_name\u1d64\u00bb;\u2020 # \u00abfailure\u00bb is true iff some selected kvm host has some selected kvm guest # such that the actual state of the guest differs from the ansible # inventory parameters for the guest, indicated by a difference between the # relevant componenents of the `kvm` and `inv` data structures; and # # \u00abreport\u00bb is a string that reports instances of some selected kvm host # having some selected kvm guest such that the actual state of the guest # differs from the ansible inventory parameters for the guest. # # \u2020: these values are extracted from the ansible inventory. - name: \"ensure that the parameters and state of each selected kvm guest of each selected kvm host agree\" # on the localhost, construct a data structure `sch` of the initial form # \u23a7 'host_mem': host_mem \u23ab # \u23aa \u23aa # \u23aa 'qemu_mem': qemu_mem \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abhost_name\u2081\u00bb: offer(\u00abhost\u2081_name\u00bb) \u23ab \u23aa # \u23aa 'host_offers': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abhost_name\u2099\u00bb: offer(\u00abhost_name\u2099\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abguest_name\u2081\u00bb: request(\u00abguest_name\u2081\u00bb) \u23ab \u23aa # 'sch': \u23a8 'guest_requests': \u23a8 \u22ee \u23ac \u23ac # \u23aa \u23a9 \u00abguest_name\u2098\u00bb: request(\u00abguest_name\u2098\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u23ab \u23aa # \u23aa 'schedule': \u23a8 \u23ac \u23aa # \u23aa \u23a9 \u23ad \u23aa # \u23aa \u23aa # \u23aa 'failure': false \u23aa # \u23aa \u23aa # \u23a9 'report': '' \u23ad # \u00abhost_name\u2081\u00bb, ..., \u00abhost_name\u2099\u00bb are the names of the existent slected kvm # hosts; # # \u00abguest_name\u2081\u00bb, ..., \u00abguest_name\u2098\u00bb are the names of the non-existent # selected kvm guests; and # host_mem, qemu_mem, request() and offer() are as described above in # \"memory requests and offers\" (in kib). # then, after each assignment following the heuristic described above in # \"guest creation schedule\", update the data structure to the interim form # \u23a7 'host_mem': host_mem \u23ab # \u23aa \u23aa # \u23aa 'qemu_mem': qemu_mem \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abhost_name\u2081\u00bb: offer\u2032(\u00abhost_name\u2081\u00bb) \u23ab \u23aa # \u23aa 'host_offers': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abhost_name\u2099\u00bb: offer\u2032(\u00abhost_name\u2099\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abguest_name\u2081\u00bb: request(\u00abguest_name\u2081\u00bb) \u23ab \u23aa # 'sch': \u23a8 'guest_requests': \u23a8 \u22ee \u23ac \u23ac # \u23aa \u23a9 \u00abguest_name\u2098\u00bb: request(\u00abguest_name\u2098\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abguest_name\u2032\u2081\u00bb: sched(\u00abguest_name\u2032\u2081\u00bb) \u23ab \u23aa # \u23aa 'schedule': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abguest_name\u2032\u2092\u00bb: sched(\u00abguest_name\u2032\u2092\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa 'failure': \u00abfailure\u00bb \u23aa # \u23aa \u23aa # \u23a9 'report': \u00abreport\u00bb \u23ad # for each \u00abhost_name\u00bb in \u00abhost_name\u2081\u00bb, ..., \u00abhost_name\u2099\u00bb, # # offer\u2032(\u00abhost_name\u00bb) is the memory that \u00abhost_name\u00bb can currently offer # to create further kvm guests without itself swapping; # # \u00abguest_name\u2032\u2081\u00bb, ..., \u00abguest_name\u2032\u2092\u00bb are the names of the non-existent # selected kvm guests for whom kvm hosts have been scheduled; # for each \u00abguest_name\u00bb in \u00abguest_name\u2032\u2081\u00bb, ..., \u00abguest_name\u2032\u2092\u00bb, # sched(\u00abguest_name\u00bb) is the name of the kvm host scheduled to create # \u00abguest_host\u00bb; # \u00abfailure\u00bb is true iff a failure as descr9ibed above in \"guest creation # schedule\" has occured; and # # \u00abreport\u00bb is a string that reports the schedule, including failures as # descr9ibed above in \"guest creation schedule\" has occured. # todo: give this task a more appropriate name. - name: \"for each non-existent selected kvm guest, schedule some existent kvm host to create the guest\" #- name: \"display the `sch` data structure\" # debug: # var: \"sch\" - name: \"display a report of the construction of the schedule\" # todo: rename this. - name: \"create each non-existent selected kvm guest on some existent selected kvm host\" # todo: rename this. - name: \"ensure each selected kvm host creates each of its scheduled kvm guests\"", "label": 1, "commit_name": "Update some of the documentation"}
{"code": "# todo: rewrite the documentation. # todo: check that each guest's parameters are set and correctly typed, and be # informative if they are not. # todo: what happens, and what _should_ happen, if a selected host does not # exist? # todo: check that each guest's connection parameters are observed. # -------- # the ansible inventory _may_ assign a string to the `domain` variable of a # machine. say that a list of domains _selects_ a machine iff the inventory # assigns one of the domains in the list to the `domain` variable of the # machine. for any list of domains, this ansible playbook tries to ensure that # a unique instance of each selected kvm guest exists, with parameters as # specified in the ansible inventory, on some selected kvm host. # for each list of domains `\u00abdomain\u2081\u00bb` ... `\u00abdomain\u2099\u00bb`, the call # in the root of the ansible directory tree executes this playbook on each kvm # host and kvm guest selected by the list. each selected kvm guests _must_ # have the ansible inventory parameters # * the natural number `\u00absocket_count\u00bb` is the number of cpu sockets the # guest should have, # * the natural number `\u00abcore_count\u00bb` is the number of cores per socket the # guest should have, # * the natural number `\u00abthread_count\u00bb` is the number of threads per core the # guest should have, # * the natural number `\u00abram\u00bb` is the mib of ram the guest should have, and # * the string `\u00abbacking_path\u00bb` is a file-system path to the backing storage # volume the guest should have. # connections: # - \u00abbridge\u2081\u00bb[,\u00abipv4_address\u2081\u00bb] # - \u22ee # - \u00abbridge\u2099\u00bb[,\u00abipv4_address\u2099\u00bb] # * the string `\u00abbridge\u1d64\u00bb` is the name of an ethernet bridge the guest should # be connected to (not yet used), # # * the optional string `\u00abipv4_address\u1d64\u00bb` is an ipv4 address the guest should # request from the dhcp server on the bridge `\u00abbridge\u1d64\u00bb` by means of a # \"magic\" mac address (see the `kvm_tool get mac address` command call of # https://levigo.de/stash/projects/lc/repos/kvm.kvm_tool) (not yet used), # * the string `\u00abstate\u00bb` is the state the guest should be in, one of `shut # off`, `running` or `paused` (the guest should be in the state `shut off` # if the parameter is not set), and # * the boolean `\u00abautostart\u00bb` is true iff the guest should be marked for # autostart (the guest is not marked for autostart if the parameter is not # set). # guest creation # -------------- # if a selected kvm guest exists on no selected kvm host then this playbook # schedules some selected host to create the guest. loosely speaking, the # playbook schedules the selected host currently offering the most ram to # create the selected guest requesting the most ram. # hosts to create selected, non-existent kvm guests. # on each selected kvm host, record in the host fact `state` the result of # running a shell script that tries to write the yaml # --- # host: # memtotal: '\u00abmemtotal\u00bb' # guests: # \u00abguest_name\u2081\u00bb: # domain_socket_count: '\u00abdomain_socket_count\u2081\u00bb' # domain_core_count: '\u00abdomain_core_count\u2081\u00bb' # domain_thread_count: '\u00abdomain_thread_count\u2081\u00bb' # domain_ram: '\u00abdomain_ram\u2081\u00bb' # domain_ram_unit: '\u00abdomain_ram_unit\u2081\u00bb' # domain_ram_kib: '\u00abdomain_ram_kib\u2081\u00bb' # domain_state '\u00abdomain_state\u2081\u00bb' # domain_autostart: '\u00abdomain_autostart\u2081\u00bb' # volume_path: '\u00abvolume_path\u2081\u00bb' # volume_backing_path: '\u00abvolume_backing_path\u2081\u00bb' # \u22ee # \u00abguest_name\u2098\u00bb: # domain_socket_count: '\u00abdomain_socket_count\u2098\u00bb' # domain_core_count: '\u00abdomain_core_count\u2098\u00bb' # domain_thread_count: '\u00abdomain_thread_count\u2098\u00bb' # domain_ram: '\u00abdomain_ram\u2098\u00bb' # domain_ram_unit: '\u00abdomain_ram_unit\u2098\u00bb' # domain_ram_kib: '\u00abdomain_ram_kib\u2098\u00bb' # domain_state '\u00abdomain_state\u2098\u00bb' # domain_autostart: '\u00abdomain_autostart\u2098\u00bb' # volume_path: '\u00abvolume_path\u2098\u00bb' # volume_backing_path: '\u00abvolume_backing_path\u2098\u00bb' # ... # * `\u00abmemtotal\u00bb` is the kib of ram the host has,\u2020 # * `\u00abguest_name\u2081\u00bb`, \u2026, `\u00abguest_name\u2098\u00bb` are the kvm guests (not necessarily # selected) the host has, # * `\u00abdomain_socket_count\u1d64\u00bb` is the number of cpu sockets `\u00abguest_name\u1d64\u00bb` # has, # * `\u00abdomain_core_count\u1d64\u00bb` is the number of cores per socket # `\u00abguest_name\u1d64\u00bb` has, # * `\u00abdomain_thread_count\u1d64\u00bb` is the number of threads per core # `\u00abguest_name\u1d64\u00bb` has, # * `\u00abdomain_ram\u1d64\u00bb` is the ram (in `\u00abdomain_ram_unit\u1d64\u00bb`) `\u00abguest_name\u1d64\u00bb` # * `\u00abdomain_ram_kib\u1d64\u00bb` is the kib of ram `\u00abguest_name\u1d64\u00bb` has if # `\u00abdomain_ram_unit\u1d64\u00bb` is kib, mib, gib or tib, the empty string # otherwise, # * `\u00abdomain_state\u1d64\u00bb` is the state `\u00abguest_name\u1d64\u00bb` is in, # * `\u00abdomain_autostart\u1d64\u00bb` is true iff `\u00abguest_name\u1d64\u00bb` is marked for # autostart, # * `\u00abvolume_path\u1d64\u00bb` is a file-system path to the running storage volume # `\u00abguest_name\u1d64\u00bb` has, and # * `\u00abvolume_backing_path\u1d64\u00bb` is a file-system path to the backing storage # volume `\u00abguest_name\u1d64\u00bb` has. # \u2020: this value is extracted from the `/proc/meminfo` file of the host. note # that, while the value is given as kilobytes in `/proc/meminfo`, it is in # fact kibibytes -- see [proc: meminfo: replace kb with kib in - name: \"capture the state of each selected kvm host and each of its kvm guests\" - name: \"schedule the creation and configuration of each selected kvm guest\" # on the local host, extract the state information that each selected kvm # host wrote to its `state` fact during the previous play, and construct from # it a data structure `kvm` of the form # \u23a7 \u23a7 \u23a7 'state': \uff5b 'memtotal': \u00abmemtotal\u2081\u00bb \uff5d \u23ab \u23ab \u23ab # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23a7 \u23a7 \u23a7 'domain_socket_count': \u00abdomain_socket_count\u2081_\u2081\u00bb \u23ab \u23ab \u23ab \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_core_count': \u00abdomain_core_count\u2081_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_thread_count': \u00abdomain_thread_count\u2081_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram': \u00abdomain_ram\u2081_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u00abguest_name\u2081_\u2081\u00bb: \u23a8 'state': \u23a8 'domain_ram_unit': \u00abdomain_ram_unit\u2081_\u2081\u00bb \u23ac \u23ac \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram_kib': \u00abdomain_ram_kib\u2081_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_state': \u00abdomain_state\u2081_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_autostart': \u00abdomain_autostart\u2081_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u00abhost_name\u2081\u00bb: \u23a8 \u23aa \u23aa \u23aa 'volume_path': \u00abvolume_path\u2081_\u2081\u00bb \u23aa \u23aa \u23ac \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23a9 \u23a9 'volume_backing_path': \u00abvolume_backing_path\u2081_\u2081\u00bb \u23ad \u23ad \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa 'guests': \u23a8 \u22ee \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23a7 \u23a7 'domain_socket_count': \u00abdomain_socket_count\u2081_\u2092\u208d\u2081\u208e\u00bb \u23ab \u23ab \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_core_count': \u00abdomain_core_count\u2081_\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_thread_count': \u00abdomain_thread_count\u2081_\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram': \u00abdomain_ram\u2081_\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u00abguest_name\u2081_\u2092\u208d\u2081\u208e\u00bb: \u23a8 'state': \u23a8 'domain_ram_unit': \u00abdomain_ram_unit\u2081_\u2092\u208d\u2081\u208e\u00bb \u23ac \u23ac \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram_kib': \u00abdomain_ram_kib\u2081_\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_state': \u00abdomain_state\u2081_\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_autostart': \u00abdomain_autostart\u2081_\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'volume_path': \u00abvolume_path\u2081_\u2092\u208d\u2081\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23a9 \u23a9 \u23a9 \u23a9 'volume_backing_path': \u00abvolume_backing_path\u2081_\u2092\u208d\u2081\u208e\u00bb \u23ad \u23ad \u23ad \u23ad \u23aa \u23aa # \u23aa 'hosts': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23aa \u23a7 'state': \uff5b 'memtotal': \u00abmemtotal\u2098\u00bb \uff5d \u23ab \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23a7 \u23a7 \u23a7 'domain_socket_count': \u00abdomain_socket_count\u2098_\u2081\u00bb \u23ab \u23ab \u23ab \u23aa \u23aa \u23aa # 'kvm': \u23a8 \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_core_count': \u00abdomain_core_count\u2098_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23ac # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_thread_count': \u00abdomain_thread_count\u2098_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram': \u00abdomain_ram\u2098_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u00abguest_name\u2098_\u2081\u00bb: \u23a8 'state': \u23a8 'domain_ram_unit': \u00abdomain_ram_unit\u2098_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram_kib': \u00abdomain_ram_kib\u2098_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_state': \u00abdomain_state\u2098_\u2081\u00bb \u23ac \u23ac \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_autostart': \u00abdomain_autostart\u2098_\u2081\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u00abhost_name\u2098\u00bb: \u23a8 \u23aa \u23aa \u23aa 'volume_path': \u00abvolume_path\u2098_\u2081\u00bb \u23aa \u23aa \u23aa \u23ac \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23a9 \u23a9 'volume_backing_path': \u00abvolume_backing_path\u2098_\u2081\u00bb \u23ad \u23ad \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa 'guests': \u23a8 \u22ee \u23ac \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23a7 \u23a7 'domain_socket_count': \u00abdomain_socket_count\u2098_\u2092\u208d\u2098\u208e\u00bb \u23ab \u23ab \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_core_count': \u00abdomain_core_count\u2098_\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_thread_count': \u00abdomain_thread_count\u2098_\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram': \u00abdomain_ram\u2098_\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u00abguest_name\u2098_\u2092\u208d\u2098\u208e\u00bb: \u23a8 'state': \u23a8 'domain_ram_unit': \u00abdomain_ram_unit\u2098_\u2092\u208d\u2098\u208e\u00bb \u23ac \u23ac \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_ram_kib': \u00abdomain_ram_kib\u2098_\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_state': \u00abdomain_state\u2098_\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'domain_autostart': \u00abdomain_autostart\u2098_\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa 'volume_path': \u00abvolume_path\u2098_\u2092\u208d\u2098\u208e\u00bb \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa # \u23aa \u23a9 \u23a9 \u23a9 \u23a9 \u23a9 'volume_backing_path': \u00abvolume_backing_path\u2098_\u2092\u208d\u2098\u208e\u00bb \u23ad \u23ad \u23ad \u23ad \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abguest_name\u2081\u00bb:\uff5b 'hosts': \uff3b \u00abhost_name\u2081_\u2081\u00bb, \u2026 , \u00abhost_name\u2081_\u209a\u208d\u2081\u208e\u00bb \uff3d\uff5d\u23ab \u23aa # \u23aa 'guests': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abguest_name\u2099\u00bb:\uff5b 'hosts': \uff3b \u00abhost_name\u2099_\u2081\u00bb, \u2026 , \u00abhost_name\u2099_\u209a\u208d\u2099\u208e\u00bb \uff3d\uff5d\u23ad \u23aa # \u23aa \u23aa # \u23aa 'failure': \u00abfailure\u00bb \u23aa # \u23aa \u23aa # \u23a9 'report': \u00abreport\u00bb \u23ad # * `\u00abhost_name\u2081\u00bb`, ..., `\u00abhost_name\u2098\u00bb` are the names of the selected kvm # hosts, # * `\u00abmemtotal\u1d64\u00bb` is the kib of ram `\u00abhost_name\u1d64\u00bb` has, # * `\u00abguest_name\u1d64_\u2081\u00bb`, ..., `\u00abguest_name\u1d64_\u2092\u208d\u1d64\u208e\u00bb` are the kvm guests (not # necessarily selected) `\u00abhost_name\u1d64\u00bb` has, # * `\u00abdomain_socket_count\u1d64_\u1d65\u00bb` is the number of cpu sockets # `\u00abguest_name\u1d64_\u1d65\u00bb` has, # * `\u00abdomain_core_count\u1d64_\u1d65\u00bb` is the number of cores per socket # `\u00abguest_name\u1d64_\u1d65\u00bb` has, # * `\u00abdomain_thread_count\u1d64_\u1d65\u00bb` is the number of threads per core # `\u00abguest_name\u1d64_\u1d65\u00bb` has, # * `\u00abdomain_ram\u1d64_\u1d65\u00bb` is the ram (in `\u00abdomain_ram_unit\u1d64_\u1d65\u00bb`) # `\u00abguest_name\u1d64_\u1d65\u00bb` has, # * `\u00abdomain_ram_kib\u1d64_\u1d65\u00bb` is the kib of ram `\u00abguest_name\u1d64_\u1d65\u00bb` has if # `\u00abdomain_ram_unit\u1d64_\u1d65\u00bb` is kib, mib, gib or tib, the empty string # otherwise, # * `\u00abdomain_state\u1d64_\u1d65\u00bb` is the state `\u00abguest_name\u1d64_\u1d65\u00bb` is in, # * `\u00abdomain_autostart\u1d64_\u1d65\u00bb` is true iff `\u00abguest_name\u1d64_\u1d65\u00bb` is marked for # autostart, # * `\u00abvolume_path\u1d64_\u1d65\u00bb` is a file-system path to the running storage volume # `\u00abguest_name\u1d64_\u1d65\u00bb` has, # * `\u00abvolume_backing_path\u1d64_\u1d65\u00bb` is a file-system path to the backing storage # volume `\u00abguest_name\u1d64_\u1d65\u00bb` has, # * `\u00abguest_name\u2081\u00bb`, ..., `\u00abguest_name\u2099\u00bb` are the kvm guests (not # necessarily selected) some selected kvm host has, # * `\u00abhost_name\u1d64_\u2081\u00bb`, ..., `\u00abhost_name\u1d64_\u209a\u208d\u1d64\u208e\u00bb` are the kvm hosts that have # guest `\u00abguest_name\u1d64\u00bb`, # * `\u00abfailure\u00bb` is true iff two or more kvm hosts each have a selected kvm # guest such that the guests have the same name, indicated by a selected # guest in kvm['guests'] having a `hosts` list with more than one item,\u2020 # and # * `\u00abreport\u00bb` is a string that reports instances of failure. # \u2020: `kvm` may contain data about unselected kvm guests (we use this data # later), but only selected guests can cause a failure here -- the creation # of selected guests can proceed even if unselected guests have conflicting # names. # on the local host, extract the ansible inventory parameters for each # selected kvm guest, and construct from it a data structure `inv` of the # form # \u23a7 \u23a7 \u23a7 \u23a7 'socket_count': \u00absocket_count\u2081\u00bb \u23ab \u23ab \u23ab \u23ab # \u23aa \u23aa \u23aa \u23aa 'core_count': \u00abcore_count\u2081\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'thread_count': \u00abthread_count\u2081\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u00abguest_name\u2081\u00bb: \u23a8 'parameters': \u23a8 'ram': \u00abram\u2081\u00bb \u23ac \u23ac \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'backing_path': \u00abbacking_path\u2081\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'connections': \u00abconnections\u2081\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'state': \u00abstate\u2081\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23a9 \u23a9 'autostart': \u00abautostart\u2081\u00bb \u23ad \u23ad \u23aa \u23aa # \u23aa 'guests': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23aa \u23a7 \u23a7 'socket_count': \u00absocket_count\u2098\u00bb \u23ab \u23ab \u23aa \u23aa # 'inv': \u23a8 \u23aa \u23aa \u23aa 'core_count': \u00abcore_count\u2098\u00bb \u23aa \u23aa \u23aa \u23ac # \u23aa \u23aa \u23aa \u23aa 'thread_count': \u00abthread_count\u2098\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u00abguest_name\u2098\u00bb: \u23a8 'parameters': \u23a8 'ram': \u00abram\u2098\u00bb \u23ac \u23ac \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'backing_path': \u00abbacking_path\u2098\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'connections': \u00abconnections\u2098\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23aa \u23aa \u23aa 'state': \u00abstate\u2098\u00bb \u23aa \u23aa \u23aa \u23aa # \u23aa \u23a9 \u23a9 \u23a9 'autostart': \u00abautostart\u2098\u00bb \u23ad \u23ad \u23ad \u23aa # \u23aa \u23aa # \u23aa 'failure': \u00abfailure\u00bb \u23aa # \u23aa \u23aa # \u23a9 'report': \u00abreport\u00bb \u23ad # * `\u00abguest_name\u2081\u00bb`, ..., `\u00abguest_name\u2098\u00bb` are the names of the selected kvm # guests, # * `\u00absocket_count\u1d64\u00bb` is the number of cpu sockets `\u00abguest_name\u1d64\u00bb` should # have, # * `\u00abcore_count\u1d64\u00bb` is the number of cores per socket `\u00abguest_name\u1d64\u00bb` # should have, # * `\u00abthread_count\u1d64\u00bb` is the number of threads per core `\u00abguest_name\u1d64\u00bb` # shouls have, # * `\u00abram\u1d64\u00bb` is the mib of ram `\u00abguest_name\u1d64\u00bb` should have, # * `\u00abbacking_path\u1d64\u00bb` is a file-system path to the backing storage volume # `\u00abguest_name\u1d64\u00bb` should have, # * `\u00abconnections\u1d64\u00bb` is the list of ethernet bridges `\u00abguest_name\u1d64\u00bb` should # be connected to, # * `\u00abstate\u1d64\u00bb` is the state `\u00abguest_name\u1d64\u00bb` should be in, # * `\u00abfailure\u00bb` is true iff some selected kvm host has some selected kvm # guest such that the actual state of the guest, read from the data # structure `kvm`, differs from the ansible inventory parameters for the # guest, and # * `\u00abreport\u00bb` is a string that reports instances of failure. - name: \"ensure that the parameters and fixed state of each selected kvm guest of each selected kvm host agree\" # on the localhost, first construct a data structure `sch` of the form # \u23a7 'host_mem': host_mem \u23ab # \u23aa \u23aa # \u23aa 'qemu_mem': qemu_mem \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abhost_name\u2081\u00bb: offer(\u00abhost_name\u2081\u00bb) \u23ab \u23aa # \u23aa 'host_offers': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abhost_name\u2098\u00bb: offer(\u00abhost_name\u2098\u00bb) \u23ad \u23aa # \u23aa \u23aa # 'sch': \u23a8 \u23a7 \u00abguest_name\u2081\u00bb: request(\u00abguest_name\u2081\u00bb) \u23ab \u23ac # \u23aa 'guest_requests': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abguest_name\u2099\u00bb: request(\u00abguest_name\u2099\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa 'commands': \uff5b \uff5d \u23aa # \u23aa \u23aa # \u23aa 'failure': false \u23aa # \u23aa \u23aa # \u23a9 'report': '' \u23ad # * `\u00abhost_name\u2081\u00bb`, ..., `\u00abhost_name\u2098\u00bb` are the names of the selected kvm # hosts, # * `\u00abguest_name\u2081\u00bb`, ..., `\u00abguest_name\u2099\u00bb` are the names of the non-existent # selected kvm guests, and # * `host_mem`, `qemu_mem`, `offer` and `request` are as described above in # \"guest creation\" (in kib). # then, after each assignment following the heuristic described above in # \"guest creation\", update the data structure to the form # \u23a7 'host_mem': host_mem \u23ab # \u23aa \u23aa # \u23aa 'qemu_mem': qemu_mem \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abhost_name\u2081\u00bb: offer\u2032(\u00abhost_name\u2081\u00bb) \u23ab \u23aa # \u23aa 'host_offers': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abhost_name\u2098\u00bb: offer\u2032(\u00abhost_name\u2098\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abguest_name\u2081\u00bb: request(\u00abguest_name\u2081\u00bb) \u23ab \u23aa # 'sch': \u23a8 'guest_requests': \u23a8 \u22ee \u23ac \u23ac # \u23aa \u23a9 \u00abguest_name\u2099\u00bb: request(\u00abguest_name\u2099\u00bb) \u23ad \u23aa # \u23aa \u23aa # \u23aa \u23a7 \u00abhost_name\u2081\u00bb: \u00abguest_creation_commands\u2081\u00bb \u23ab \u23aa # \u23aa 'commands': \u23a8 \u22ee \u23ac \u23aa # \u23aa \u23a9 \u00abhost_name\u2098\u00bb: \u00abguest_creation_commands\u2098\u00bb \u23ad \u23aa # \u23aa \u23aa # \u23aa 'failure': \u00abfailure\u00bb \u23aa # \u23aa \u23aa # \u23a9 'report': \u00abreport\u00bb \u23ad # * `offer\u2032(\u00abhost_name\u1d64\u00bb)` is the memory that `\u00abhost_name\u1d64\u00bb can currently # offer to create further kvm guests without itself swapping; # * `\u00abguest_creation_commands\u1d64\u00bb` is a list of commands to create # non-existent selected kvm guests on \u00abhost_name\u1d64\u00bb, # * \u00abfailure\u00bb is true iff a failure as described above in \"guest creation # schedule\" has occured; and # * \u00abreport\u00bb is a string that reports the schedule, including failure, as # described above in \"guest creation\". - name: \"schedule the creation and configuration of each selected kvm guest\" {#- for each host (in alphabetical order), i append its list of commands to the report. -#} {%- for host_name, offer in sch['host_offers'] | dictsort(by='key') -%} {% set _ = sch.update({ 'report': sch['report'] + 'host `' + host_name + ' is scheduled to run the commands\\n' }) -%} {%- for command in sch['commands'][host_name] -%} {% set _ = sch.update({ 'report': sch['report'] + ' ' + command + '\\n' }) -%} {%- endfor -%} {%- endfor -%} - name: \"display the `sch` data structure\" debug: var: \"sch\" - name: \"display the schedule\" - name: \"ensure each selected kvm guest exists and is properly configured on some selected kvm host\" - name: \"ensure each selected kvm guest exists and is properly configured on some selected kvm host\"", "label": 0, "commit_name": "Update some of the documentation"}
{"code": "- /opt/server-ansible/registry-images:/data - \"$registry_auth_file/auth\":/auth", "label": 1, "commit_name": "fix: Fix indention error"}
{"code": "- /opt/server-ansible/registry-images:/data - \"$registry_auth_file/auth\":/auth", "label": 0, "commit_name": "fix: Fix indention error"}
{"code": "shell: /bin/zsh", "label": 1, "commit_name": "fix: move workspace; fix: zsh path; feat: change powerlevel10k config"}
{"code": "shell: /usr/bin/zsh", "label": 0, "commit_name": "fix: move workspace; fix: zsh path; feat: change powerlevel10k config"}
{"code": "vpc_id: \"{{vpcout.vpc.id}}\"", "label": 1, "commit_name": "new code is added to playbook13"}
{"code": "vpc_id: \"{{vpcid}}\"", "label": 0, "commit_name": "new code is added to playbook13"}
{"code": "name: [ lynx, weechat, weechat-python, weechat-perl, weechat-lua, weechat-ruby, weechat-spell, mutt, newsboat, fa, lastpass-cli, neoftech, ranger, aspell, aspell-en ]", "label": 1, "commit_name": "Add a slew of additional packages that were missed after provisioning my l203ma"}
{"code": "name: [ lynx, weechat, weechat-python, weechat-perl, weechat-lua, weechat-ruby, weechat-spell, mutt, newsboat, fa, lastpass-cli, neoftech, ranger, aspell, aspell-en, imagemagick, parted ]", "label": 0, "commit_name": "Add a slew of additional packages that were missed after provisioning my l203ma"}
{"code": "upgrade: true", "label": 1, "commit_name": "fix molecule to work with Vagrant instead of Docker"}
{"code": "# upgrade: true", "label": 0, "commit_name": "fix molecule to work with Vagrant instead of Docker"}
{"code": "#molecule_test_debian_12: # <<: *molecule_test # variables: # scenario: \"cicd-debian-12\" # rules: # - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' molecule_test_docker_dind: scenario: \"cicd-docker-dind\" #molecule_test_ubuntu_22: # <<: *molecule_test # variables: # scenario: \"cicd-ubuntu-22\" # allow_failure: true # rules: # - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' #molecule_test_debian_11: # <<: *molecule_test # variables: # scenario: \"cicd-debian-11\" # allow_failure: true # rules: # - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' - \"molecule_test_docker_dind\"", "label": 1, "commit_name": "force CI"}
{"code": "molecule_test_debian_12: scenario: \"cicd-debian-12\" molecule_test_ubuntu_22: <<: *molecule_test variables: scenario: \"cicd-ubuntu-22\" allow_failure: true rules: - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' molecule_test_debian_11: <<: *molecule_test variables: scenario: \"cicd-debian-11\" allow_failure: true rules: - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' - \"molecule_test_debian_12\"", "label": 0, "commit_name": "force CI"}
{"code": "- --pod-network-cidr=192.168.2.0/24 command: \"{{ item }}\" with_items: - mkdir -p /home/pi/.kube - cp -i /etc/kubernetes/admin.conf /home/pi/.kube/config - chown -r pi:pi /home/pi/.kube shell: kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\"", "label": 1, "commit_name": "Typo in worker kubelet args, install specific version of docker, set daemon params"}
{"code": "register: kubeadm - debug: var: kubeadm.stdout_lines - name: create kube directory for pi user file: path: /home/pi/.kube state: directory owner: pi group: pi mode: '0750' copy: src: /etc/kubernetes/admin.conf dest: /home/pi/.kube/config owner: pi group: pi mode: '0600' remote_src: yes shell: kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\\&env.no_masq_local=1\"", "label": 0, "commit_name": "Typo in worker kubelet args, install specific version of docker, set daemon params"}
{"code": "include_tasks: \"tasks/services/{{ service }}.yml\"", "label": 1, "commit_name": "Fixes"}
{"code": "include_tasks: \"services/{{ service }}.yml\" # fixme: path include_tasks", "label": 0, "commit_name": "Fixes"}
{"code": "url: \"https://{{ inventory_hostname }}:{{ inv_install_elasticsearch__port }}/_cluster/health?wait_for_status=yellow&timeout=50s&pretty\" url: \"https://{{ inventory_hostname }}:{{ inv_install_elasticsearch__port }}/_cluster/health?wait_for_status=yellow&timeout=50s&pretty\" url: \"http://{{ inventory_hostname }}:{{ inv_install_logstash__api_ports }}/\" url: \"https://{{ inventory_hostname }}:{{ inv_install_logstash__api_ports }}/\" url: \"https://{{ inventory_hostname }}:{{ inv_install_logstash__api_ports }}/\" url: \"https://{{ inventory_hostname }}:{{ inv_install_logstash__api_ports }}/\" host: \"{{ inventory_hostname }}\" host: \"{{ inventory_hostname }}\" host: \"{{ inventory_hostname }}\" url: \"http://{{ inventory_hostname }}:{{ inv_add_apache_confs__http_listen_port }}/\" url: \"https://{{ inventory_hostname }}:{{ inv_add_apache_confs__https_listen_port }}/\"", "label": 1, "commit_name": "added prepare and verify"}
{"code": "url: \"https://localhost:{{ inv_install_elasticsearch__port }}/_cluster/health?wait_for_status=yellow&timeout=50s&pretty\" url: \"https://localhost:{{ inv_install_elasticsearch__port }}/_cluster/health?wait_for_status=yellow&timeout=50s&pretty\" url: \"http://localhost:{{ inv_install_logstash__api_ports }}/\" url: \"https://localhost:{{ inv_install_logstash__api_ports }}/\" url: \"https://localhost:{{ inv_install_logstash__api_ports }}/\" url: \"https://localhost:{{ inv_install_logstash__api_ports }}/\" host: \"localhost\" host: \"localhost\" host: \"localhost\" url: \"http://localhost:{{ inv_add_apache_confs__http_listen_port }}/\" url: \"https://localhost:{{ inv_add_apache_confs__https_listen_port }}/\"", "label": 0, "commit_name": "added prepare and verify"}
{"code": "apt: state: latest file: copy:", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.apt: ansible.builtin.file: mode: \"0755\" ansible.builtin.copy:", "label": 0, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.pacman:", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "community.general.pacman:", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "# gitlab_rails['db_host'] = '{{ groups.primary_pgbouncer_internal[0] }}' - import_tasks: tasks/bootstrap/default/reconfigure.yml", "label": 1, "commit_name": "Merge branch 'da-fix-pg-bouncer-host-secondary-node' into 'master'"}
{"code": "# gitlab_rails['db_host'] = '{{ groups.secondary_pgbouncer_internal[0] }}' - import_tasks: tasks/bootstrap/default/reconfigure.yml", "label": 0, "commit_name": "Merge branch 'da-fix-pg-bouncer-host-secondary-node' into 'master'"}
{"code": "tasks:", "label": 1, "commit_name": "fix inventory and skeleton playbook"}
{"code": "tasks:", "label": 0, "commit_name": "fix inventory and skeleton playbook"}
{"code": "nagios_http_port: 80", "label": 1, "commit_name": "Many fixes here:"}
{"code": "nagios_http_port: 8888 # change this to your email address if you want notifications ### elk options ### # if you use my elk playbook you'll need this for http checks # https://github.com/sadsfae/ansible-elk kibana_user: admin kibana_password: admin", "label": 0, "commit_name": "Many fixes here:"}
{"code": "- name: setup idm server:", "label": 1, "commit_name": "fix type in the name"}
{"code": "- name: setup idm server", "label": 0, "commit_name": "fix type in the name"}
{"code": "- hosts: localhost gather_facts: true tasks: - name: disable firewall become: true ufw: state: disabled - name: create tftpd directory for kernel file: path: \"{{ ansible_env.home }}/nos/kernel\" state: directory - name: create nfs mount point for v1 rootfs become: true become_user: \"{{ ansible_env.user }}\" file: path: \"{{ ansible_env.home }}/nos/v1/rootfs\" state: directory - name: create nfs mount point for v2 rootfs file: path: \"{{ ansible_env.home }}/nos/v2/rootfs\" state: directory - name: replace pattern in nfs export file replace: dest: \"{{ playbook_dir }}/templates/uma/nfs_export.j2\" regexp: \"##user##\" replace: \"{{ ansible_env.user }}\" - name: replace pattern in tftp file replace: dest: \"{{ playbook_dir }}/templates/uma/tftpd-hpa.j2\" regexp: \"##user##\" replace: \"{{ ansible_env.user }}\" - name: copy nfs export file for nos become: true become_user: root template: backup: yes src: \"{{ playbook_dir }}/templates/uma/nfs_export.j2\" dest: /etc/exports owner: root group: root mode: 0644 - name: copy tftpd-hpa conf file for nos become: true become_user: root template: backup: yes src: \"{{ playbook_dir }}/templates/uma/tftpd-hpa.j2\" dest: /etc/default/tftpd-hpa owner: root group: root mode: 0644 - name: restart nfs server and tftp server become: yes service: name: \"{{ item }}\" state: restarted with_items: - tftpd-hpa - nfs-kernel-server", "label": 1, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "- name: disable firewall become: true ufw: state: disabled - name: create tftpd directory for kernel file: path: \"{{ ansible_env.home }}/nos/kernel\" state: directory - name: create nfs mount point for v1 rootfs become: true become_user: \"{{ ansible_env.user }}\" file: path: \"{{ ansible_env.home }}/nos/v1/rootfs\" state: directory - name: create nfs mount point for v2 rootfs file: path: \"{{ ansible_env.home }}/nos/v2/rootfs\" state: directory - name: replace pattern in nfs export file replace: dest: \"{{ playbook_dir }}/templates/uma/nfs_export.j2\" regexp: \"##user##\" replace: \"{{ ansible_env.user }}\" - name: replace pattern in tftp file replace: dest: \"{{ playbook_dir }}/templates/uma/tftpd-hpa.j2\" regexp: \"##user##\" replace: \"{{ ansible_env.user }}\" - name: copy nfs export file for nos become: true become_user: root template: backup: yes src: \"{{ playbook_dir }}/templates/uma/nfs_export.j2\" dest: /etc/exports owner: root group: root mode: 0644 - name: copy tftpd-hpa conf file for nos become: true become_user: root template: backup: yes src: \"{{ playbook_dir }}/templates/uma/tftpd-hpa.j2\" dest: /etc/default/tftpd-hpa owner: root group: root mode: 0644 - name: restart nfs server and tftp server become: yes service: name: \"{{ item }}\" state: restarted with_items: - tftpd-hpa - nfs-kernel-server", "label": 0, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "- name: fail on change", "label": 1, "commit_name": "fix some ansible-lint errors"}
{"code": "- name: fail on change", "label": 0, "commit_name": "fix some ansible-lint errors"}
{"code": "rewriterule ^ - [e=preferredlang:%1,e=preferredregion:%1]", "label": 1, "commit_name": "Fix CMS assigning preferred language region based on FB OG locale"}
{"code": "rewriterule ^ - [e=preferredlang:%1,e=preferredregion:%2]", "label": 0, "commit_name": "Fix CMS assigning preferred language region based on FB OG locale"}
{"code": "dest: /home/jaller94/silvy-matrix/config/matrix.js", "label": 1, "commit_name": "Fix bruce's config"}
{"code": "dest: /home/jaller94/bruce-matrix/config/matrix.js", "label": 0, "commit_name": "Fix bruce's config"}
{"code": "os_version: \"{{ ansible_lsb.release if ansible_lsb is defined else ansible_distribution_version }}\" os_version_major: \"{{ os_version | regex_replace('^([0-9]+)[^0-9]*.*', '\\\\\\\\1') }}\" '7': 'e/epel-release-7-5.noarch.rpm'", "label": 1, "commit_name": "Merge pull request #51 from ernestas-poskus/fix/os_version_major_parsing_and_7_epel_release"}
{"code": "os_version_major: \"{{ ansible_distribution_major_version }}\" '7': 'e/epel-release-7-6.noarch.rpm'", "label": 0, "commit_name": "Merge pull request #51 from ernestas-poskus/fix/os_version_major_parsing_and_7_epel_release"}
{"code": "file: path=/srv/wordpress/ owner=wordpress group=wordpress state=directory recurse=yess setype=httpd_sys_content_t", "label": 1, "commit_name": "Fixed typo."}
{"code": "file: path=/srv/wordpress/ owner=wordpress group=wordpress state=directory recurse=yes setype=httpd_sys_content_t", "label": 0, "commit_name": "Fixed typo."}
{"code": "- role: website container_name: \"{{ pawc_container_name }}\" ssh_port: \"{{ pawc_ssh_port }}\" url: \"{{ pawc_url }}\" proxy_config: \"{{ role_path }}/../../files/ams1.paddatrapper.com/pawc-proxy.conf.j2\" additional_ports: - { protocol: tcp, port: 8000, description: pawc django }", "label": 1, "commit_name": "disable pawc.pl until rate limit expires"}
{"code": "# - role: website # container_name: \"{{ pawc_container_name }}\" # ssh_port: \"{{ pawc_ssh_port }}\" # url: \"{{ pawc_url }}\" # proxy_config: \"{{ role_path }}/../../files/ams1.paddatrapper.com/pawc-proxy.conf.j2\" # additional_ports: # - { protocol: tcp, port: 8000, description: pawc django }", "label": 0, "commit_name": "disable pawc.pl until rate limit expires"}
{"code": "- name: common - set hostname hosts: \"{{ create_vm__hosts | default([]) }}\" gather_facts: false tags: - skip_ansible_lint - always - setup tasks: - name: common - set inventory hostname as host variable ansible.builtin.add_host: name: hostname_holder vm_name: \"{{ inventory_hostname }}\" vm_ip_address: \"{{ vm_ip_address }}\" changed_when: false - name: common - print host variables ansible.builtin.debug: msg: \"{{ item.name }}: {{ item.value }}\" loop: - name: hostname value: \"{{ hostvars['hostname_holder'].vm_name }}\" - name: ip value: \"{{ hostvars['hostname_holder'].vm_ip_address }}\" # ----------------------------------------------------------------------------- zvm__name: \"{{ hostvars['hostname_holder'].vm_name }}\" zvm__ssh_host: \"{{ hostvars['hostname_holder'].vm_name }}\" vm_ip_address: \"{{ hostvars['hostname_holder'].vm_ip_address }}\"", "label": 1, "commit_name": "fix: remove hostname_holder"}
{"code": "vm_inventory_hostname: \"{{ groups[create_vm__hosts] | first }}\" zvm__name: \"{{ vm_inventory_hostname }}\" zvm__ssh_host: \"{{ hostvars[vm_inventory_hostname].zvm__ssh_host }}\" vm_ip_address: \"{{ hostvars[vm_inventory_hostname].vm_ip_address }}\"", "label": 0, "commit_name": "fix: remove hostname_holder"}
{"code": "postgresql['md5_auth_cidr_addresses'] = [ '{{ groups.secondary_trackingdbs_internal[0] }}/32', '{{ groups.secondary_trackingdbs_internal[1] }}/32', '{{ groups.secondary_trackingdbs_internal[2] }}/32', '{{ groups.secondary_pgbouncer_trackingdb_internal[0] }}/32', 'localhost' # patroni configuration patroni['replication_password'] = '{{ sql_user_password_plain }}' patroni['postgresql']['max_wal_senders'] = 4", "label": 1, "commit_name": "Refactor postgresql authentication configuration"}
{"code": "# patroni configuration patroni['replication_password'] = '{{ sql_user_password_plain }}' patroni['postgresql']['max_wal_senders'] = 8 patroni['postgresql']['max_replication_slots'] = 8 # patroni needs one extra slot when doing backup restore, so always use ammount of slots * 2 postgresql['listen_address'] = '0.0.0.0' postgresql['md5_auth_cidr_addresses'] = %w[ {% for host in groups.secondary_trackingdbs_internal %}{{ host }}/32 {% endfor %} {{ groups.secondary_pgbouncer_trackingdb_internal[0] }}/32 {{ groups.primary_host_internal[0] }}/32 {{ groups.secondary_host_internal[0] }}/32 localhost", "label": 0, "commit_name": "Refactor postgresql authentication configuration"}
{"code": "service: name=nginx state=reload enabled=yes", "label": 1, "commit_name": "Make common stuff optional; fix nginx reload"}
{"code": "service: name=nginx state=reloaded enabled=yes", "label": 0, "commit_name": "Make common stuff optional; fix nginx reload"}
{"code": "with_items: \"{{apt_other_repos}}\" when: not apt_other_repos is none", "label": 1, "commit_name": "fix logic bug"}
{"code": "with_items: \"{{ apt_other_repos }}\" when: not apt_other_repos is undefined", "label": 0, "commit_name": "fix logic bug"}
{"code": "- role: geerlingguy.homebrew - role: geerlingguy.mas - import_tasks: tasks/dock.yml when: configure_dock tags: ['dock']", "label": 1, "commit_name": "Fixes #116: Switch from roles and dock tasks to geerlingguy.mac collection."}
{"code": "- role: elliotweiser.osx-command-line-tools - role: geerlingguy.mac.homebrew - role: geerlingguy.mac.mas - role: geerlingguy.mac.dock when: configure_dock tags: ['dock']", "label": 0, "commit_name": "Fixes #116: Switch from roles and dock tasks to geerlingguy.mac collection."}
{"code": "- name: load os-specific vars ansible.builtin.include_vars: \"{{ lookup('first_found', params) }}\" vars: params: files: - '{{ ansible_distribution }}.yml' - '{{ ansible_os_family }}.yml' - main.yml paths: - 'vars' - name: configure the system ansible.builtin.include_tasks: essential.yml - name: update the packages and configure auto-updates (redhat-based) ansible.builtin.include_tasks: setup-redhat.yml when: - ansible_os_family == 'redhat' - name: update the packages and configure auto-updates (debian-based) ansible.builtin.include_tasks: setup-debian.yml when: - ansible_os_family == 'debian' - name: configure firewalld ansible.builtin.include_tasks: firewall-redhat.yml when: - ansible_os_family == 'redhat' and (enable_firewall | default(true)) - name: configure ufw ansible.builtin.include_tasks: firewall-debian.yml when: - ansible_os_family == 'debian' and (enable_firewall | default(true))", "label": 1, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "- name: update the packages and configure auto-updates ansible.builtin.include_tasks: setup.yml - name: configure the firewall ansible.builtin.include_tasks: firewall.yml", "label": 0, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "opts: rw,size=500m,uid=knot-resolver,gid=knot-resolver,nosuid,nodev,noexec,mode=0700", "label": 1, "commit_name": "fix: constant size to avoid creating giant cache in limited space"}
{"code": "opts: rw,size=110m,uid=knot-resolver,gid=knot-resolver,nosuid,nodev,noexec,mode=0700", "label": 0, "commit_name": "fix: constant size to avoid creating giant cache in limited space"}
{"code": "docker_tag: enmanuelmoreira/docker-ansible-almalinux8:latest", "label": 1, "commit_name": "Fix image name"}
{"code": "docker_tag: enmanuelmoreira/docker-ansible-alpine:latest", "label": 0, "commit_name": "Fix image name"}
{"code": "action: apt pkg=mysql-server state=installed action: apt pkg=python-mysqldb state=installed action: service name=mysql state=started command: /usr/bin/mysqladmin -u root password \"{{ mysql_root_password }}\" when: mysql_root_password is defined when: mysql_root_password is defined", "label": 1, "commit_name": "Merge pull request #113 from ftao/auth-bug-fix"}
{"code": "apt: pkg=mysql-server state=installed apt: pkg=python-mysqldb state=installed service: name=mysql state=started mysql_user: name=root host=localhost password=\"{{ mysql_root_password }}\" state=present", "label": 0, "commit_name": "Merge pull request #113 from ftao/auth-bug-fix"}
{"code": "--sds_ip {{ hostvars[inventory_hostname]['ansible_'+scaleio_interface]['ipv4']['address'] }}", "label": 1, "commit_name": "fixes issue for scaleio interface on non-homogenius clusters"}
{"code": "--sds_ip {{ hostvars[inventory_hostname]['ansible_'+hostvars[inventory_hostname]['scaleio_interface']]['ipv4']['address'] }}", "label": 0, "commit_name": "fixes issue for scaleio interface on non-homogenius clusters"}
{"code": "inv_install_nexus_repository_container_name: \"{{ inv_install_nexus_repository_container_name }}\" inv_install_nexus_repository_data_path: \"{{ inv_install_nexus_repository_data_path }}\" inv_install_nexus_repository_heap: \"{{ inv_install_nexus_repository_heap }}\" inv_install_nexus_repository_web_address: \"{{ inv_install_nexus_repository_web_address }}\" inv_install_nexus_repository_web_port: \"{{ inv_install_nexus_repository_web_port }}\" inv_install_nexus_repository_web_port_min: \"{{ inv_install_nexus_repository_web_port_min }}\" inv_install_nexus_repository_web_port_max: \"{{ inv_install_nexus_repository_web_port_max }}\"", "label": 1, "commit_name": "fix playbooks"}
{"code": "install_nexus_repository_container_name: \"{{ inv_install_nexus_repository_container_name }}\" install_nexus_repository_data_path: \"{{ inv_install_nexus_repository_data_path }}\" install_nexus_repository_heap: \"{{ inv_install_nexus_repository_heap }}\" install_nexus_repository_web_address: \"{{ inv_install_nexus_repository_web_address }}\" install_nexus_repository_web_port: \"{{ inv_install_nexus_repository_web_port }}\" install_nexus_repository_web_port_min: \"{{ inv_install_nexus_repository_web_port_min }}\" install_nexus_repository_web_port_max: \"{{ inv_install_nexus_repository_web_port_max }}\"", "label": 0, "commit_name": "fix playbooks"}
{"code": "command: /usr/bin/bash /tmp/raspbian-ua-netinst/build.sh", "label": 1, "commit_name": "build: fix bash path"}
{"code": "command: /bin/bash /tmp/raspbian-ua-netinst/build.sh", "label": 0, "commit_name": "build: fix bash path"}
{"code": "stage: post_build", "label": 1, "commit_name": "refactor: streamline stages"}
{"code": "stage: test", "label": 0, "commit_name": "refactor: streamline stages"}
{"code": "- not remote | default ('false') | bool", "label": 1, "commit_name": "minor typo in variable name fixed"}
{"code": "- not remove | default ('false') | bool", "label": 0, "commit_name": "minor typo in variable name fixed"}
{"code": "- name: copy gitlab configuration file. template: src: \"gitlab.rb.j2\" dest: /etc/gitlab/gitlab.rb owner: root group: root mode: 0600 notify: restart gitlab", "label": 1, "commit_name": "update code"}
{"code": "# - name: copy gitlab configuration file. # template: # src: \"gitlab.rb.j2\" # dest: /etc/gitlab/gitlab.rb # owner: root # group: root # mode: 0600 # notify: restart gitlab", "label": 0, "commit_name": "update code"}
{"code": "user: > shell=/bin/bash path=\"{{ samba_share_path }}\" owner=\"{{ storage_user }}\" group=\"{{ storage_group }}\" become_user: \"{{ storage_user }}\" sudo: yes mode=0644 sudo: yes", "label": 1, "commit_name": "Minor fixes"}
{"code": "user: > shell=/bin/bash path=\"{{ samba_share_path }}\" owner=\"{{ storage_user }}\" group=\"{{ storage_group }}\" owner=\"{{ storage_user }}\" become: yes mode=0644 become: yes", "label": 0, "commit_name": "Minor fixes"}
{"code": "audiobookshelf_container_image: '{{ audiobookshelf_container_repo }}{{ \":\" + audiobookshelf_container_tag }}'", "label": 1, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "audiobookshelf_container_image: 'advplyr/audiobookshelf:{{ audiobookshelf_container_tag }}'", "label": 0, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "until: res.changed", "label": 1, "commit_name": "Fix attribute access error while trying to read task result"}
{"code": "until: res.changed is defined and res.changed", "label": 0, "commit_name": "Fix attribute access error while trying to read task result"}
{"code": "become: yes become_user: dcadm1n become: yes become_user: dcadm1n", "label": 1, "commit_name": "tabbing fix"}
{"code": "become: yes become_user: dcadm1n become: yes become_user: dcadm1n", "label": 0, "commit_name": "tabbing fix"}
{"code": "# handlers file for training", "label": 1, "commit_name": "fixes and add demo role"}
{"code": "# handlers file for training - name: restart nginx debug: msg: \"restarted nginx\" - name: restart consul debug: msg: \"restarted consul\" - name: restart filebeat debug: msg: \"restarted filebeat\"", "label": 0, "commit_name": "fixes and add demo role"}
{"code": "- \"{{ deluge_download_directory }}:/root/downloads:rw\"", "label": 1, "commit_name": "Merge pull request #682 from leonhartyao/fix-deluge-download-issue"}
{"code": "- \"{{ deluge_download_directory }}:/downloads:rw\"", "label": 0, "commit_name": "Merge pull request #682 from leonhartyao/fix-deluge-download-issue"}
{"code": "src=../../files/rabbitmq.list", "label": 1, "commit_name": "Merge pull request #1 from reactiveops/ansible-2-fix"}
{"code": "src=files/rabbitmq.list", "label": 0, "commit_name": "Merge pull request #1 from reactiveops/ansible-2-fix"}
{"code": "url: \"https://download.docker.com/linux/ubuntu/gpg\" src: \"docker.list\" dest: \"/etc/apt/sources.list.d/docker.list\" url: \"https://github.com/docker/compose/releases/download/v2.2.3/docker-compose-linux-x86_64\"", "label": 1, "commit_name": "refactor: start lint"}
{"code": "url: https://download.docker.com/linux/ubuntu/gpg src: docker.list dest: /etc/apt/sources.list.d/docker.list url: https://github.com/docker/compose/releases/download/v2.2.3/docker-compose-linux-x86_64", "label": 0, "commit_name": "refactor: start lint"}
{"code": "- ../config.yml - include: tasks/ansible-setup.yml - include: tasks/sudoers.yml - include: tasks/terminal.yml - include: tasks/osx.yml - include: tasks/extra-packages.yml include: \"{{ outer_item }}\"", "label": 1, "commit_name": "fix syntax warnings"}
{"code": "- ./config.yml - include_tasks: tasks/ansible-setup.yml - include_tasks: tasks/sudoers.yml - include_tasks: tasks/terminal.yml - include_tasks: tasks/osx.yml - include_tasks: tasks/extra-packages.yml include_tasks: \"{{ outer_item }}\"", "label": 0, "commit_name": "fix syntax warnings"}
{"code": "# roles: # - geerlingguy.nodejs # - name: installing latest nginx # apt: # name: nginx # state: latest # - name: installing latest git # apt: # name: git # state: latest # - name: nginx template # template: # src: templates/default.j2 # dest: /etc/nginx/sites-available/default # - name: starting nginx # service: # name: nginx # enabled: yes # state: restarted # - name: adding production group # group: # name: production # - name: adding git user # user: # name: git # group: production # - name: adding debian user to production group # user: # name: debian # group: production # - name: adding ssh key # authorized_key: # key: ssh-rsa aaaab3nzac1yc2eaaaadaqabaaacaqdy88sex13bmxjp452daylk5kzmch08m23+exoov46+kjnxwugm2kxuesi1te8xbep53p/lbn2rwmzljzpkdlhgb4unxtv0nyxf8hciqj5moxbihglfgojxa8cm1mgyrfyaxfq0ocytsei13if5p3pd0a7etu8mnwlyndpy9etllwygjacgz8xjnqyfhvo7jsy9o8oajjq4yjtkatsu1h0e9ij/v3wtsifwytuw+qkdeeuj+oasrs9v8nd5sjt5oqe3l4fkobumghhwadbehwlqbi/8cpit0q7zskg4yclzblnllf7+vxtzkhybtykhxzqhll6x6vk86ni1eliktmfptpgmtnuhjnd8yadthgmbr8e5hdzb9lul03hwrqzysc54noo21n99gu1hzdpqu4hdbugvjexd6uvwe5p1lfutldzw3/gw/azz+cu8i9wctr2niojmy/33rqv88oq7htcj+v97zpddrmfpijbpe+aamm9lyugt69g9spr5rsmlrgrcvle6jejbpiug3q1bmquxtnmz/rhife7w5a9xjrl3xc/7qbit5+pm0mzmiziqflvjfmhrvi+cky8saehzmxggv5znapiwu6jqntylej332ojtqzwtoktol6vtsegq0yvtoqt88tqwopdugu1a7fdsesutuy4lrcva3unejsppzq== badr.youbi-idrissi@student.ecp.fr # user: git # - name: creating bare repos # command: git init --bare /home/git/eisenhower-backend.git # - command: git init --bare /home/git/eisenhower-client.git # - name: setting permissions # file: # path: /home/git/eisenhower-backend.git # group: production # owner: git # recurse: yes # - file: # path: /home/git/eisenhower-backend.git # group: production # owner: git # recurse: yes # - name: creating folder structure # file: # path: /var/www/html/eisenhower # state: directory # owner: git # group: production # - template: # src: env.j2 # dest: /var/www/html/eisenhower/.env # owner: git # group: production", "label": 1, "commit_name": "Deploying optimised app directly"}
{"code": "roles: - geerlingguy.nodejs - name: installing latest nginx apt: name: nginx state: latest - name: installing latest git apt: name: git state: latest - name: nginx template template: src: templates/default.j2 dest: /etc/nginx/sites-available/default - name: starting nginx service: name: nginx enabled: yes state: restarted - name: adding production group group: name: production - name: adding git user user: name: git group: production - name: adding debian user to production group user: name: debian group: production - name: adding ssh key authorized_key: key: ssh-rsa aaaab3nzac1yc2eaaaadaqabaaacaqdy88sex13bmxjp452daylk5kzmch08m23+exoov46+kjnxwugm2kxuesi1te8xbep53p/lbn2rwmzljzpkdlhgb4unxtv0nyxf8hciqj5moxbihglfgojxa8cm1mgyrfyaxfq0ocytsei13if5p3pd0a7etu8mnwlyndpy9etllwygjacgz8xjnqyfhvo7jsy9o8oajjq4yjtkatsu1h0e9ij/v3wtsifwytuw+qkdeeuj+oasrs9v8nd5sjt5oqe3l4fkobumghhwadbehwlqbi/8cpit0q7zskg4yclzblnllf7+vxtzkhybtykhxzqhll6x6vk86ni1eliktmfptpgmtnuhjnd8yadthgmbr8e5hdzb9lul03hwrqzysc54noo21n99gu1hzdpqu4hdbugvjexd6uvwe5p1lfutldzw3/gw/azz+cu8i9wctr2niojmy/33rqv88oq7htcj+v97zpddrmfpijbpe+aamm9lyugt69g9spr5rsmlrgrcvle6jejbpiug3q1bmquxtnmz/rhife7w5a9xjrl3xc/7qbit5+pm0mzmiziqflvjfmhrvi+cky8saehzmxggv5znapiwu6jqntylej332ojtqzwtoktol6vtsegq0yvtoqt88tqwopdugu1a7fdsesutuy4lrcva3unejsppzq== badr.youbi-idrissi@student.ecp.fr user: git - name: creating bare repos command: git init --bare /home/git/eisenhower-backend.git - command: git init --bare /home/git/eisenhower-client.git - name: setting permissions file: path: /home/git/eisenhower-backend.git group: production owner: git recurse: yes - file: path: /home/git/eisenhower-backend.git group: production owner: git recurse: yes - name: creating folder structure file: path: /var/www/html/eisenhower state: directory owner: git group: production - template: src: env.j2 dest: /var/www/html/eisenhower/.env owner: git group: production - name: creating static directory file: path: /var/www/html/eisenhower/static state:directory owner: git group: production", "label": 0, "commit_name": "Deploying optimised app directly"}
{"code": "remote_src: false", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "remote_src: false", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "command: > - name: copy php-fpm configuration template: src=\"php-fpm.conf.j2\" dest=\"/etc/php5/fpm/pool.d/{{ item.site_name }}.conf\" with_items: wordpress_sites notify: restart php-fpm", "label": 1, "commit_name": "HHVM implementation"}
{"code": "command: >", "label": 0, "commit_name": "HHVM implementation"}
{"code": "\"task failed for testing\"", "label": 1, "commit_name": "Fix wrong parameter for fail module"}
{"code": "msg: \"task failed for testing\"", "label": 0, "commit_name": "Fix wrong parameter for fail module"}
{"code": "- name: openvpn client - installing package easy-rsa when: rc_ovpnc_client_conf.stat.exists == false when: rc_ovpnc_client_conf.stat.exists == false when: rc_ovpnc_client_conf.stat.exists == false when: rc_ovpnc_client_conf.stat.exists == false when: rc_ovpnc_client_conf.stat.exists == false when: rc_ovpnc_client_conf.stat.exists == false when: rc_ovpnc_client_conf.stat.exists == false when: rc_ovpnc_client_conf.stat.exists == false", "label": 1, "commit_name": "Final source re-arrangements before second code review"}
{"code": "- name: installing package easy-rsa", "label": 0, "commit_name": "Final source re-arrangements before second code review"}
{"code": "src: https://gitlab.com/a-gave/ansible_openwrt_buildroot.git", "label": 1, "commit_name": "fix requirements, minor on v19 targets"}
{"code": "src: git+https://gitlab.com/a-gave/ansible_openwrt_buildroot.git", "label": 0, "commit_name": "fix requirements, minor on v19 targets"}
{"code": "shell: echo 'kubelet_extra_args=\"--kube-reserved=cpu=500m,memory=32mi,ephemeral-storage=500mi --system-reserved=cpu=250mi,memory=16mi,ephemeral-storage=500mi\"' | tee /etc/default/kubelet command: \"sh {{ hostvars['pikube-master.localdomain']['join_command']['stdout_lines'][0] }}\"", "label": 1, "commit_name": "Typo in worker kubelet args, install specific version of docker, set daemon params"}
{"code": "shell: echo 'kubelet_extra_args=\"--kube-reserved=cpu=500m,memory=32mi,ephemeral-storage=500mi --system-reserved=cpu=250m,memory=16mi,ephemeral-storage=500mi\"' | tee /etc/default/kubelet command: \"{{ hostvars['pikube-master.localdomain']['join_command']['stdout_lines'][0] }}\"", "label": 0, "commit_name": "Typo in worker kubelet args, install specific version of docker, set daemon params"}
{"code": "- {name: \"delete inactive\", job: \". ~/.profile; cd ~/www/; node delete-inactive.js >~/delete-inactive.log\"}", "label": 1, "commit_name": "Ignore errors throw by delete-inactive.js"}
{"code": "- {name: \"delete inactive\", job: \". ~/.profile; cd ~/www/; node delete-inactive.js >~/delete-inactive.log 2>&1\"}", "label": 0, "commit_name": "Ignore errors throw by delete-inactive.js"}
{"code": "inv_install_apache__remove_all_vhosts: true", "label": 1, "commit_name": "fix idempotence"}
{"code": "inv_install_apache__remove_all_vhosts: false", "label": 0, "commit_name": "fix idempotence"}
{"code": "name: \"{{ item }}\" with_items: ['postgresql', 'postgresql-contrib', 'libpq-dev', 'python3-psycopg2']", "label": 1, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "name: ['postgresql', 'postgresql-contrib', 'libpq-dev', 'python3-psycopg2']", "label": 0, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "- postfix - mailutils", "label": 1, "commit_name": "Cleanup formatting and fix pear"}
{"code": "- postfix - mailutils", "label": 0, "commit_name": "Cleanup formatting and fix pear"}
{"code": "- google.cloud - ansible.posix - amazon.aws - community.aws", "label": 1, "commit_name": "Merge branch '13-broken-playbook-to-copy-and-paste-error' into 'main'"}
{"code": "- google.cloud - ansible.posix - amazon.aws - community.aws", "label": 0, "commit_name": "Merge branch '13-broken-playbook-to-copy-and-paste-error' into 'main'"}
{"code": "when: {{ ip_access }} == public when: {{ ip_access }} == public when: {{ ip_access }} == private when: {{ ip_access }} == private", "label": 1, "commit_name": "fix ansible quoting"}
{"code": "when: \"{{ ip_access }} == public\" when: \"{{ ip_access }} == public\" when: \"{{ ip_access }} == private\" when: \"{{ ip_access }} == private\"", "label": 0, "commit_name": "fix ansible quoting"}
{"code": "bootstrap_ssl_files__user: \"{{ inv_bootstrap_ssl_files__user }}\" bootstrap_ssl_files__base_path: \"{{ inv_bootstrap_ssl_files__base_path }}\" bootstrap_ssl_files__ca_validity: \"{{ inv_bootstrap_ssl_files__ca_validity }}\" bootstrap_ssl_files__key_size: \"{{ inv_bootstrap_ssl_files__key_size }}\" bootstrap_ssl_files__root_ca: \"{{ inv_bootstrap_ssl_files__root_ca }}\" bootstrap_ssl_files__intermediates_ca: \"{{ inv_bootstrap_ssl_files__intermediates_ca }}\" bootstrap_ssl_files__end_certs: \"{{ inv_bootstrap_ssl_files__end_certs }}\" bootstrap_ssl_files__cert_validity: \"{{ inv_bootstrap_ssl_files__cert_validity }}\"", "label": 1, "commit_name": "fix CI 3 4"}
{"code": "bootstrap_ssl_files__user: \"{{ input_bootstrap_ssl_files__user }}\" bootstrap_ssl_files__base_path: \"{{ input_bootstrap_ssl_files__base_path }}\" bootstrap_ssl_files__ca_validity: \"{{ input_bootstrap_ssl_files__ca_validity }}\" bootstrap_ssl_files__key_size: \"{{ input_bootstrap_ssl_files__key_size }}\" bootstrap_ssl_files__root_ca: \"{{ input_bootstrap_ssl_files__root_ca }}\" bootstrap_ssl_files__intermediates_ca: \"{{ input_bootstrap_ssl_files__intermediates_ca }}\" bootstrap_ssl_files__end_certs: \"{{ input_bootstrap_ssl_files__end_certs }}\" bootstrap_ssl_files__cert_validity: \"{{ input_bootstrap_ssl_files__cert_validity }}\"", "label": 0, "commit_name": "fix CI 3 4"}
{"code": "bastionsgid: {{bastionhost_out.group_id}}", "label": 1, "commit_name": "new code is added to playbook13"}
{"code": "bastionsgid: {{bastionsg_out.group_id}}", "label": 0, "commit_name": "new code is added to playbook13"}
{"code": "copy: src=files/apache_php_fpm/security.conf dest=/etc/apache2/conf-available/security.conf owner=root group=root mode=0644 template: src=files/apache_php_fpm/000-default.conf.j2 dest=/etc/apache2/sites-available/000-default.conf owner=root group=root mode=0644 copy: src=files/apache_php_fpm/index.php dest=/var/www/html/index.php owner=root group=root mode=0644", "label": 1, "commit_name": "Update 20210409 - Apache2+FPM bug, added mod_php configuration."}
{"code": "- name: enable mod_php module apache2_module: name: php7.3 state: present notify: restart apache2 copy: src=files/apache_mod_php/security.conf dest=/etc/apache2/conf-available/security.conf owner=root group=root mode=0644 template: src=files/apache_mod_php/000-default.conf.j2 dest=/etc/apache2/sites-available/000-default.conf owner=root group=root mode=0644 - name: copy php configuration copy: src=files/apache_mod_php/php.ini dest=/etc/php/7.3/fpm/php.ini owner=root group=root mode=0644 notify: restart apache2 copy: src=files/apache_mod_php/index.php dest=/var/www/html/index.php owner=root group=root mode=0644", "label": 0, "commit_name": "Update 20210409 - Apache2+FPM bug, added mod_php configuration."}
{"code": "node_version: 11.9.0 core_version: 3.7.0", "label": 1, "commit_name": "fix: bump node, core, and set the network apply setting"}
{"code": "node_version: 11.13.0 core_version: 3.7.1 pop_network_apply: true", "label": 0, "commit_name": "fix: bump node, core, and set the network apply setting"}
{"code": "tags: install-element", "label": 1, "commit_name": "minor fixes, add a redlight install section for rapid testing"}
{"code": "tags: install-element # create admin user - import_tasks: \"{{ role_path }}/tasks/create_admin_user.yml\" tags: create-admin-user", "label": 0, "commit_name": "minor fixes, add a redlight install section for rapid testing"}
{"code": "shell: \"skopeo inspect {{ image_protocol }}{{ bundle_image }}\"", "label": 1, "commit_name": "Merge pull request #51 from shawn-hurley/bug/fix-gateway-timeout"}
{"code": "## must use this in conjunction with extract bundle shell: \"skopeo inspect oci:{{ operator_bundle_dir }}:latest\"", "label": 0, "commit_name": "Merge pull request #51 from shawn-hurley/bug/fix-gateway-timeout"}
{"code": "repo: \"{{ item.0.git_proto }}://{{ item.0.git_user }}@{{ item.0.git_host }}:{{ item.0.git_repo }}\"", "label": 1, "commit_name": "Fix merge conflict"}
{"code": "repo: \"{{ item.0.git_proto }}://{{ item.0.git_user }}@{{ item.0.git_host }}/{{ item.0.git_repo }}\"", "label": 0, "commit_name": "Fix merge conflict"}
{"code": "# - docker # - pkg-setup # - thesis-deps # - vmbox - messengers", "label": 1, "commit_name": "Uncomment code from ansible roles"}
{"code": "- docker - pkg-setup - thesis-deps - vmbox - messengers", "label": 0, "commit_name": "Uncomment code from ansible roles"}
{"code": "allow_failure: false molecule_test_debian_12: <<: *molecule_test variables: scenario: \"cicd-debian-12\" rules: - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' molecule_test_ubuntu_22: scenario: \"cicd-ubuntu-22\" allow_failure: true molecule_test_debian_11: <<: *molecule_test variables: scenario: \"cicd-debian-11\" allow_failure: true rules: - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' - \"molecule_test_debian_12\"", "label": 1, "commit_name": "fix CI 2"}
{"code": "#allow_failure: false #molecule_test_debian_12: # <<: *molecule_test # variables: # scenario: \"cicd-debian-12\" # rules: # - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' molecule_test_docker_dind: allow_failure: true #because token removed scenario: \"cicd-docker-dind\" #molecule_test_ubuntu_22: # <<: *molecule_test # variables: # scenario: \"cicd-ubuntu-22\" # allow_failure: true # rules: # - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' #molecule_test_debian_11: # <<: *molecule_test # variables: # scenario: \"cicd-debian-11\" # allow_failure: true # rules: # - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"' - \"molecule_test_docker_dind\"", "label": 0, "commit_name": "fix CI 2"}
{"code": "src: /usr/local/lib/x86_64-linux-gnu/python3/dist-packages/gi/overrides/apex.py", "label": 1, "commit_name": "fix: use correct overrides path"}
{"code": "src: /usr/lib/x86_64-linux-gnu/python3/dist-packages/gi/overrides/apex.py", "label": 0, "commit_name": "fix: use correct overrides path"}
{"code": "- { role: ansible-firewall-docker, tags: [firewall] } - { role: ansible-docker-host, tags: [docker] } #- {role: ansible-vector, tags: [vector]} region: us-east-1 - apt: #ssl_mode: verify-full - { role: ansible-docker-matrix }", "label": 1, "commit_name": "various fixes"}
{"code": "gather_facts: true - {role: ansible-docker-host, tags: [baseline, docker]} - {role: ansible-vector, tags: [baseline, vector]} - debug: var: matrix_sygnal_enabled region: \"{{ aws_region }}\" - name: download aws certificates get_url: url: https://truststore.pki.rds.amazonaws.com/global/global-bundle.pem dest: /usr/local/share/ca-certificates/aws-global-bundle.crt mode: 0644 register: aws_certs - name: download aws rds certificates get_url: url: https://s3.amazonaws.com/rds-downloads/rds-combined-ca-bundle.pem dest: /usr/local/share/ca-certificates/rds-combined-ca-bundle.crt mode: 0644 register: aws_certs2 - name: update ca certs command: /usr/sbin/update-ca-certificates when: aws_certs.changed or aws_certs2.changed - name: ensure pg python module is installed apt: state: present ssl_mode: verify-full ca_cert: /etc/ssl/certs/ca-certificates.crt register: pg_ping - name: assert database available ansible.builtin.assert: that: - pg_ping.is_available fail_msg: synapse database is not configured or is available success_msg: succesfully connected to the synapse database - {role: ansible-docker-matrix}", "label": 0, "commit_name": "various fixes"}
{"code": "pl_subnet_name: \"{{subnet_name|default('subnet_1')}}\" pl_virtualmachine_network_name: \"{{pl_virtualmachine_name}}_nic\" pl_security_group_name: \"{{security_group_name|default('security_group_1')}}\" pl_virtualmachine_username: \"{{virtualmachine_username|default('azureuser')}}\" pl_virtualmachine_size: \"{{virtualmachine_size|default('standard_d1_v2')}}\" pl_azure_ssh_public_key: \"{{azure_ssh_public_key}}\" pl_image_name: \"{{image_name|default('ubuntuserver')}}\" pl_image_publisher: \"{{image_publisher|default('canonical')}}\" pl_image_sku: \"{{image_sku|default('16.04-lts')}}\" pl_image_version: \"{{image_version|default('latest')}}\" pl_virtualmachine_status: \"{{virtualmachine_status|default('true')}}\"", "label": 1, "commit_name": "Updating security groups"}
{"code": "pl_virtualmachine_network_name: \"{{pl_virtualmachine_name}}-{{pl_availabilityset_name}}_nic\" pl_availabilityset_name : \"{{availabilityset_name|default('1a')}}\"", "label": 0, "commit_name": "Updating security groups"}
{"code": "- ../config.yml", "label": 1, "commit_name": "Merge pull request #68 from newtonne/fileglob-fix"}
{"code": "- \"{{ playbook_dir }}/config.yml\"", "label": 0, "commit_name": "Merge pull request #68 from newtonne/fileglob-fix"}
{"code": "- ansible-playbook playbooks/$playbook -i $inventory -l $hosts -e $extravars -t $tags", "label": 1, "commit_name": "fix"}
{"code": "- ansible-playbook playbooks/$playbook -i $inventory -l $hosts -e $extravars -t $tags -vd", "label": 0, "commit_name": "fix"}
{"code": "marathon_playbook_version: \"0.3.2\"", "label": 1, "commit_name": "Merge pull request #23 from ernestas-poskus/fix/os_version_major_parsing"}
{"code": "marathon_playbook_version: \"0.3.3\"", "label": 0, "commit_name": "Merge pull request #23 from ernestas-poskus/fix/os_version_major_parsing"}
{"code": "name: \"{{ item }}\" with_items: \"{{ gnome_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ gnome_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "lineinfile: regexp=\"requiretty\" dest=/etc/sudoers state=absent lineinfile: regexp=\"requiretty\" dest=/etc/sudoers/os_defaults state=absent", "label": 1, "commit_name": "fixing tty typo"}
{"code": "lineinfile: regexp=\"^\\s+\\w+\\s+requiretty\" dest=/etc/sudoers state=absent lineinfile: regexp=\"requiretty\" dest=/etc/sudoers.d/os_defaults state=absent", "label": 0, "commit_name": "fixing tty typo"}
{"code": "license: license gpl-2.0 min_ansible_version: 2.1", "label": 1, "commit_name": "Fix licence and add some information in Readme"}
{"code": "license: license mit min_ansible_version: \"2.1\"", "label": 0, "commit_name": "Fix licence and add some information in Readme"}
{"code": "tag: '{{default .t .tag}}' d_tag: '{{default .default_tag .tag}}' - docker run -t --rm {{.d_tag}} /bin/sh -c \"ansible --version\" - docker run -t --rm {{.d_tag}} /bin/sh -c \"ansible-lint --version\" - docker run -t --rm -v $(pwd)/tests:/ansible {{.d_tag}} /bin/sh -c \"ansible-galaxy install -r requirements.yml && ansible-lint --offline --project-dir . --exclude .cache playbook.yml\" - docker run -t --rm -v $(pwd)/tests:/ansible {{.d_tag}} /bin/sh -c \"ansible-galaxy install -r requirements.yml && ansible-playbook --limit local --vault-password-file vault-password-file.dist -i inventory playbook.yml\" tag: '{{default .t .tag}}' d_tag: '{{default .default_tag .tag}}' - docker run -t --rm -v $(pwd)/tests:/ansible {{.d_tag}} ansible-vault decrypt --vault-password-file vault-password-file.dist keys/key-test.pem - docker run -t --rm --network {{.ansible_network}} -v $(pwd)/tests:/ansible {{.d_tag}} /bin/sh -c \"ansible-galaxy install -r requirements.yml && ansible-playbook --limit remote --vault-password-file vault-password-file.dist -i inventory playbook.yml\"", "label": 1, "commit_name": "Fix IMG variable in sanity tests tasks"}
{"code": "img: '{{default .i .img}}' d_img: '{{default .default_tag .img}}' - docker run -t --rm {{.d_img}} /bin/sh -c \"ansible --version\" - docker run -t --rm {{.d_img}} /bin/sh -c \"ansible-lint --version\" - docker run -t --rm -v $(pwd)/tests:/ansible {{.d_img}} /bin/sh -c \"ansible-galaxy install -r requirements.yml && ansible-lint --offline --project-dir . --exclude .cache playbook.yml\" - docker run -t --rm -v $(pwd)/tests:/ansible {{.d_img}} /bin/sh -c \"ansible-galaxy install -r requirements.yml && ansible-playbook --limit local --vault-password-file vault-password-file.dist -i inventory playbook.yml\" img: '{{default .i .img}}' d_img: '{{default .default_tag .img}}' - docker run -t --rm -v $(pwd)/tests:/ansible {{.d_img}} ansible-vault decrypt --vault-password-file vault-password-file.dist keys/key-test.pem - docker run -t --rm --network {{.ansible_network}} -v $(pwd)/tests:/ansible {{.d_img}} /bin/sh -c \"ansible-galaxy install -r requirements.yml && ansible-playbook --limit remote --vault-password-file vault-password-file.dist -i inventory playbook.yml\"", "label": 0, "commit_name": "Fix IMG variable in sanity tests tasks"}
{"code": "- name: add rabbitmq user and set priveleges configure_priv=.* read_priv=.* write_priv=.*", "label": 1, "commit_name": "Make user permissions configurable. Fixes #39"}
{"code": "- name: add rabbitmq user and set privileges configure_priv={{ item.configure_priv | default('.*') }} read_priv={{ item.read_priv | default('.*') }} write_priv={{ item.write_priv | default('.*') }}", "label": 0, "commit_name": "Make user permissions configurable. Fixes #39"}
{"code": "become: yes become_user: gitlab-runner cmd: 'gitlab-runner --executor docker --docker-image \"{docker_image}\" --name \"{runner_name}\" --url \"{gitlab_url}\" --registration-token \"{registration_token}\"' creates: /var/lib/gitlab-runner/.gitlab-runner/config.toml", "label": 1, "commit_name": "fixes found due to end to end testing"}
{"code": "- name: enable gitlab-runner syslog lineinfile: path: /etc/conf.d/gitlab-runner regexp: '^\\s*gitlab_runner_opts=' line: 'gitlab_runner_opts=\"--config /etc/gitlab-runner/config.toml --working-directory /var/lib/gitlab-runner --service gitlab-runner --syslog\" # set by ansible' state: present - name: debug register debug: msg: \"gitlab-runner register --non-interactive --executor docker --docker-image \\\"{{docker_image}}\\\" --name \\\"{{runner_name}}\\\" --url \\\"{{gitlab_url}}\\\" --registration-token \\\"{{registration_token}}\\\"\" cmd: \"gitlab-runner register --non-interactive --run-untagged --executor docker --docker-image \\\"{{docker_image}}\\\" --name \\\"{{runner_name}}\\\" --url \\\"{{gitlab_url}}\\\" --registration-token \\\"{{registration_token}}\\\"\" creates: /etc/gitlab-runner/config.toml - name: adjust permissions the toml file: path: /etc/gitlab-runner/config.toml group: gitlab-runner mode: '0640' - name: adjust permissions on the folder file: path: /etc/gitlab-runner group: gitlab-runner mode: '0750'", "label": 0, "commit_name": "fixes found due to end to end testing"}
{"code": "when: \"ocp_ver != 3.11\" when: \"ocp_ver != 3.11\" when: \"ocp_ver == 3.11\"", "label": 1, "commit_name": "Fixing ocp_ver variable validation"}
{"code": "when: - ocp_ver == 3.11 when: - ocp_ver != 3.11 when: - ocp_ver == 3.11", "label": 0, "commit_name": "Fixing ocp_ver variable validation"}
{"code": "- es_enable_xpack and '\"security\" in es_xpack_features' - (es_enable_xpack and '\"security\" in es_xpack_features') and (es_version | version_compare('6.0.0', '>')) - (es_enable_xpack and '\"security\" in es_xpack_features') and (es_version | version_compare('6.0.0', '>')) and es_api_basic_auth_username is defined and list_keystore is defined and es_api_basic_auth_username == 'elastic' and 'bootstrap.password' not in list_keystore.stdout_lines when: (es_enable_xpack and '\"security\" in es_xpack_features') and ((es_users is defined and es_users.file is defined) or (es_roles is defined and es_roles.file is defined)) when: es_enable_xpack and '\"security\" in es_xpack_features'", "label": 1, "commit_name": "Fix conditionals introduced in #408"}
{"code": "- es_enable_xpack and \"security\" in es_xpack_features - (es_enable_xpack and \"security\" in es_xpack_features) and (es_version | version_compare('6.0.0', '>')) - (es_enable_xpack and \"security\" in es_xpack_features) and (es_version | version_compare('6.0.0', '>')) and es_api_basic_auth_username is defined and list_keystore is defined and es_api_basic_auth_username == 'elastic' and 'bootstrap.password' not in list_keystore.stdout_lines when: (es_enable_xpack and \"security\" in es_xpack_features) and ((es_users is defined and es_users.file is defined) or (es_roles is defined and es_roles.file is defined)) when: es_enable_xpack and \"security\" in es_xpack_features", "label": 0, "commit_name": "Fix conditionals introduced in #408"}
{"code": "repo: 'ssh://git@git.worobetz.ca:/srv/git/homedir.git'", "label": 1, "commit_name": "Fix merge conflict"}
{"code": "- name: copy in deploy key copy: src: id_ed25519.git dest: \"~/.ssh/id_ed25519.git\" mode: 0700 owner: sysadmin group: sysadmin repo: 'ssh://git@gitlab.com/cworobetz/home.git' key_file: '~/.ssh/id_ed25519.git'", "label": 0, "commit_name": "Fix merge conflict"}
{"code": "molecule_run_dir: \"{{ lookup('env', 'molecule_ephemeral_directory') }}\" path: \"{{ molecule_run_dir }}/tmp\" - name: create ca key privatekey_path: \"{{ ca_key.filename }}\" graylog_http_publish_uri: \"https://{{ hostvars[inventory_hostname]['ansible_eth0']['ipv4']['address'] }}/\" - name: set up ldap auth endpoint: \"localhost\" graylog_user: \"admin\" graylog_password: \"yourpassword\" search_pattern: \"(&(objectclass=inetorgperson)(uid={0}))\" tags: [\"ldap_config\"]", "label": 1, "commit_name": "fix: fixed issues with yamllint"}
{"code": "graylog_endpoint: \"{{ hostvars[inventory_hostname]['ansible_eth0']['ipv4']['address'] }}\" graylog_user: admin graylog_user_password: yourpassword path: \"cache/deploy-graylog\" - name: create ca keygraylog_external privatekey_path:: \"{{ ca_key.filename }}\" graylog_http_publish_uri: \"https://{{ graylog_endpoint }}\" - name: set up ladap auth endpoint: \"{{graylog_endpoint}}\" graylog_user: \"{{graylog_user}}\" graylog_password: \"{{graylog_user_password}}\" search_pattern: \"(&(objectclass=inetorgperson)(uid={0}))\" tags: [\"graylog_ldap_config\"] - name: \"debugaloo\" debug: var: graylog_endpoint tags: [\"graylog_input_config\"] - name: add syslog input dreamer_labs.graylog_modules.graylog_input_rsyslog: endpoint: \"{{ graylog_endpoint }}\" graylog_user: \"{{ graylog_user }}\" graylog_password: \"{{ graylog_user_password }}\" validate_certs: \"false\" action: \"create\" input_type: \"tcp\" title: \"rsyslog tcp\" global_input: \"true\" allow_override_date: \"true\" bind_address: \"0.0.0.0\" expand_structured_data: \"false\" force_rdns: \"false\" number_worker_threads: \"2\" port: \"1514\" recv_buffer_size: \"1048576\" store_full_message: \"true\" tags: [\"graylog_input_config\"]", "label": 0, "commit_name": "fix: fixed issues with yamllint"}
{"code": "- name: set trusted domain command: > php \"{{ occ_command }}\" config:system:set trusted_domains 1 --value={{ ansible_fqdn }} become: true become_user: www-data become_method: sudo - name: configure pretty urls command: > php \"{{ occ_command }}\" config:system:set overwrite.cli.url --value=https://{{ ansible_fqdn }} become: true become_user: www-data become_method: sudo - name: update htaccess for pretty urls command: > php \"{{ occ_command }}\" maintenance:update:htaccess become: true become_user: www-data become_method: sudo - name: configure cache command: > php \"{{ occ_command }}\" config:system:set memcache.local --value=\"\\oc\\memcache\\apcu\"", "label": 1, "commit_name": "Fix ansible-lint E301 errors"}
{"code": "args: creates: /var/www/nextcloud/config/config.php register: installer_ran - name: configure nextcloud block: - name: set trusted domain command: > php \"{{ occ_command }}\" config:system:set trusted_domains 1 --value={{ ansible_fqdn }} - name: configure pretty urls command: > php \"{{ occ_command }}\" config:system:set overwrite.cli.url --value=https://{{ ansible_fqdn }} - name: update htaccess for pretty urls command: > php \"{{ occ_command }}\" maintenance:update:htaccess - name: configure cache command: > php \"{{ occ_command }}\" config:system:set memcache.local --value=\"\\oc\\memcache\\apcu\" when: installer_ran is succeeded", "label": 0, "commit_name": "Fix ansible-lint E301 errors"}
{"code": "php_opcache_revalidate_freq: 2 # 30 en prod", "label": 1, "commit_name": "Role php-fpm: fix linting errors"}
{"code": "php_opcache_revalidate_freq: 2 # 30 en prod", "label": 0, "commit_name": "Role php-fpm: fix linting errors"}
{"code": "key_file: /home/dcadm1n/.ssh/deploy_key", "label": 1, "commit_name": "keyfile name fix"}
{"code": "key_file: /home/dcadm1n/.ssh/deo-moodle", "label": 0, "commit_name": "keyfile name fix"}
{"code": "- name: install pip name: python-pip", "label": 1, "commit_name": "Merge pull request #46 from C-J1/fix-issue-45"}
{"code": "- name: install python3-pip name: python3-pip", "label": 0, "commit_name": "Merge pull request #46 from C-J1/fix-issue-45"}
{"code": "region: '{{ stack_regeion }}'", "label": 1, "commit_name": "Fix typo"}
{"code": "region: '{{ stack_region }}'", "label": 0, "commit_name": "Fix typo"}
{"code": "- name: wrapper playbook for kitchen testing \"elasticsearch\" es_heap_size: \"1g\"", "label": 1, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "- name: standard test for single node setup. tests idempotence. es_heap_size: \"1g\" #do not add tests here. this test is run twice and confirms idempotency.", "label": 0, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "- name: restart firewalld", "label": 1, "commit_name": "fix some ansible-lint errors"}
{"code": "- name: restart firewalld", "label": 0, "commit_name": "fix some ansible-lint errors"}
{"code": "version: 2.0.1", "label": 1, "commit_name": "Updat ansible-docker-matrix (again) to pull in upload fix"}
{"code": "version: 2.0.2", "label": 0, "commit_name": "Updat ansible-docker-matrix (again) to pull in upload fix"}
{"code": "apt: name=subversion state=latest", "label": 1, "commit_name": "Make common stuff optional; fix nginx reload"}
{"code": "ignore_errors: yes ignore_errors: yes apt: name=subversion state=latest ignore_errors: yes", "label": 0, "commit_name": "Make common stuff optional; fix nginx reload"}
{"code": "command: microk8s.start", "label": 1, "commit_name": "add become: yes fix permission of .kube"}
{"code": "become: yes become: yes become: yes become: yes - name: update user become: yes user: name: vagrant groups: - microk8s - name: update .kube permission file: path: '~/.kube' owner: vagrant recurse: yes command: microk8s.start become: yes", "label": 0, "commit_name": "add become: yes fix permission of .kube"}
{"code": "satnogs_setup_ansible_url_unstable: 'https://gitlab.com/librespacefoundation/satnogs/satnogs-client-ansible.git'", "label": 1, "commit_name": "satnogs-setup: Fix overriding of Ansible URL and branch experimental defaults"}
{"code": "satnogs_setup_ansible_url_stable: 'https://gitlab.com/librespacefoundation/satnogs/satnogs-client-ansible.git' satnogs_setup_ansible_branch_stable: 'stable' satnogs_setup_ansible_url_unstable: '{{ satnogs_setup_ansible_url_stable }}'", "label": 0, "commit_name": "satnogs-setup: Fix overriding of Ansible URL and branch experimental defaults"}
{"code": "- xenial", "label": 1, "commit_name": "Fix playbooks for kubuntu focal with new additions"}
{"code": "- focal", "label": 0, "commit_name": "Fix playbooks for kubuntu focal with new additions"}
{"code": "- name: sensu user: sensu - name: test - name: policy vhost: sensu tags: \"federation-upstream-set=all\" - meta: flush_handlers", "label": 1, "commit_name": "Change item.name to item.vhost. Fix #31"}
{"code": "- vhost: sensu user: sensu - name: test - name: policy vhost: sensu tags: \"federation-upstream-set=all\" - meta: flush_handlers", "label": 0, "commit_name": "Change item.name to item.vhost. Fix #31"}
{"code": "- arch_dir: \"/var/lib/psql/backups\"", "label": 1, "commit_name": "Merge branch 'fix-db-path' into 'master'"}
{"code": "- arch_dir: \"/var/lib/pgsql/backups\"", "label": 0, "commit_name": "Merge branch 'fix-db-path' into 'master'"}
{"code": "enable_host_only_vpn: false # if true only allows inter vpn communication, no outside traffic allow_client_to_client: true # set to false to disallow clients communicating on the server", "label": 1, "commit_name": "Fix: tunneling not working correct"}
{"code": "enable_vpn_only_communication: false # if true only allows only inter vpn communication, no outside traffic", "label": 0, "commit_name": "Fix: tunneling not working correct"}
{"code": "name: postgresql-9.6 name: postgresql-9.6 state: started", "label": 1, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "become: yes name: postgresql-9.6 become: yes name: postgresql-9.6 state: started", "label": 0, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "tar_ball: \"enemon_{{ date_from }}_{{ date_to }}.tgz\" dest: \"{{ tar_ball }}\" src: \"{{ tar_ball }}\" path: \"{{ tar_ball }}\"", "label": 1, "commit_name": "Fix naming"}
{"code": "tar_ball: \"enemon_diff.tgz\" header: true dest: \"{{ enemon_bkp_dir }}/{{ outdir }}/{{ tar_ball }}\" src: \"{{ enemon_bkp_dir }}/{{ outdir }}/{{ tar_ball }}\" path: \"{{ enemon_bkp_dir }}/{{ outdir }}/{{ tar_ball }}\"", "label": 0, "commit_name": "Fix naming"}
{"code": "- name: enumerate all cluster hosts within the hosts file - name: find the designated host - name: waiting for microk8s to be ready on microk8s host master - name: get the microk8s join command from the microk8s master - name: get microk8s cluster nodes - name: waiting for microk8s to be ready on microk8s host node - name: set the microk8s join command on the microk8s node - name: configure cluster addons - name: define ip addresses for metallb to use - name: install metallb", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"microk8s: enumerate all cluster hosts within the hosts file\" - name: \"microk8s: find the designated host\" - name: \"microk8s: waiting for microk8s to be ready on microk8s host master\" - name: \"microk8s: get the microk8s join command from the microk8s master\" - name: \"microk8s: get microk8s cluster nodes\" - name: \"microk8s: waiting for microk8s to be ready on microk8s host node\" - name: \"microk8s: set the microk8s join command on the microk8s node\" - name: \"microk8s: configure cluster addons\" - name: \"microk8s: define ip addresses for metallb to use\" - name: \"microk8s: install metallb\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: installing essentials tags: yum,centos yum: name: \"{{ packages }}\" state: latest - name: install terraform on master node hosts: master become: true - name: create jcode user tags: always user: name: jcode group: root - name: add sudoers file for jcode tags: always copy: src: sudoer_jcode dest: /etc/sudoers.d/jcode owner: root group: root mode: 0440", "label": 1, "commit_name": "initialized jcode user, bootstrap script, and separated bootstrap essential tasks from yummy.yml to bootstrap.yml"}
{"code": "- name: installing essentials tags: yum,centos yum: name: \"{{ packages }}\" state: latest update_cache: yes changed_when: false - hosts: master - hosts: web_servers tasks: - name: copy html file for landing site tags: apache,apache2,http,httpd copy: src: landing.html dest: /var/www/html/index.html owner: root group: root mode: 0644", "label": 0, "commit_name": "initialized jcode user, bootstrap script, and separated bootstrap essential tasks from yummy.yml to bootstrap.yml"}
{"code": "docker push $dockerhub_username/$ci_project_name:ci_commit_short_sha", "label": 1, "commit_name": "fix typo"}
{"code": "docker push $dockerhub_username/$ci_project_name:$ci_commit_short_sha", "label": 0, "commit_name": "fix typo"}
{"code": "35366130313631336535386266343937373839343264343461663966363362376465656431363339 3066316534633931383963613064383733643134373432650a313939646166613130353035353831 37316334613731373865373436653234303735326264343364363733656436316131363865373061 6235623531366230340a333261306563323939353261643935393861373534373532613934623361 39653861316532323663623238326434656334323935373930366666613036343136643435383530 66616138623538623332336633303338636264663634396238613230633836613935383436643061 32656237323032383836646439393432383564323232336266653334373638386433613336623462 64656263363763666562346536613366366433333730663134653562633238633362343934396364 63326131633365393830616165306137393636333563353037343834336236666339336636363333 36363632333630623263643863633932316633373335326433363231663732646366323462316532 65613732326661623135386262333366343362333931613737306264613037316264343930613739 30326338386339656263326335633661333036343934633137306161393063633031303162646237 63373434616336373932363364633037336664643530633633656236313963326566653137643032 63646263643665623638623037383136646262366336636263366535396331313436326539636336 66366239333734313435333733633666313465303030323561313935636162373931616238616139 39613934313535336333393263373463373332333330636261373130333262646536393133626635 63373233353765303566643366306531306264323561313265313630623666313237653363363565 39373337376635353830396262346435386533383263623234636339663237626530383266333262 33306565623835316137646461323461656561396231363433396563366137363938336665393066 35353761313135303334333865666632383061353361663238336137386539343937666566353364 63323162346239636333353236623034383565666665646134313634393066663133613937623439 35623139303438363363316435666337353766633438363332323762623431316632333262346665 39303462623737626230633035343137343433383939663264393665303238646433363230343333 36616365363035346163396339333962353533323639313761343930336534636662313638376664 31346163343062666261356238353537353336643931386338373237343762373237386331666465 63303566663462663134663434363161623665353730353234366132306538666537373937383666 32646630653432383734323538376261376665666466333033663137326536313936306536653363 66346436626364633162", "label": 1, "commit_name": "Make it open source-able"}
{"code": "65616666393764653535653239323064333834656532343834303265346332353864343638616130 3731383639336162666565613164646566643535396130350a663830336435663365623064313434 37356665303031343731373562326234636630313831623864326538646337333737353162636439 3862316633383839610a353431666566653430626465333431313362613536636235653034353566 64666463626564623436326662343366393936623537303333613061663439353133653464316334 34303438636230636339336337623131346261656231326438653666346433343036333235356562 63373663363162363732643262643032323731613738623733383363626535623332323862386431 38613763376335353662616237643534383039303363396662333031346331373235623863376330 61323062393732373161303663383338353630303066363132376262633033616639363037636635 63303263383963346234303230313832333030393335636430643535346564356666363834343566 30346335326537356534356465613630373535343436626438323035656366343765333661353039 61376531643166373361383261653330613734366431363635303439306262616434613239366163 35366635353265393733313235636138656134653561346635356439396235353237643038363234 65396463613463333866326462383438373332666465646561613464613562353537303264303965 35633336396635323665343033376539333430346166303438666431373430646262353766343466 63316238373436626635646337316237393666333666303639383338316166356231313266623865 31323531623263376439366432393735343364313939323435656432316163393334383861623462 6336343239346464653836336265373839393934633438323931", "label": 0, "commit_name": "Make it open source-able"}
{"code": "when: ansible_os_family in ['rocky', 'redhat']", "label": 1, "commit_name": "Fix little bugs"}
{"code": "when: ansible_os_family in ['rocky', 'redhat']", "label": 0, "commit_name": "Fix little bugs"}
{"code": "- { regexp: '^#avoid_daily_autocommits=1', line: 'avoid_daily_autocommits=1' }", "label": 1, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "# - { regexp: '^#avoid_daily_autocommits=1', line: 'avoid_daily_autocommits=1' }", "label": 0, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "curl -h \"host: gitlab.90cos.cdl.af.mil\" \"{{ groups['gitlab_backend'][0] }}\"", "label": 1, "commit_name": "fix: fix stream and testing"}
{"code": "curl -k \"https://{{ groups['gitlab_backend'][0] }}\" register: proxy_gitlab_results - name: ensure proxy node returns shell: | curl \"https://gitlab.internal.test\" - name: assert proxy results return gitlab assert: that: proxy_gitlab_results.stdout == \"gitlab\"", "label": 0, "commit_name": "fix: fix stream and testing"}
{"code": "- puppetmaster", "label": 1, "commit_name": "puppetmaster: Add full provisioning"}
{"code": "- puppet-master - name: create directory for eyaml keys ansible.builtin.file: path: \"{{ puppet_home_dir }}/keys\" state: directory owner: puppet group: puppet mode: '0755' - name: deploy eyaml keys ansible.builtin.copy: src: \"{{ item }}\" dest: \"{{ puppet_home_dir }}/keys/\" owner: puppet group: puppet mode: '0700' diff: false loop: - private_key.pkcs7.pem - public_key.pkcs7.pem notify: - restart puppet-master notify: - restart puppet-master - name: set up .ssh directory ansible.builtin.file: path: \"{{ puppet_home_dir }}/.ssh\" state: directory owner: puppet group: puppet mode: '0700' - name: deploy ssh key for ca sync ansible.builtin.copy: src: \"{{ item }}\" dest: \"{{ puppet_home_dir }}/.ssh/{{ item }}\" owner: puppet group: puppet mode: '0600' diff: false loop: - id_ed25519 - id_ed25519.pub", "label": 0, "commit_name": "puppetmaster: Add full provisioning"}
{"code": "homeshick clone '{{ repo_url }}'", "label": 1, "commit_name": "Fix bug: repo_url variable is visible across tasks"}
{"code": "homeshick clone '{{ dotfiles_repo_url }}'", "label": 0, "commit_name": "Fix bug: repo_url variable is visible across tasks"}
{"code": "# defaults file for training", "label": 1, "commit_name": "fixes and add demo role"}
{"code": "# defaults file for training training_session_attendees: 0", "label": 0, "commit_name": "fixes and add demo role"}
{"code": "debug: msg=\"successful license operation often results in an exception. this is expected behaviour.\"", "label": 1, "commit_name": "typo fix"}
{"code": "debug: msg=\"successful license operation often results in an exception. this is expected behavior.\"", "label": 0, "commit_name": "typo fix"}
{"code": "failed_when: result.status == 200 or result.status == -1 failed_when: result.status == 200 or result.status == -1", "label": 1, "commit_name": "fix CI 4"}
{"code": "failed_when: not (result.status == 200 or result.status == -1) failed_when: not (result.status == 200 or result.status == -1)", "label": 0, "commit_name": "fix CI 4"}
{"code": "when: ansible_facts.distribution == 'ubuntu'", "label": 1, "commit_name": "fix: check the capability, not the platform"}
{"code": "when: \"ansible_facts['services'][unit] is defined\"", "label": 0, "commit_name": "fix: check the capability, not the platform"}
{"code": "name: \"{{ item }}\" with_items: \"{{ sshuttle_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ sshuttle_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "value: \"120\"", "label": 1, "commit_name": "Fix Gnome terminal width"}
{"code": "value: \"160\"", "label": 0, "commit_name": "Fix Gnome terminal width"}
{"code": "when: manage_file_users and (users_to_remove | length > 0)", "label": 1, "commit_name": "Fixes for conditional execution as a task"}
{"code": "when: manage_file_users and (users_to_remove | length > 0)", "label": 0, "commit_name": "Fixes for conditional execution as a task"}
{"code": "project: \"awx on k3s\" playbook: backup/ansible/project/backup.yml", "label": 1, "commit_name": "fix delegation in playbooks"}
{"code": "project: \"awx ansible\" playbook: playbooks/restore_local.yml", "label": 0, "commit_name": "fix delegation in playbooks"}
{"code": "when: on_success - changes:", "label": 1, "commit_name": "[FIX] wrong rules"}
{"code": "changes:", "label": 0, "commit_name": "[FIX] wrong rules"}
{"code": "url: \"https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\"", "label": 1, "commit_name": "refactor: start lint"}
{"code": "url: https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3", "label": 0, "commit_name": "refactor: start lint"}
{"code": "hosts: \"all\" - name: \"include labocbz.prepare_host\" tags: - \"labocbz.prepare_host\" ansible.builtin.include_role: name: \"labocbz.prepare_host\" loop: \"{{ groups['all'] }}\" loop: \"{{ groups['all'] }}\" # if you have any prepararion task - name: \"prepare\" hosts: \"all:&apache2\" gather_facts: true tasks: - name: \"include labocbz.prepare_host\" tags: - \"labocbz.prepare_host\" vars: prepare_host_system_users: \"{{ inv_prepare_host_apache_system_users }}\" ansible.builtin.include_role: name: \"labocbz.prepare_host\" - name: \"import cryptographic content if needed (cert)\" loop: \"{{ inv_add_apache_confs_configurations_cert_bundles }}\" loop_control: loop_var: bundle when: inv_add_apache_confs_configurations_cert_bundles is defined and bundle.type == \"cert\" ansible.builtin.copy: src: \"../../tests/certs/{{ bundle.name }}.zip\" dest: \"/tmp/{{ bundle.name }}.zip\" owner: \"root\" group: \"root\" mode: 0700 - name: \"import cryptographic content if needed (ca)\" loop: \"{{ inv_add_apache_confs_configurations_cert_bundles }}\" loop_control: loop_var: bundle when: inv_add_apache_confs_configurations_cert_bundles is defined and bundle.type == \"ca\" ansible.builtin.copy: src: \"../../tests/certs/{{ bundle.name }}\" dest: \"/tmp/{{ bundle.name }}\" owner: \"root\" group: \"root\" mode: 0700 - name: \"include labocbz.add_certificates\" tags: - \"labocbz.add_certificates\" loop: \"{{ inv_add_apache_confs_configurations_cert_bundles }}\" loop_control: loop_var: bundle when: inv_add_apache_confs_configurations_cert_bundles is defined vars: add_certificates_bundle_name: \"{{ bundle.name }}\" add_certificates_bundle_type: \"{{ bundle.type }}\" add_certificates_bundle_src: \"{{ bundle.src }}\" add_certificates_bundle_dest: \"{{ bundle.dest }}\" #add_certificates_bundle_src_user: \"{{ bundle.src_user }}\" #add_certificates_bundle_src_password: \"{{ bundle.src_password }}\" add_certificates_bundle_dest_user: \"{{ bundle.dest_user }}\" add_certificates_bundle_dest_group: \"{{ bundle.dest_group }}\" add_certificates_bundle_dest_mode: \"{{ bundle.dest_mode }}\" ansible.builtin.include_role: name: \"labocbz.add_certificates\" # if you have any prepararion task - name: \"prepare\" hosts: \"all:&jenkins-agent\" gather_facts: true tasks: prepare_host_system_users: \"{{ inv_prepare_host_apache_system_users }}\" loop: \"{{ inv_install_jenkins_agent_cert_bundles }}\" when: inv_install_jenkins_agent_cert_bundles is defined and bundle.type == \"cert\" loop: \"{{ inv_install_jenkins_agent_cert_bundles }}\" when: inv_install_jenkins_agent_cert_bundles is defined and bundle.type == \"ca\" - name: \"include labocbz.add_certificates\" tags: - \"labocbz.add_certificates\" loop: \"{{ inv_install_jenkins_agent_cert_bundles }}\" loop_control: loop_var: bundle when: inv_install_jenkins_agent_cert_bundles is defined vars: add_certificates_bundle_name: \"{{ bundle.name }}\" add_certificates_bundle_type: \"{{ bundle.type }}\" add_certificates_bundle_src: \"{{ bundle.src }}\" add_certificates_bundle_dest: \"{{ bundle.dest }}\" #add_certificates_bundle_src_user: \"{{ bundle.src_user }}\" #add_certificates_bundle_src_password: \"{{ bundle.src_password }}\" add_certificates_bundle_dest_user: \"{{ bundle.dest_user }}\" add_certificates_bundle_dest_group: \"{{ bundle.dest_group }}\" add_certificates_bundle_dest_mode: \"{{ bundle.dest_mode }}\" ansible.builtin.include_role: name: \"labocbz.add_certificates\"", "label": 1, "commit_name": "fix and refacto"}
{"code": "hosts: \"cicd-debian-11\" #- name: \"include cryptographic content var file\" # ansible.builtin.include_vars: \"../../tests/certs/main.yml\" loop: \"{{ groups['cicd-debian-11'] }}\" loop: \"{{ groups['cicd-debian-11'] }}\" prepare_host__apache_system_users: \"{{ inv_prepare_host__apache_system_users }}\" loop: \"{{ inv_add_apache_confs__configurations_cert_bundles }}\" when: inv_add_apache_confs__configurations_cert_bundles is defined and bundle.type == \"cert\" loop: \"{{ inv_add_apache_confs__configurations_cert_bundles }}\" when: inv_add_apache_confs__configurations_cert_bundles is defined and bundle.type == \"ca\"", "label": 0, "commit_name": "fix and refacto"}
{"code": "# it is unused by default but see ensemble-template.yaml for usage.", "label": 1, "commit_name": "update documentation"}
{"code": "# it is unused by default but see ensemble-template.yaml for instructions on how to include this instead of service_template.py.", "label": 0, "commit_name": "update documentation"}
{"code": "# defaults file for ansible-playbook-cfme-deploy", "label": 1, "commit_name": "Setting some intial variables and define a datastructure for a complete multiregion, mulizone implementation"}
{"code": "# defaults file for ansible-playbook-cfme-deploy miq_init_cmd: \"appliance_console_cli -i -r {{ miq_region }} -u {{ miq_db_username }} -p '{{ miq_db_password }}' -k -f\" cfme_deploy_initialpasswd: \"smartvm\" # this datastructure defines the complete cf infrastructure cfme_deploy_infra: - region: main zone: - webui: - server: servera - server: serverb - selfservice - server: serverc - vcenter: - server: serverd - azure: - server: servere", "label": 0, "commit_name": "Setting some intial variables and define a datastructure for a complete multiregion, mulizone implementation"}
{"code": "mode: 0755 command: /usr/bin/code --install-extension rust-lang.rust-analyzer", "label": 1, "commit_name": "refactor: lint"}
{"code": "mode: \"0755\" mode: \"0755\" ansible.builtin.command: /usr/bin/code --install-extension rust-lang.rust-analyzer", "label": 0, "commit_name": "refactor: lint"}
{"code": "action: mysql_user user=root password=$mysql_root_password host=localhost - name: mysql | delete anonymous mysql server user for $server_hostname action: mysql_user user=\"\" host=\"$server_hostname\" state=\"absent\" action: mysql_user user=\"root\" password=\"$mysql_root_password\" host=\"::1\" action: mysql_user user=\"root\" password=\"$mysql_root_password\" host=\"127.0.0.1\" action: mysql_user user=\"root\" password=\"$mysql_root_password\" host=\"localhost\" - name: mysql | secure the mysql root user for $server_hostname domain action: mysql_user user=\"root\" password=\"$mysql_root_password\" host=\"$server_hostname\" tags: common", "label": 1, "commit_name": "Removing legacy variable substitution $var and replacing with {{}} due to deprecation"}
{"code": "action: mysql_user user=root password={{ mysql_root_password }} host=localhost - name: mysql | delete anonymous mysql server user for {{ server_hostname }} action: mysql_user user=\"\" host=\"{{ server_hostname }} state=\"absent\" action: mysql_user user=\"root\" password=\"{{ mysql_root_password }}\" host=\"::1\" action: mysql_user user=\"root\" password=\"{{ mysql_root_password }}\" host=\"127.0.0.1\" action: mysql_user user=\"root\" password=\"{{ mysql_root_password }}\" host=\"localhost\" - name: mysql | secure the mysql root user for {{ server_hostname }} domain action: mysql_user user=\"root\" password=\"{{ mysql_root_password }}\" host=\"{{ server_hostname }}\" tags: common", "label": 0, "commit_name": "Removing legacy variable substitution $var and replacing with {{}} due to deprecation"}
{"code": "community.general.system.ufw: community.general.system.ufw: community.general.system.ufw:", "label": 1, "commit_name": "Merge branch '116-deprecation-warning-wrong-use-of-internal-ref-for-ufw-module' into 'master'"}
{"code": "community.general.ufw: community.general.ufw: community.general.ufw:", "label": 0, "commit_name": "Merge branch '116-deprecation-warning-wrong-use-of-internal-ref-for-ufw-module' into 'master'"}
{"code": "dest: /etc/my.cnf notify: \"restart ${{ mysqlservice }}\" - name: \"deletes anonymous mysql server user for localhost\" mysql_user: user: \"\" state: \"absent\" login_user: root login_password: \"{{ mysql_root_pass }}\" port: \"${{ mysql_port }}/tcp\"", "label": 1, "commit_name": "Fix path and variable ref"}
{"code": "dest: /root/.my.cnf notify: \"restart {{ mysqlservice }}\" - name: \"deletes anonymous mysql server user for localhost\" mysql_user: user: \"\" state: \"absent\" login_user: root login_password: \"{{ mysql_root_pass }}\" port: \"{{ mysql_port }}/tcp\"", "label": 0, "commit_name": "Fix path and variable ref"}
{"code": "- cd ansible/playbooks/nginx_proxy", "label": 1, "commit_name": "fix: fix stream and testing"}
{"code": "- cd nginx_proxy", "label": 0, "commit_name": "fix: fix stream and testing"}
{"code": "- name: a playbook to remove a specified package - name: remove a package name: tree", "label": 1, "commit_name": "Fix variables"}
{"code": "- name: a playbook to install a specified package - name: install a package name: \"{{ package }}\"", "label": 0, "commit_name": "Fix variables"}
{"code": "regexp: '^%wheel' line: '%wheel all=(all) nopasswd: all' validate: '/usr/sbin/visudo -cf %s' regexp: '^#?permitrootlogin' line: 'permitrootlogin prohibit-password' tags: ssh-keys tags: ssh-keys tags: ssh-keys tags: \"upgrade\" tags: \"upgrade\"", "label": 1, "commit_name": "Fix formatting in VPS set-up task file"}
{"code": "regexp: \"^%wheel\" line: \"%wheel all=(all) nopasswd: all\" validate: \"/usr/sbin/visudo -cf %s\" regexp: \"^#?permitrootlogin\" line: \"permitrootlogin prohibit-password\" tags: - ssh-keys tags: - ssh-keys tags: - ssh-keys tags: - upgrade tags: - upgrade", "label": 0, "commit_name": "Fix formatting in VPS set-up task file"}
{"code": "author: your name description: your role description company: your company (optional)", "label": 1, "commit_name": "Fixed typo"}
{"code": "author: crazyusb description: sysadmin company: yuna", "label": 0, "commit_name": "Fixed typo"}
{"code": "{ script: prop_dnatpr, path: commun/tables } ], { script: prop_type_filiation, path: commun/tables } ], { script: prop_ccocac, path: commun/tables } ],", "label": 1, "commit_name": "Fix ansible dict, broken in 1a50c468"}
{"code": "{ script: prop_dnatpr, path: commun/tables }, { script: prop_type_filiation, path: commun/tables }, { script: prop_ccocac, path: commun/tables },", "label": 0, "commit_name": "Fix ansible dict, broken in 1a50c468"}
{"code": "- name: https://gitlab.com/my0373-ansible/playbooks/ansible-fedora-laptop.git", "label": 1, "commit_name": "Fixed typo in requirements.yml"}
{"code": "- name: https://gitlab.com/my0373-ansible/collections/my0373/ansible-my0373-fedora.git", "label": 0, "commit_name": "Fixed typo in requirements.yml"}
{"code": "register: self_signed_crt register: self_signed_key name: \"{{ item }}\" with_items: ['nginx']", "label": 1, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "register: self_signed_crt register: self_signed_key name: ['nginx']", "label": 0, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "loop: \"{{ inv_install_haproxy_cert_bundles }}\" when: inv_install_haproxy_cert_bundles is defined loop: \"{{ add_haproxy_http_confs_configurations }}\" destination_port: \"{{ conf.port }}\"", "label": 1, "commit_name": "refacto, iptables, fixes"}
{"code": "loop: \"{{ inv_haproxy_cert_bundles }}\" when: inv_haproxy_cert_bundles is defined - name: \"start haproxy\" ansible.builtin.meta: flush_handlers - name: \"start haproxy\" ansible.builtin.meta: flush_handlers - name: \"include labocbz.add_haproxy_bdd_confs\" tags: - \"labocbz.add_haproxy_bdd_confs\" vars: add_haproxy_bdd_confs_confs_path: \"{{ inv_add_haproxy_bdd_confs_confs_path }}\" add_haproxy_bdd_confs_configurations: \"{{ inv_add_haproxy_bdd_confs_configurations }}\" ansible.builtin.include_role: name: \"labocbz.add_haproxy_bdd_confs\" loop: \"{{ inv_add_haproxy_http_confs_configurations }}\" destination_port: \"{{ conf.frontend.port }}\"", "label": 0, "commit_name": "refacto, iptables, fixes"}
{"code": "- name: \"download windows 10 from microsoft\" get_url: url: \"{{ windows_10_iso }}\" dest: /usr/share/virtualbox", "label": 1, "commit_name": "Uncomment code from ansible roles"}
{"code": "#- name: \"download windows 10 from microsoft\" # get_url: # url: \"{{ windows_10_iso }}\" # dest: /usr/share/virtualbox", "label": 0, "commit_name": "Uncomment code from ansible roles"}
{"code": "- name: enable selinux policy: targeted state: enforcing", "label": 1, "commit_name": "add new hardening role and make playbooks intentionally less secure"}
{"code": "- name: disable selinux state: disabled", "label": 0, "commit_name": "add new hardening role and make playbooks intentionally less secure"}
{"code": "- name: \"prepare docker\"", "label": 1, "commit_name": "fix typo"}
{"code": "- name: \"prepare apache2\"", "label": 0, "commit_name": "fix typo"}
{"code": "- name: update apt packages cache apt: update_cache={{ update_apt_cache }} cache_valid_time=86400 - name: perform aptitude safe-upgrade apt: upgrade=yes when: run_aptitude_safe_upgrade is defined and run_aptitude_safe_upgrade - name: add user user: name=\"{{ server_user }}\" shell=\"{{ shell }}\" password=\"{{ server_user_password }}\" when: server_user != \"root\" - name: add authorized_keys for the user authorized_key: user={{ server_user }} key=\"{{ lookup('file', item) }}\" with_items: - \"{{ user_public_keys }}\" - name: install sudo apt: name=sudo update_cache={{ update_apt_cache }} state=present cache_valid_time=86400 - name: add user to sudoers lineinfile: dest=/etc/sudoers regexp=\"{{ server_user }} all\" line=\"{{ server_user }} all=(all) all\" state=present # unattended upgrades settings - name: install unattended upgrades apt: update_cache={{ update_apt_cache }} state=installed pkg=unattended-upgrades when: enable_unattended_upgrades is defined and enable_unattended_upgrades - name: set up unattended upgrades copy: src=apt_periodic dest=/etc/apt/apt.conf.d/10periodic - name: automatically remove unused dependencies when: enable_unattended_upgrades is defined and enable_unattended_upgrades lineinfile: dest=/etc/apt/apt.conf.d/50unattended-upgrades regexp=\"unattended-upgrade::remove-unused-dependencies\" line=\"unattended-upgrade::remove-unused-dependencies \\\"true\\\";\" state=present create=yes # uncomplicated firewall settings - name: install uncomplicated firewall apt: update_cache={{ update_apt_cache }} state=installed pkg=ufw when: enable_ufw is defined and enable_ufw # allow only ssh and http(s) ports - name: allow ssh and http(s) connections ufw: rule=allow port={{ item }} with_items: - \"{{ ufw_allowed_ports }}\" when: enable_ufw is defined and enable_ufw - name: enable ufw/firewall ufw: state=enabled policy=deny # fail2ban settings - name: install fail2ban apt: update_cache={{ update_apt_cache }} state=installed pkg=fail2ban when: enable_fail2ban is defined and enable_fail2ban - name: set up fail2ban command: cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local creates=/etc/fail2ban/jail.local notify: restart fail2ban - name: limit su access to sudo group command: dpkg-statoverride --update --add root sudo 4750 /bin/su register: limit_su_res failed_when: limit_su_res.rc != 0 and (\"already exists\" not in limit_su_res.stderr) changed_when: limit_su_res.rc == 0 - name: disallow password authentication lineinfile: dest=/etc/ssh/sshd_config regexp=\"^passwordauthentication\" line=\"passwordauthentication no\" state=present notify: restart ssh - name: allow ssh only for primary user lineinfile: dest=/etc/ssh/sshd_config regexp=\"^allowusers\" line=\"allowusers {{ server_user }}\" state=present notify: restart ssh - name: disallow root ssh access lineinfile: dest=/etc/ssh/sshd_config regexp=\"^permitrootlogin\" line=\"permitrootlogin no\" state=present notify: restart ssh when: server_user != \"root\" - name: delete root password action: shell passwd -d root notify: restart ssh when: server_user != \"root\"", "label": 1, "commit_name": "Split security role tasks into separate tasks."}
{"code": "- include: perform_aptitude_dist_upgrade.yml when: perform_aptitude_dist_upgrade is defined and perform_aptitude_dist_upgrade - include: force_ssh_authentication.yml when: force_ssh_authentication is defined and force_ssh_authentication - include: create_non_root_sudo_user.yml - include: setup_unattended_upgrades.yml - include: setup_uncomplicated_firewall.yml - include: setup_fail2ban.yml", "label": 0, "commit_name": "Split security role tasks into separate tasks."}
{"code": "when: not enable_host_only_vpn", "label": 1, "commit_name": "Fix: tunneling not working correct"}
{"code": "- name: enable ipv4 forward without reboot shell: echo 1 > /proc/sys/net/ipv4/ip_forward when: not enable_vpn_only_communication", "label": 0, "commit_name": "Fix: tunneling not working correct"}
{"code": "url: \"http://{{ inventory_hostname }}:{{ inv_install_prometheus__port }}\" url: \"http://{{ inventory_hostname }}:{{ inv_install_prometheus__port }}\" url: \"https://{{ inventory_hostname }}:{{ inv_install_prometheus__port }}\" url: \"https://{{ inventory_hostname }}:{{ inv_install_prometheus__port }}\" host: \"127.0.0.1\" host: \"{{ inventory_hostname }}\" host: \"{{ inventory_hostname }}\" host: \"{{ inventory_hostname }}\" url: \"http://{{ inventory_hostname }}:{{ inv_add_apache_confs__http_listen_port }}/\" url: \"https://{{ inventory_hostname }}:{{ inv_add_apache_confs__https_listen_port }}/\"", "label": 1, "commit_name": "fix CI 1"}
{"code": "url: \"http://localhost:{{ inv_install_prometheus__port }}\" url: \"http://localhost:{{ inv_install_prometheus__port }}\" url: \"https://localhost:{{ inv_install_prometheus__port }}\" url: \"https://localhost:{{ inv_install_prometheus__port }}\" host: \"localhost\" host: \"localhost\" host: \"localhost\" host: \"localhost\" url: \"http://localhost:{{ inv_add_apache_confs__http_listen_port }}/\" url: \"https://localhost:{{ inv_add_apache_confs__https_listen_port }}/\"", "label": 0, "commit_name": "fix CI 1"}
{"code": "deb: /tmp/gitlab-runner_{{ arch.stdout }}.deb", "label": 1, "commit_name": "-> Solve issue \ud83d\udca1:"}
{"code": "- name: check if gitlab-runner is installed command: gitlab-runner -v register: gitlab_runner ignore_errors: true - debug: var=gitlab_runner when: gitlab_runner.failed | bool deb: /tmp/gitlab-runner_{{ arch.stdout }}.deb when: gitlab_runner.failed | bool", "label": 0, "commit_name": "-> Solve issue \ud83d\udca1:"}
{"code": "state: directorry", "label": 1, "commit_name": "Fix typo"}
{"code": "state: directory", "label": 0, "commit_name": "Fix typo"}
{"code": "with_items: \"{{users_to_remove}}\" when: manage_native_users and es_users.native.keys() > 0 with_dict: \"{{es_users.native}}\" with_items: \"{{roles_to_remove}}\" when: manage_native_roles and es_roles.native.keys() > 0 with_dict: \"{{es_roles.native}}\"", "label": 1, "commit_name": "Fixes for conditional execution as a task"}
{"code": "with_items: \"{{users_to_remove | default([]) }}\" - set_fact: native_users={{ es_users.native }} when: manage_native_users and es_users.native.keys() > 0 when: manage_native_users and native_users.keys() > 0 with_dict: \"{{native_users | default({}) }}\" with_items: \"{{roles_to_remove | default([]) }}\" - set_fact: native_roles={{ es_roles.native }} when: manage_native_roles and es_roles.native.keys() > 0 when: manage_native_roles and native_roles.keys() > 0 with_dict: \"{{ native_roles | default({})}}\"", "label": 0, "commit_name": "Fixes for conditional execution as a task"}
{"code": "name: \"{{ item }}\" with_items: \"{{ glow_python_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ glow_python_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "shell: echo \"{{rake_result.stdout_lines[3] | regex_replace('^.*\\\"password:\\s*(.*)\\\".*$','\\1')}}\" register: admin_password content=\"{{ admin_password.stdout }}\\n\" when: admin_password.changed", "label": 1, "commit_name": "fix ansible lint ANSIBLE0013: remove shell usage"}
{"code": "set_fact: admin_password: \"{{rake_result.stdout_lines[3] | regex_replace('^.*\\\"password:\\\\s*(.*)\\\".*$','\\\\1')}}\" content=\"{{ admin_password }}\\n\" when: rake_result.changed", "label": 0, "commit_name": "fix ansible lint ANSIBLE0013: remove shell usage"}
{"code": "line: 192.168.1.69 hualcoyotl uuid=9836683c36681d8e /media/descargas ntfs defaults 0 0 uuid=\"5aa5a70d-92fd-431d-9bef-dd229128ab4c\" /media/backup xfs defaults 0 0 uuid=6cc8a668533cd38b /mnt/bobac_ntfs ntfs noauto 0 0 uuid=4492-e896 /mnt/ventoy exfat defaults,noauto,uid=1000,gid=1000 0 0 hualcoyotl:/ /home/tockar/nfs nfs defaults,timeo=900,retrans=5,_netdev,user 0 0 state: present key: https://brave-browser-rpm-release.s3.brave.com/brave-core.asc state: present key: https://gitlab.com/paulcarroty/vscodium-deb-rpm-repo/-/raw/master/pub.gpg - borg - name: unpack borg latest backup cmd:", "label": 1, "commit_name": "ADD way to handle borg backup, small fixes"}
{"code": "line: 192.168.1.69 hualcoyotl uuid=9836683c36681d8e /media/descargas ntfs defaults 0 0 uuid=\"5aa5a70d-92fd-431d-9bef-dd229128ab4c\" /media/backup xfs defaults 0 0 uuid=6cc8a668533cd38b /mnt/bobac_ntfs ntfs noauto 0 0 uuid=4492-e896 /mnt/ventoy exfat defaults,noauto,uid=1000,gid=1000 0 0 hualcoyotl:/ /home/rtokarski/nfs nfs defaults,timeo=900,retrans=5,_netdev,user 0 0 rpm_key: state: present key: https://brave-browser-rpm-release.s3.brave.com/brave-core.asc rpm_key: state: present key: https://gitlab.com/paulcarroty/vscodium-deb-rpm-repo/-/raw/master/pub.gpg mode: 0644 - borgbackup - name: determine if extracting a local borg backup is necessary command: ls /home/rtokarski register: ls changed_when: '\".borgexcuses\" not in ls.stdout' notify: borg-extract handlers: - name: borg-extract shell: cmd: > borg extract /media/backup/borg/castleyankee::$(borg list /media/backup/borg/castleyankee --format '{archive}{nl} | head -n1') chdir: /home/rtokarski when: ls.changed ...", "label": 0, "commit_name": "ADD way to handle borg backup, small fixes"}
{"code": "- name: reset owner of ssh config - name: reset owner of ssh config - name: reset owner of ssh config", "label": 1, "commit_name": "Naming fix"}
{"code": "- name: reset owner of ssh deo-moodle - name: set owner of ssh config - name: set owner of ssh deo-moodle", "label": 0, "commit_name": "Naming fix"}
{"code": "# when the local kernel version does not match the remote version # the kernel will need to updated and a manual reboot required bluetooth_enabled: false", "label": 1, "commit_name": "fixed bugs"}
{"code": "# when the local kernel version does not match the remote version, # the kernel will need to be updated and a manual reboot will be required bluetooth_enabled: 'false'", "label": 0, "commit_name": "fixed bugs"}
{"code": "- name: verify and add the new runners", "label": 1, "commit_name": "-> Solve issue \ud83d\udca1:"}
{"code": "- name: verify and add new runners", "label": 0, "commit_name": "-> Solve issue \ud83d\udca1:"}
{"code": "- import_playbook: type_install_base.yaml - import_playbook: type_install_openvpn.yaml - import_playbook: type_create_client.yaml", "label": 1, "commit_name": "Change: A few linting errors"}
{"code": "- name: install base system import_playbook: type_install_base.yaml - name: install openvpn import_playbook: type_install_openvpn.yaml - name: setup cients import_playbook: type_create_client.yaml", "label": 0, "commit_name": "Change: A few linting errors"}
{"code": "mesos_playbook_version: \"0.3.5\"", "label": 1, "commit_name": "Merge pull request #51 from ernestas-poskus/fix/os_version_major_parsing_and_7_epel_release"}
{"code": "mesos_playbook_version: \"0.3.6\"", "label": 0, "commit_name": "Merge pull request #51 from ernestas-poskus/fix/os_version_major_parsing_and_7_epel_release"}
{"code": "ansible.builtin.user: \"{{ ansible_user }}\"", "label": 1, "commit_name": "lint fixes"}
{"code": "user: \"{{ ansible_user }}\"", "label": 0, "commit_name": "lint fixes"}
{"code": "deb: \"https://github.com/kong/insomnia/releases/download/core%402021.7.2/insomnia.core-2021.7.2.deb\"", "label": 1, "commit_name": "refactor: start lint"}
{"code": "deb: https://github.com/kong/insomnia/releases/download/core%402021.7.2/insomnia.core-2021.7.2.deb", "label": 0, "commit_name": "refactor: start lint"}
{"code": "- name: add brotli module to start of nginx config", "label": 1, "commit_name": "Fix typo install_brotli"}
{"code": "- name: add brotli module to the start of nginx config", "label": 0, "commit_name": "Fix typo install_brotli"}
{"code": "include: \"roles/minemeld/tasks/{{distribution_pre_task}}.yml\" - include: structure.yml - include: prototypes.yml - include: core.yml - include: webui.yml include: \"roles/minemeld/tasks/{{distribution_post_task}}.yml\"", "label": 1, "commit_name": "fixed a typo and updated to remove items deprecated as of ansible 2.4.1.0"}
{"code": "include_tasks: \"roles/minemeld/tasks/{{distribution_pre_task}}.yml\" - import_tasks: structure.yml - import_tasks: prototypes.yml - import_tasks: core.yml - import_tasks: webui.yml include_tasks: \"roles/minemeld/tasks/{{distribution_post_task}}.yml\"", "label": 0, "commit_name": "fixed a typo and updated to remove items deprecated as of ansible 2.4.1.0"}
{"code": "smtp_smarthost: 'localhost:25' smtp_from: {{alertmanager_smtp_from}} receiver: 'team-sydit-pushover' repeat_interval: 3h severity: 'critical' severity: 'warning' - name: 'team-sydit-mail' - to: {{alertmanager_receiver_email}} - name: team-sydit-pushover - user_key: {{pushover_userkey}} token: {{pushover_token}} - {{template}}", "label": 1, "commit_name": "fixes in ansible syntax. using more default values and making environment deployment easier."}
{"code": "smtp_smarthost: \"{{ alertmanager_smtp_smarthost | default('localhost:25') }}\" smtp_from: {{ alertmanager_smtp_from | default('root@localhost') }} receiver: {{ alertmanager_team_name | default(\"default-team\") }} repeat_interval: 1h severity: critical severity: warning - name: {{ alertmanager_team_name | default('default-team') }} - to: {{alertmanager_receiver_email | default('root@localhost') }} {% if pushover_userkey %} - name: {{ alertmanager_team_name }} - user_key: {{ pushover_userkey }} token: {{ pushover_token }} {% endif %} - {{ template }}", "label": 0, "commit_name": "fixes in ansible syntax. using more default values and making environment deployment easier."}
{"code": "- include: play_install_ansible.yml - include: play_install_java.yml", "label": 1, "commit_name": "Updated local.yml to install software and modifying permissions of private file"}
{"code": "remote_user: root roles: - git - java", "label": 0, "commit_name": "Updated local.yml to install software and modifying permissions of private file"}
{"code": "- set_fact: list_command=\"list\" #list currently installed plugins - ignore xpack if > v 2.0 shell: \"{{es_home}}/bin/elasticsearch-plugin list | grep -ve 'x-pack'\" failed_when: \"'error' in installed_plugins.stdout\" with_items: \"{{ installed_plugins.stdout_lines | default([]) }}\" when: es_plugins_reinstall and installed_plugins.stdout_lines | length > 0 and not 'no plugin detected' in installed_plugins.stdout_lines[0]", "label": 1, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "- set_fact: list_command=\"\" #if we are reinstalling all plugins, e.g. to a version change, we need to remove all plugins (inc. x-pack) to install any plugins. otherwise we don't consider x-pack so the role stays idempotent. - set_fact: list_command=\"| grep -ve 'x-pack'\" when: not es_plugins_reinstall #list currently installed plugins. we have to list the directories as the list commmand fails if the es version is different than the plugin version. shell: \"ls {{es_home}}/plugins {{list_command}}\" #if es_plugins_reinstall is set to true we remove all plugins - set_fact: plugins_to_remove=\"{{ installed_plugins.stdout_lines | default([]) }}\" when: es_plugins_reinstall #if the plugins listed are different than those requested, we remove those installed but not listed in the config - set_fact: plugins_to_remove=\"{{ installed_plugins.stdout_lines | difference(es_plugins | json_query('es_plugins[*].plugin')) | default([]) }}\" when: not es_plugins_reinstall with_items: \"{{ plugins_to_remove | default([]) }}\" when: es_plugins_reinstall and plugins_to_remove | length > 0", "label": 0, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "dotfiles_repo: git@github.com:geerlingguy/dotfiles.git", "label": 1, "commit_name": "Use https dotfiles git repo URL to not require auth."}
{"code": "dotfiles_repo: https://github.com/geerlingguy/dotfiles.git", "label": 0, "commit_name": "Use https dotfiles git repo URL to not require auth."}
{"code": "docker_compose_version: \"2.24.1\"", "label": 1, "commit_name": "feat: Move Docker registry as optional install, fix docker compose version"}
{"code": "docker_compose_version: \"v2.24.1\"", "label": 0, "commit_name": "feat: Move Docker registry as optional install, fix docker compose version"}
{"code": "- name: unmount the root filesystem from the rhel9 image", "label": 1, "commit_name": "Correct minor typo"}
{"code": "- name: mount the root filesystem from the rhel9 image", "label": 0, "commit_name": "Correct minor typo"}
{"code": "collections: - name: \"https://github.com/mbank59/ansible-graylog-modules.git\"", "label": 1, "commit_name": "fix: fixed issues with yamllint"}
{"code": "collections: - name: \"https://github.com/mbank59/ansible-graylog-modules.git\"", "label": 0, "commit_name": "fix: fixed issues with yamllint"}
{"code": "shell: dpkg-query -w rabbitmq-server | awk '{print $nf}'", "label": 1, "commit_name": "crossplatform way to check the version of rabbitmq"}
{"code": "shell: rabbitmqctl status | awk '{print $nf}'", "label": 0, "commit_name": "crossplatform way to check the version of rabbitmq"}
{"code": "shell: \"etcdctl -c https://{{ hostvars[groups['etcd-sec'][0]].ansible_default_ipv4.address }}:2379 --cert-file /etc/etcd/peer.crt --key-file /etc/etcd/peer.key --ca-file /etc/etcd/ca.crt member add {{ ansible_hostname }} https://{{ ansible_default_ipv4.address }}:2380 2>/dev/null | grep '^etcd_initial_cluster='\" - name: add the configuration lines for etcd_name - name: add the configuration lines for etcd_initial_cluster - name: add the configuration lines for etcd_initial_cluster_state", "label": 1, "commit_name": "mend"}
{"code": "shell: \"etcdctl -c https://{{ hostvars[groups['etcd-sec'][0]].ansible_default_ipv4.address }}:2379 --cert-file /etc/etcd/peer.crt --key-file /etc/etcd/peer.key --ca-file /etc/etcd/ca.crt member add {{ ansible_hostname }} https://{{ ansible_default_ipv4.address }}:2380 2>/dev/null | grep '^etcd_initial_cluster='\" - name: add the configuration lines for etcd_name - name: add the configuration lines for etcd_initial_cluster - name: add the configuration lines for etcd_initial_cluster_state", "label": 0, "commit_name": "mend"}
{"code": "- debug: var: ansible_facts.services - debug: msg: networkmanager is installed! when: \"'networkmanager' in ansible_facts.services\" when: \"'networkmanager' in ansible_facts.services\" name: networkmanager", "label": 1, "commit_name": "fix: use full name NetworkManager.service"}
{"code": "when: \"'networkmanager.service' in ansible_facts.services\" name: networkmanager.service", "label": 0, "commit_name": "fix: use full name NetworkManager.service"}
{"code": "# satnogs client ansible configuration example", "label": 1, "commit_name": "Fix references to old project name"}
{"code": "# satnogs ansible configuration example", "label": 0, "commit_name": "Fix references to old project name"}
{"code": "- ansible-role-vscode", "label": 1, "commit_name": "Added role and some fix from ansible-lint"}
{"code": "name: setup workstation - ansible-role-vscode - ansible-role-worktools - ansible-role-tailscale", "label": 0, "commit_name": "Added role and some fix from ansible-lint"}
{"code": "register: firewalld_tcp{{logstash_syslog_port}}_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_tcp{{logstash_syslog_port}}_exists.rc != 0 register: iptables_tcp5044_exists failed_when: iptables_tcp{{logstash_syslog_port}}_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_tcp5044_exists.stdout|int == 0", "label": 1, "commit_name": "Multiple Fixes: Firewall and Ansible Lint"}
{"code": "register: firewalld_logstash_syslog_port_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_logstash_syslog_port_exists.rc != 0 register: iptables_logstash_syslog_port_exists failed_when: iptables_logstash_syslog_port_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_logstash_syslog_port_exists.stdout|int == 0", "label": 0, "commit_name": "Multiple Fixes: Firewall and Ansible Lint"}
{"code": "- name: \"converge\" hosts: \"cicd-debian-11\" tasks: - name: \"include labocbz.prepare_host\" tags: - \"labocbz.prepare_host\" vars: prepare_host__users: \"{{ inv_prepare_host__users }}\" prepare_host__packages_removed: \"{{ inv_prepare_host__packages_removed }}\" prepare_host__packages_installed: \"{{ inv_prepare_host__packages_installed }}\" prepare_host__system_users: \"{{ inv_prepare_host__system_users }}\" ansible.builtin.include_role: name: \"labocbz.prepare_host\"", "label": 1, "commit_name": "fix CI"}
{"code": "- name: \"include tool.bootstrap_playbook playbook\" tags: - \"tool.bootstrap_playbook\" vars: tower_env: \"cicd-debian-11\" ansible.builtin.import_playbook: \"../../playbook.yml\"", "label": 0, "commit_name": "fix CI"}
{"code": "- \"ansible-playbook --extra-vars '{\\\"configure_sudoers\\\":\\\"false\\\"}' main.yml\"", "label": 1, "commit_name": "Fixes #24: Add travis_wait to fix builds that take longer than 10 minutes."}
{"code": "- \"travis_wait 30 ansible-playbook --extra-vars '{\\\"configure_sudoers\\\":\\\"false\\\"}' main.yml\"", "label": 0, "commit_name": "Fixes #24: Add travis_wait to fix builds that take longer than 10 minutes."}
{"code": "docker_nginx_config_root: \"{{ docker_nginx_config_root }}\" docker_nginx_confd: \"{{ docker_nginx_confd }}\" docker_nginx_http: \"{{ docker_nginx_http }}\" docker_nginx_ssl: \"{{ docker_nginx_ssl }}\" docker_nginx_logs: \"{{ docker_nginx_logs }}\" - \"{{ docker_nginx_config_root }}\" - \"{{ docker_nginx_confd }}\" - \"{{ docker_nginx_http }}\" - \"{{ docker_nginx_ssl }}\" - \"{{ docker_nginx_logs }}\" image: \"{{ docker_image_nginx }}:{{ docker_image_nginx_tag }}\" - \"{{ docker_nginx_confd }}:/etc/nginx/conf.d:ro\" - \"{{ docker_nginx_http }}:/http:ro\" - \"{{ docker_nginx_ssl }}:/ssl-certs:ro\" - \"{{ docker_nginx_logs }}:/var/log/nginx:rw\" image: \"{{ docker_image_nginx }}:{{ docker_image_nginx_tag }}\" - \"{{ docker_nginx_confd }}:/etc/nginx/conf.d:ro\" - \"{{ docker_nginx_http }}:/http:ro\" - \"{{ docker_nginx_ssl }}:/ssl-certs:ro\" - \"{{ docker_nginx_logs }}:/var/log/nginx:rw\" dest: \"{{ docker_nginx_confd }}/default.conf\" - \"{{ docker_nginx_config_root }}\" - \"{{ docker_nginx_confd }}\" - \"{{ docker_nginx_http }}\" - \"{{ docker_nginx_ssl }}\" - \"{{ docker_nginx_logs }}\"", "label": 1, "commit_name": "Merge branch 'fix-bugs' into 'development'"}
{"code": "directory_nginx_config_root: \"{{ directory_nginx_config_root }}\" directory_nginx_confd: \"{{ directory_nginx_confd }}\" directory_nginx_http: \"{{ directory_nginx_http }}\" directory_nginx_ssl: \"{{ directory_nginx_ssl }}\" directory_nginx_logs: \"{{ directory_nginx_logs }}\" - \"{{ directory_nginx_config_root }}\" - \"{{ directory_nginx_confd }}\" - \"{{ directory_nginx_http }}\" - \"{{ directory_nginx_ssl }}\" - \"{{ directory_nginx_logs }}\" image: \"{{ docker_image_nginx }}:{{ docker_image_nginx_tag }}\" - \"{{ directory_nginx_confd }}:/etc/nginx/conf.d:ro\" - \"{{ directory_nginx_http }}:/http:ro\" - \"{{ directory_nginx_ssl }}:/ssl-certs:ro\" - \"{{ directory_nginx_logs }}:/var/log/nginx:rw\" image: \"{{ docker_image_nginx }}:{{ docker_image_nginx_tag }}\" - \"{{ directory_nginx_confd }}:/etc/nginx/conf.d:ro\" - \"{{ directory_nginx_http }}:/http:ro\" - \"{{ directory_nginx_ssl }}:/ssl-certs:ro\" - \"{{ directory_nginx_logs }}:/var/log/nginx:rw\" dest: \"{{ directory_nginx_confd }}/default.conf\" - \"{{ directory_nginx_config_root }}\" - \"{{ directory_nginx_confd }}\" - \"{{ directory_nginx_http }}\" - \"{{ directory_nginx_ssl }}\" - \"{{ directory_nginx_logs }}\"", "label": 0, "commit_name": "Merge branch 'fix-bugs' into 'development'"}
{"code": "galaxy_info: role_name: nginx author: no fuss computing description: template role to create a docker container with nginx issue_tracker_url: https://gitlab.com/nofusscomputing/infrastructure/ansible-roles license: https://gitlab.com/nofusscomputing/infrastructure/ansible-roles/-/blob/master/license min_ansible_version: 1.2 platforms: - name: debian versions: - 10 galaxy_tags: [ nginx ]", "label": 1, "commit_name": "Merge branch 'fix-more-bugs' into 'development'"}
{"code": "galaxy_info: role_name: nginx author: no fuss computing description: template role to create a docker container with nginx issue_tracker_url: https://gitlab.com/nofusscomputing/infrastructure/ansible-roles license: https://gitlab.com/nofusscomputing/infrastructure/ansible-roles/-/blob/master/license min_ansible_version: 1.2 platforms: - name: debian versions: - 10 galaxy_tags: [ nginx ]", "label": 0, "commit_name": "Merge branch 'fix-more-bugs' into 'development'"}
{"code": "folder_path: \"{{ ansible_env.home }}/games\" steam_dir: \"{{ ansible_env.home }}/.local/share/steam/steamapps/common\" - bgee - bg2ee - iwdee games_paths: bgee: \"{{ steam_dir }}/baldur's gate enhanced edition\" bg2ee: \"{{ steam_dir }}/baldur's gate ii enhanced edition\" iwdee: \"{{ steam_dir }}/icewind dale enhanced edition\"", "label": 1, "commit_name": "Updated to remove bloat in vars.yml, and hanlde loops better"}
{"code": "folder_path: \"{{ lookup('env', 'home') }}/games\" steam_dir: \"{{ lookup('env', 'home') }}/.local/share/steam/steamapps/common\" bgee: \"baldur's gate enhanced edition\" bg2ee: \"baldur's gate ii enhanced edition\" iwdee: \"icewind dale enhanced edition\"", "label": 0, "commit_name": "Updated to remove bloat in vars.yml, and hanlde loops better"}
{"code": "name: registry.gitlab.com/local_infrastructure/alpine-ansible:1.2.0", "label": 1, "commit_name": "fix"}
{"code": "name: registry.gitlab.com/local_infrastructure/image-alpine-ansible:1.2.0", "label": 0, "commit_name": "fix"}
{"code": "notify: - restart httpd", "label": 1, "commit_name": "Remove irksome handler and fix issue #6"}
{"code": "# change listening port for http to match group_vars/all.yml - name: set http listen port lineinfile: dest=/etc/httpd/conf/httpd.conf \\ regexp=\"^listen\" \\ line=\"listen {{nagios_http_port}}\"", "label": 0, "commit_name": "Remove irksome handler and fix issue #6"}
{"code": "with_dict: sysctl_config with_dict: sysctl_rhel_config", "label": 1, "commit_name": "fix bare variables usage for loops"}
{"code": "with_dict: '{{ sysctl_config }}' with_dict: '{{ sysctl_rhel_config }}'", "label": 0, "commit_name": "fix bare variables usage for loops"}
{"code": "when: item.name is match(\"weidu-linux\") and not weidu.stat.exists path: \"{{ ansible_user_dir }}/.{{ lookup('env', 'shell') | regex_replace('^/bin/', '') }}rc\"", "label": 1, "commit_name": "Updated to remove bloat in vars.yml, and hanlde loops better"}
{"code": "when: item.name is match(\"weidu-linux\") path: \"{{ lookup('env', 'home') }}/.{{ lookup('env', 'shell') | regex_replace('^/bin/', '') }}rc\"", "label": 0, "commit_name": "Updated to remove bloat in vars.yml, and hanlde loops better"}
{"code": "- name: install postgresql module dependency", "label": 1, "commit_name": "postgresql: Fix name of RHEL-only task"}
{"code": "- name: install postgresql module dependency on rhel", "label": 0, "commit_name": "postgresql: Fix name of RHEL-only task"}
{"code": "sudo: yes", "label": 1, "commit_name": "Fixing permissions errors with Dashboard & Website.."}
{"code": "sudo: no sudo: yes sudo: yes sudo: yes sudo: yes sudo: yes sudo: yes", "label": 0, "commit_name": "Fixing permissions errors with Dashboard & Website.."}
{"code": "dockerfile: dockerfile-focal dockerfile: dockerfile--11", "label": 1, "commit_name": "Fix Dockerfile input"}
{"code": "dockerfile: dockerfile-11 dockerfile: dockerfile-11", "label": 0, "commit_name": "Fix Dockerfile input"}
{"code": "- multi-arch - multi-arch", "label": 1, "commit_name": "fix: tagging runner"}
{"code": "tags: - kaniko - kaniko tags: - kaniko - kaniko tags: - kaniko tags: - kaniko", "label": 0, "commit_name": "fix: tagging runner"}
{"code": "# 15.2 tag amd64:15.2: version: \"15.2\" arm64:15.2: version: \"15.2\" arm/v7:15.2: version: \"15.2\" arm/v6:15.2: version: \"15.2\" # 15.1 tag amd64:15.1: version: \"15.1\" arm64:15.1: version: \"15.1\" arm/v7:15.1: version: \"15.1\" arm/v6:15.1: version: \"15.1\" deploy:15.2: version: \"15.2\" deploy:15.1: version: \"15.1\"", "label": 1, "commit_name": "Fix tag versions (#2)"}
{"code": "# 3.12 tag amd64:3.12: version: \"3.12\" arm64:3.12: version: \"3.12\" arm/v7:3.12: version: \"3.12\" arm/v6:3.12: version: \"3.12\" # 3.11 tag amd64:3.11: version: \"3.11\" arm64:3.11: version: \"3.11\" arm/v7:3.11: version: \"3.11\" arm/v6:3.11: version: \"3.11\" # 3.10 tag amd64:3.10: <<: *container-build variables: platform: linux/amd64 version: \"3.10\" arm64:3.10: <<: *container-build variables: platform: linux/arm64 version: \"3.10\" arm/v7:3.10: <<: *container-build variables: platform: linux/arm/v7 version: \"3.10\" arm/v6:3.10: <<: *container-build variables: platform: linux/arm/v6 version: \"3.10\" # 3.9 tag amd64:3.9: <<: *container-build variables: platform: linux/amd64 version: \"3.9\" arm64:3.9: <<: *container-build variables: platform: linux/arm64 version: \"3.9\" arm/v7:3.9: <<: *container-build variables: platform: linux/arm/v7 version: \"3.9\" arm/v6:3.9: <<: *container-build variables: platform: linux/arm/v6 version: \"3.9\" deploy:3.12: <<: *deploy variables: version: \"3.12\" deploy:3.11: <<: *deploy variables: version: \"3.11\" deploy:3.10: version: \"3.10\" deploy:3.9: version: \"3.9\"", "label": 0, "commit_name": "Fix tag versions (#2)"}
{"code": "vnet_name2: \"myvnet{{ rpfx }}\"", "label": 1, "commit_name": "fix name (#59)"}
{"code": "vnet_name2: \"myvnet{{ rpfx }}2\"", "label": 0, "commit_name": "fix name (#59)"}
{"code": "action: apt pkg=$item state=installed", "label": 1, "commit_name": "Removing legacy variable substitution $var and replacing with {{}} due to deprecation"}
{"code": "action: apt pkg={{ item }} state=installed", "label": 0, "commit_name": "Removing legacy variable substitution $var and replacing with {{}} due to deprecation"}
{"code": "- training", "label": 1, "commit_name": "fixes and add demo role"}
{"code": "- training tags: - training - name: ansible demo hosts: localhost roles: - { role: demo, say_text: \"luke, i am your father\" } tags: - demo", "label": 0, "commit_name": "fixes and add demo role"}
{"code": "- name: add cert-manager namespace - name: download the clusterissuer yml - name: install cert-manager - name: install the clusterissuer for production - name: install the clusterissuer for staging - name: install the cert-manager secret kubernetes.core.k8s: state: present template: cert-manager-cloudflare-secret.yml.j2 vars: apitoken: \"{{ lookup('env', 'cert_manager_api_token') }}\" when: inventory_hostname == master_node", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"cert-manager: add namespace\" - name: \"cert-manager: download the clusterissuer yml\" - name: \"cert-manager: install cert-manager\" - name: \"cert-manager: install the clusterissuer for production\" - name: \"cert-manager: install the clusterissuer for staging\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- \"{{ work_dir }}/config\":/config", "label": 1, "commit_name": "Fix ansible syntax"}
{"code": "- \"{{ work_dir }}/config:/config\"", "label": 0, "commit_name": "Fix ansible syntax"}
{"code": "password: password", "label": 1, "commit_name": "Minor fix"}
{"code": "password: password", "label": 0, "commit_name": "Minor fix"}
{"code": "type: docker_logs", "label": 1, "commit_name": "various fixes"}
{"code": "include_units: - docker - ssh exclude_units: - vector type: docker", "label": 0, "commit_name": "various fixes"}
{"code": "postgresql_user: name=postgres password=\"{{ lookup('file','/home/deploybot/pgsql') }}\" check_implicit_admin=yes login_user=postgres login_password='' state=present name: pgsql", "label": 1, "commit_name": "Bugfixes for PGSql installer"}
{"code": "postgresql_user: name=postgres password=\"{{ lookup('file','/home/deploybot/pgsql') }}\" login_user=postgres login_password='' state=present name: postgresql", "label": 0, "commit_name": "Bugfixes for PGSql installer"}
{"code": "shell: \"microk8s add-node | grep -e -m1 'microk8s join {{ microk8s_ip_regex_ha }}'\"", "label": 1, "commit_name": "Add wireguard, do some cleanups, utilize wireguard for microk8s and fix a glaring omission with longhorn using the /tmp folder - meaning upon host reboot everything was lost"}
{"code": "shell: \"microk8s add-node | tac | grep -e -m1 'microk8s join {{ microk8s_ip_regex_ha }}'\"", "label": 0, "commit_name": "Add wireguard, do some cleanups, utilize wireguard for microk8s and fix a glaring omission with longhorn using the /tmp folder - meaning upon host reboot everything was lost"}
{"code": "when: ansible_facts.system == \"linux\" when: ansible_facts.system == \"linux\"", "label": 1, "commit_name": "Fix error: dict object has no attribute 'system' (#409)"}
{"code": "when: ansible_facts.system is defined and ansible_facts.system == \"linux\" when: ansible_facts.system is defined and ansible_facts.system == \"linux\"", "label": 0, "commit_name": "Fix error: dict object has no attribute 'system' (#409)"}
{"code": "failed_when: install_rkhunter__create_report_status.rc != 1 # because emails are not correctly sended changed_when: install_rkhunter__create_report_status.rc != 1 # because emails are not correctly sended failed_when: install_rkhunter__create_report_status.rc != 1 # because emails are not correctly sended changed_when: install_rkhunter__create_report_status.rc != 1 # because emails are not correctly sended", "label": 1, "commit_name": "fix verify rkhunter"}
{"code": "failed_when: false # because emails are not correctly sended failed_when: false # because emails are not correctly sended", "label": 0, "commit_name": "fix verify rkhunter"}
{"code": "rpmfusion_distribution_major_version: \"{{ _rpmfusion_distribution_major_version[ansible_distribution_major_version] | default(ansible_distribution_major_version) }}\" rpmfusion_free_repository: \"https://download1.rpmfusion.org/free/{{ rpmfusion_distribution }}/rpmfusion-free-release-{{ rpmfusion_distribution_major_version }}.noarch.rpm\" rpmfusion_nonfree_repository: \"https://download1.rpmfusion.org/nonfree/{{ rpmfusion_distribution }}/rpmfusion-nonfree-release-{{ rpmfusion_distribution_major_version }}.noarch.rpm\" rpmfusion_free_gpgp_key: \"https://rpmfusion.org/keys?action=attachfile&do=get&target=rpm-gpg-key-rpmfusion-free-{{ rpmfusion_distribution }}-{{ rpmfusion_gpgkey }}\" rpmfusion_nonfree_gpgp_key: \"https://rpmfusion.org/keys?action=attachfile&do=get&target=rpm-gpg-key-rpmfusion-nonfree-{{ rpmfusion_distribution }}-{{ rpmfusion_gpgkey }}\"", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "rpmfusion_distribution_major_version: \"{{ _rpmfusion_distribution_major_version[ansible_distribution_major_version] | default(ansible_distribution_major_version) }}\" rpmfusion_free_repository: \"https://download1.rpmfusion.org/free/{{ rpmfusion_distribution }}/rpmfusion-free-release-{{ rpmfusion_distribution_major_version }}.noarch.rpm\" rpmfusion_nonfree_repository: \"https://download1.rpmfusion.org/nonfree/{{ rpmfusion_distribution }}/rpmfusion-nonfree-release-{{ rpmfusion_distribution_major_version }}.noarch.rpm\" rpmfusion_free_gpgp_key: \"https://rpmfusion.org/keys?action=attachfile&do=get&target=rpm-gpg-key-rpmfusion-free-{{ rpmfusion_distribution }}-{{ rpmfusion_gpgkey }}\" rpmfusion_nonfree_gpgp_key: \"https://rpmfusion.org/keys?action=attachfile&do=get&target=rpm-gpg-key-rpmfusion-nonfree-{{ rpmfusion_distribution }}-{{ rpmfusion_gpgkey }}\"", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "- name: recover postgresql from backup command: pg_restore -u postgres -d postgres -v /tmp/db/pg.dump become: yes become_user: postgres # fixme: this shouldn't be done here - name: change postgresql authentication configuration command: sed -i 's/^\\(.* postgres\\s*\\)peer/\\1md5/' /etc/postgresql/11/main/pg_hba.conf - name: restart postgresql systemd: name: postgresql state: restarted", "label": 1, "commit_name": "fix: drop failing pgsql restore"}
{"code": "#- name: recover postgresql from backup # command: pg_restore -u postgres -d postgres -v /tmp/db/pg.dump # become: yes # become_user: postgres # ## fixme: this shouldn't be done here #- name: change postgresql authentication configuration # command: sed -i 's/^\\(.* postgres\\s*\\)peer/\\1md5/' /etc/postgresql/11/main/pg_hba.conf # #- name: restart postgresql # systemd: # name: postgresql # state: restarted", "label": 0, "commit_name": "fix: drop failing pgsql restore"}
{"code": "#- role: prepare-system # action: 05-reboot-machines", "label": 1, "commit_name": "Change: A few linting errors"}
{"code": "- role: prepare-system action: 05-reboot-machines", "label": 0, "commit_name": "Change: A few linting errors"}
{"code": "- name: install keepassxc password manager and required packages become: true community.general.pacman: name: - keepassxc state: present", "label": 1, "commit_name": "linting fixes"}
{"code": "- name: install keepassxc password manager and required packages become: true community.general.pacman: name: - keepassxc state: present", "label": 0, "commit_name": "linting fixes"}
{"code": "password: \"{{ root_password }}\"", "label": 1, "commit_name": "password hash"}
{"code": "password: \"{{ root_password | password_hash('sha512') }}\"", "label": 0, "commit_name": "password hash"}
{"code": "command: \"touch {{certs_directory}}/cacert-merge-config.yml\" args: creates: \"{{certs_directory}}/cacert-merge-config.yml\"", "label": 1, "commit_name": "fixed a typo and updated to remove items deprecated as of ansible 2.4.1.0"}
{"code": "file: path=\"{{certs_directory}}/cacert-merge-config.yml\" state=touch owner=minemeld group=minemeld mode=\"{{file_permissions}}\"", "label": 0, "commit_name": "fixed a typo and updated to remove items deprecated as of ansible 2.4.1.0"}
{"code": "gather_facts: no - raw: test -e /bin/python3 || apt-get install python3 -y action: 05-reboot-machines", "label": 1, "commit_name": "Change: A few linting errors"}
{"code": "gather_facts: false - name: install python if not installed ansible.builtin.raw: test -e /bin/python3 || apt-get install python3 -y action: 05-reboot-machines", "label": 0, "commit_name": "Change: A few linting errors"}
{"code": "vpc_id: \"{{vpoout.vpc.id}}\"", "label": 1, "commit_name": "new code is added to playbook13"}
{"code": "vpc_id: \"{{vpcout.vpc.id}}\"", "label": 0, "commit_name": "new code is added to playbook13"}
{"code": "notify: restart httpd register: firewalld_tcp80_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_tcp80_exists.rc != 0 register: iptables_tcp80_exists failed_when: iptables_tcp80_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_tcp80_exists.stdout|int == 0 # firewalld - name: determine if firewalld is in use shell: systemctl is-enabled firewalld.service | egrep -qv 'masked|disabled' ignore_errors: true register: firewalld_in_use no_log: true - name: determine if firewalld is active shell: systemctl is-active firewalld.service | grep -vq inactive ignore_errors: true register: firewalld_is_active no_log: true register: firewalld_tcp8080_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_tcp8080_exists.rc != 0 register: iptables_tcp443_exists failed_when: iptables_tcp443_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_tcp443_exists.stdout|int == 0", "label": 1, "commit_name": "Many fixes here:"}
{"code": "notify: - restart httpd - elkservers.cfg - elasticsearch.cfg register: firewalld_nagios_http_port_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_nagios_http_port_exists.rc != 0 register: iptables_nagios_http_port_exists failed_when: iptables_nagios_http_port_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_nagios_http_port_exists.stdout|int == 0 register: firewalld_nagios_https_port_exists when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_nagios_https_port_exists.rc != 0 register: iptables_nagios_https_port_exists failed_when: iptables_nagios_https_port_exists == 127 when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_nagios_https_port_exists.stdout|int == 0", "label": 0, "commit_name": "Many fixes here:"}
{"code": "- \"{{pubsub2_out.subnet.id}}\"", "label": 1, "commit_name": "new code is added to playbook13"}
{"code": "- \"{{pubsub3_out.subnet.id}}\"", "label": 0, "commit_name": "new code is added to playbook13"}
{"code": "- pleroma-backend - pleroma-be", "label": 1, "commit_name": "refactor: changed pleroma-backend to pleroma-main"}
{"code": "- pleroma-main - pleroma-main", "label": 0, "commit_name": "refactor: changed pleroma-backend to pleroma-main"}
{"code": "- name: create basic wordpress site configuration template: src=wp-basic.conf.j2 dest=/etc/nginx/sites-available/wp-basic.conf - name: enable basic wordpress site configuration file: src=\"/etc/nginx/sites-available/wp-basic.conf\" dest=\"/etc/nginx/sites-enabled/wp-basic.conf\" when: wp_basic", "label": 1, "commit_name": "Refactor Nginx tasks"}
{"code": "- name: create php-fpm wordpress site configuration template: src=wp-php-fpm.conf.j2 dest=/etc/nginx/sites-available/wp-php-fpm.conf - name: enable php-fpm wordpress site configuration file: src=\"/etc/nginx/sites-available/wp-php-fpm.conf\" dest=\"/etc/nginx/sites-enabled/wp-php-fpm.conf\" when: wp_php_fpm", "label": 0, "commit_name": "Refactor Nginx tasks"}
{"code": "command: \"{{ openshift.common.client_binary }} new-project validate\" shell: \"{{ openshift.common.client_binary }} new-app https://github.com/openshift/cakephp-ex.git\" shell: \"{{ openshift.common.client_binary }} get pod | grep -v deploy | awk '/cakephp-ex-1-build/{ print $3 }'\" shell: \"{{ openshift.common.client_binary }} get pod | grep -v deploy | grep -v build | awk '/cakephp-ex-1-*/{print $3}'\" - name: expose the svc shell: \"{{ openshift.common.client_binary }} expose svc cakephp-ex\" url: \"http://cakephp-ex-validate.{{ hostvars['localhost']['wildcard_zone'] }}\" command: \"{{ openshift.common.client_binary }} delete project validate\"", "label": 1, "commit_name": "gitless validation testing - safer for atomic (#403)"}
{"code": "command: \"{{ openshift.common.client_binary }} new-project {{ project }}\" shell: \"{{ openshift.common.client_binary }} new-app {{ app }}\" shell: \"{{ openshift.common.client_binary }} get pod | grep -v deploy | awk '/{{ app }}-1-build/{ print $3 }'\" shell: \"{{ openshift.common.client_binary }} get pod | grep -v deploy | grep -v build | awk '/{{ app }}-1-*/{print $3}'\" url: \"http://{{ app }}-{{ project }}.{{ hostvars['localhost']['wildcard_zone'] }}\" command: \"{{ openshift.common.client_binary }} delete project {{ project }}\"", "label": 0, "commit_name": "gitless validation testing - safer for atomic (#403)"}
{"code": "tower_env: \"local\"", "label": 1, "commit_name": "fix tower env"}
{"code": "tower_temp: true #tower_env: \"local\"", "label": 0, "commit_name": "fix tower env"}
{"code": "- nunes-moura-cloud", "label": 1, "commit_name": "#5 documentation of the services"}
{"code": "- nunes-moura-cloud", "label": 0, "commit_name": "#5 documentation of the services"}
{"code": "name: brave description: brave browser repository baseurl: https://brave-browser-rpm-release.s3.brave.com/brave-browser.repo - name: install brave browser dnf: name=brave-browser", "label": 1, "commit_name": "Fix Brave Repo, Add 1Password"}
{"code": "name: brave-browser description: brave browser enabled: true baseurl: https://brave-browser-rpm-release.s3.brave.com/$basearch - name: add 1password repo yum_repository: name: 1password description: 1password stable channel baseurl: https://downloads.1password.com/linux/rpm/stable/$basearch enabled: true gpgcheck: yes gpgkey: https://downloads.1password.com/linux/keys/1password.asc - name: install third-party packages dnf: name: - 1password - 1password-cli - brave-browser", "label": 0, "commit_name": "Fix Brave Repo, Add 1Password"}
{"code": "mode: 0644", "label": 1, "commit_name": "add new hardening role and make playbooks intentionally less secure"}
{"code": "mode: 0666", "label": 0, "commit_name": "add new hardening role and make playbooks intentionally less secure"}
{"code": "state: reloaded", "label": 1, "commit_name": "fix container state"}
{"code": "state: started", "label": 0, "commit_name": "fix container state"}
{"code": "- curl -slo https://raw.githubusercontent.com/homebrew/install/master/uninstall - chmod +x ./uninstall - ./uninstall --force", "label": 1, "commit_name": "Use new homebrew uninstaller - fixes CI failure."}
{"code": "- curl -slo https://raw.githubusercontent.com/homebrew/install/master/uninstall.sh - chmod +x ./uninstall.sh - ./uninstall.sh --force", "label": 0, "commit_name": "Use new homebrew uninstaller - fixes CI failure."}
{"code": "loop: \"{{ [input_bootstrap_ssl_files_root_ca] + input_bootstrap_ssl_files_intermediates_ca }}\" root_ca_path: \"{{ input_bootstrap_ssl_files_base_path }}/{{ root_ca.cn | replace(' ', '-') }}\" cert_path: \"{{ input_bootstrap_ssl_files_base_path }}/{{ root_ca.cn | replace(' ', '-') }}/certs/{{ certificate.cn | replace(' ', '-') }}.pem.crt\" key_path: \"{{ input_bootstrap_ssl_files_base_path }}/{{ root_ca.cn | replace(' ', '-') }}/private/{{ certificate.cn | replace(' ', '-') }}.pem.key\" req_path: \"{{ input_bootstrap_ssl_files_base_path }}/{{ root_ca.cn | replace(' ', '-') }}/req/{{ certificate.cn | replace(' ', '-') }}.req\" csr_path: \"{{ input_bootstrap_ssl_files_base_path }}/{{ root_ca.cn | replace(' ', '-') }}/csr/{{ certificate.cn | replace(' ', '-') }}.pem.csr\" ca_chains_path: \"{{ input_bootstrap_ssl_files_base_path }}/{{ root_ca.cn | replace(' ', '-') }}/certs/ca-chain.pem.crt\" bundle_path: \"{{ input_bootstrap_ssl_files_base_path }}/{{ root_ca.cn | replace(' ', '-') }}/bundles/{{ certificate.cn | replace(' ', '-') }}\"", "label": 1, "commit_name": "fix CI 5"}
{"code": "loop: \"{{ [input_bootstrap_ssl_files__root_ca] + input_bootstrap_ssl_files__intermediates_ca }}\" root_ca_path: \"{{ input_bootstrap_ssl_files__base_path }}/{{ root_ca.cn | replace(' ', '-') }}\" cert_path: \"{{ input_bootstrap_ssl_files__base_path }}/{{ root_ca.cn | replace(' ', '-') }}/certs/{{ certificate.cn | replace(' ', '-') }}.pem.crt\" key_path: \"{{ input_bootstrap_ssl_files__base_path }}/{{ root_ca.cn | replace(' ', '-') }}/private/{{ certificate.cn | replace(' ', '-') }}.pem.key\" req_path: \"{{ input_bootstrap_ssl_files__base_path }}/{{ root_ca.cn | replace(' ', '-') }}/req/{{ certificate.cn | replace(' ', '-') }}.req\" csr_path: \"{{ input_bootstrap_ssl_files__base_path }}/{{ root_ca.cn | replace(' ', '-') }}/csr/{{ certificate.cn | replace(' ', '-') }}.pem.csr\" ca_chains_path: \"{{ input_bootstrap_ssl_files__base_path }}/{{ root_ca.cn | replace(' ', '-') }}/certs/ca-chain.pem.crt\" bundle_path: \"{{ input_bootstrap_ssl_files__base_path }}/{{ root_ca.cn | replace(' ', '-') }}/bundles/{{ certificate.cn | replace(' ', '-') }}\"", "label": 0, "commit_name": "fix CI 5"}
{"code": "admin_key: b884c3934a224a78489941f705c8793e", "label": 1, "commit_name": "Deleted auth for allow create users"}
{"code": "admin_key:", "label": 0, "commit_name": "Deleted auth for allow create users"}
{"code": "file: shell: path: \"{{ lookup('env','home') }}/.profile\" line: \"export qt_qpa_platformtheme=gtk2\"", "label": 1, "commit_name": "Fix task for QT theming"}
{"code": "ansible.builtin.file: ansible.builtin.shell: path: \"{{ lookup('env','home') }}/.profile\" line: \"export qt_qpa_platformtheme=gtk2\"", "label": 0, "commit_name": "Fix task for QT theming"}
{"code": "# update the hosts file witha final entry that will ovverride the entry for the current host with 127.0.0.1", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "# update the hosts file witha final entry that will override the entry for the current host with 127.0.0.1", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "- name: copy php fpm configuration copy: src=files/apache_php_fpm/php.ini dest=/etc/php/7.3/fpm/php.ini owner=root group=root mode=0644", "label": 1, "commit_name": "Update 20210409 - Apache2+FPM bug, added mod_php configuration."}
{"code": "backup: yes", "label": 0, "commit_name": "Update 20210409 - Apache2+FPM bug, added mod_php configuration."}
{"code": "- pgbouncer-trackingdb", "label": 1, "commit_name": "Fix bootstrapping"}
{"code": "- trackingdb-pgbouncer", "label": 0, "commit_name": "Fix bootstrapping"}
{"code": "src: templates/nfs/fstab", "label": 1, "commit_name": "Fix some typos"}
{"code": "src: templates/nfs-client/fstab", "label": 0, "commit_name": "Fix some typos"}
{"code": "include_role:", "label": 1, "commit_name": "Merge branch 'fix-ansible-lint' into 'main'"}
{"code": "ansible.builtin.include_role:", "label": 0, "commit_name": "Merge branch 'fix-ansible-lint' into 'main'"}
{"code": "state: latest", "label": 1, "commit_name": "restore: fix under indented state"}
{"code": "state: latest", "label": 0, "commit_name": "restore: fix under indented state"}
{"code": "repo: https://gitlab.com/deokiatama/dkr-deo-moodle.git key_file: /home/dcadm1n/.ssh/deo-moodle", "label": 1, "commit_name": "provision for web and db"}
{"code": "repo: https://gitlab.com/deokiatama/dkr-deo-moodle-db.git", "label": 0, "commit_name": "provision for web and db"}
{"code": "password: \"postgres\"", "label": 1, "commit_name": "Fix install PostgreSQL"}
{"code": "password: \"postgres\" version: 9: 6: repo: \"https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-6-x86_64/pgdg-centos96-9.6-3.noarch.rpm\" group: \"postgresql database server 9.6 pgdg\" directories: data: \"/var/lib/pgsql/9.6/data\" service: \"postgresql-9.6\"", "label": 0, "commit_name": "Fix install PostgreSQL"}
{"code": "datadog_skip_install: \"false\"", "label": 1, "commit_name": "Fix execution with `jinja2_native = True` (#383)"}
{"code": "datadog_skip_install: no", "label": 0, "commit_name": "Fix execution with `jinja2_native = True` (#383)"}
{"code": "# - alertmanager:9093", "label": 1, "commit_name": "fixes alert routing, now it works."}
{"code": "- \"{{ alertmanager_server | default('localhost:9093') }}\"", "label": 0, "commit_name": "fixes alert routing, now it works."}
{"code": "- name: update package caches changed_when: false ansible.builtin.shell: cmd: \"pacman -f --refresh --refresh\" - name: check if kernel needs update changed_when: false ansible.builtin.shell: # when the local kernel version does not match the remote version, # the kernel will need to be updated and a reboot will be required cmd: \"[[ $(pacman -q linux | awk '{print $2}') != $(pacman -s --info linux | grep -e '[0-9].arch' | awk '{print $3}') ]]\" register: kernel_needs_update - ansible.builtin.fail: msg: - \"kernel versions are mismatched (local version vs. remote version)\" - \"to mitigate strange errors with package or module versions...\" - \"update keyring, system, and reboot:\" - \"sudo bash -c 'pacman -sy --noconfirm archlinux-keyring && pacman -syyu --noconfirm && reboot'\" when: kernel_needs_update.rc != 0 # - name: update keyring # become: true # community.general.pacman: # name: archlinux-keyring # state: latest # - name: upgrade system # become: true # community.general.pacman: # update_cache: true # upgrade: true", "label": 1, "commit_name": "tweaks"}
{"code": "- name: update keyring community.general.pacman: name: archlinux-keyring state: latest", "label": 0, "commit_name": "tweaks"}
{"code": "- { role: k3s/deploy, apps: [ 'loki' ], tags: [ 'loki' ] } - { role: k3s/deploy, apps: [ 'prometheus-operator' ], tags: [ 'prometheus' ] } - { role: k3s/deploy, apps: [ 'service-monitor.yaml' ], tags: [ 'prometheus' ] } - { role: k3s/deploy, apps: [ 'grafana-datasources.yaml', 'grafana' ], tags: [ 'grafana' ] }", "label": 1, "commit_name": "Upgrade k3s to version 0.6.1; Refactor roles & plays"}
{"code": "- hosts: master[0] remote_user: root vars: ansible_python_interpreter: /usr/bin/python3 roles: - { role: k3s/deploy, apps: [ 'metrics-server.yml' ], tags: [ 'metrics' ] } - { role: k3s/deploy, apps: [ 'loki.yml' ], tags: [ 'loki', 'logs' ] } post_tasks: - name: wait a while for loki to be installed tags: [ 'pause' ] pause: seconds: 90 - { role: k3s/deploy, apps: [ 'promtail.yml' ], tags: [ 'logs', 'promtail' ] } - { role: k3s/deploy, apps: [ 'prometheus-operator.yml' ], tags: [ 'prometheus' ] } - { role: k3s/deploy, apps: [ 'service-monitor.yml' ], tags: [ 'prometheus' ] }", "label": 0, "commit_name": "Upgrade k3s to version 0.6.1; Refactor roles & plays"}
{"code": "curl -h \"host: confluence.90cos.cdl.af.mil\" \"{{ groups['confluence_backend'][0] }}\" curl -h \"host: jira.90cos.cdl.af.mil\" \"{{ groups['jira_backend'][0] }}\"", "label": 1, "commit_name": "fix: fix stream and testing"}
{"code": "curl -k \"https://{{ groups['confluence_backend'][0] }}\" curl -k \"https://{{ groups['jira_backend'][0] }}\" - name: ensure proxy node returns with confluence shell: | curl \"https://confluence.internal.test\" register: proxy_confluence_results - name: ensure proxy node returns with jira shell: | curl \"https://jira.internal.test\" register: proxy_jira_results - name: assert proxy node returns with confluence assert: that: proxy_confluence_results - name: assert proxy node returns with jira assert: that: proxy_jira_results", "label": 0, "commit_name": "fix: fix stream and testing"}
{"code": "debug: var=debug2", "label": 1, "commit_name": "fix"}
{"code": "debug: var=debug2.changed", "label": 0, "commit_name": "fix"}
{"code": "- name: elasticsearch xpack tests", "label": 1, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "- name: elasticsearch xpack tests initial es_version: \"5.1.2\" #modifies the installation. changes es_admin password and upgrades es. tests confirm the correct version is installed. - name: elasticsearch xpack modify hosts: localhost roles: - { role: elasticsearch, es_api_port: 9200, es_config: { \"http.port\": 9200, \"transport.tcp.port\":9300, discovery.zen.ping.unicast.hosts: \"localhost:9300\", \"xpack.security.authc.realms.file1.type\": \"file\",\"xpack.security.authc.realms.file1.order\": 0, \"xpack.security.authc.realms.native1.type\": \"native\",\"xpack.security.authc.realms.native1.order\": 1 }, es_instance_name: \"security_node\" } vars: es_heap_size: \"1g\" es_templates: true es_version: \"5.2.2\" es_enable_xpack: true es_xpack_license: \"{{ lookup('file', '/tmp/license.json') }}\" es_plugins: - plugin: ingest-attachment es_xpack_features: - security - alerting es_api_basic_auth_username: elastic es_api_basic_auth_password: changeme es_role_mapping: power_user: - \"cn=admins,dc=example,dc=com\" user: - \"cn=users,dc=example,dc=com\" - \"cn=admins,dc=example,dc=com\" es_users: native: kibana4_server: password: changeme roles: - kibana4_server file: es_admin: password: changemeagain roles: - admin testuser: password: changemealso! roles: - power_user - user", "label": 0, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "- { key: \"output\", value: \"mail\" } - { key: \"mailto\", value: \"monitoring@sublimigeek.fr\" } - { key: \"mailfrom\", value: \"logwatch@sublimigeek.fr\" } - { key: \"detail\", value: \"high\" } compose_version: \"1.24.1\"", "label": 1, "commit_name": "Merge branch 'fix/logrotate-deployment-and-minor-improvements' into 'master'"}
{"code": "logwatch_configuration_cache_path: \"/var/cache/logwatch\" - { key: \"output =\", value: \"mail\" } - { key: \"mailto =\", value: \"monitoring@sublimigeek.fr\" } - { key: \"mailfrom =\", value: \"logwatch@sublimigeek.fr\" } - { key: \"detail =\", value: \"high\" } - { key: \"range =\", value: \"yesterday\" } - { key: \"tmpdir =\", value: \"{{ logwatch_configuration_cache_path }}\" } compose_version: \"1.25.5\"", "label": 0, "commit_name": "Merge branch 'fix/logrotate-deployment-and-minor-improvements' into 'master'"}
{"code": "purge_networks: true", "label": 1, "commit_name": "refactor: Migrate to networks: strict from purge_networks"}
{"code": "comparisons: networks: strict", "label": 0, "commit_name": "refactor: Migrate to networks: strict from purge_networks"}
{"code": "docker_repo_baseurl: 'https://download.docker.com/linux/centos/7/$basearch/stable'", "label": 1, "commit_name": "docker-engine: Fix 'docker-ce' repository base URL to always follow release version"}
{"code": "docker_repo_baseurl: 'https://download.docker.com/linux/centos/$releasever/$basearch/stable'", "label": 0, "commit_name": "docker-engine: Fix 'docker-ce' repository base URL to always follow release version"}
{"code": "# installation du paquet fail2ban # copie des filtres utiles non pr\u00e9sents dans fail2ban par d\u00e9faut # g\u00e9n\u00e9ration de la configuration de fail2ban # pas de restart car fail2ban est chatouilleux \u00e0 ce sujet :) # todo - afficher un message \u00e0 l'utilisateur si fail2ban ne d\u00e9marre pas # affichage d'un message d'erreur \u00e0 l'utilisateur # msg: \"fail2ban tries to load jail without service to analyse !\\n check logs with : systemctl status fail2ban.service\"", "label": 1, "commit_name": "comments translation and check Fail2Ban service after service restart (to avoid errors if logs do not exist)"}
{"code": "# installation of the fail2ban package # add on remote system useful filters for fail2ban # generation of the new fail2ban configuration # no restart because fail2ban service can't handle it correctly ! - check fail2ban status # todo - remove \"check fail2ban status\" handler # exit with error if fail2ban isn't correctly started # it's possible to check if a string is in status returned by systemd module # register: fail2ban_return # failed_when: \"'exited' in fail2ban_return.status.substate\" # but i don't understand why, it seems that the status variable isn't \"uptodate\" after notify and # handler execution for restart or stop/start so the conditional check failed # todo # be able to print message to user when fail2ban does not start correctly # msg: \"**** fail2ban tries to load jail without service to analyse ! check logs with : systemctl status fail2ban.service ****\" # maybe the solution can be to use playbook_blocks : # (http://docs.ansible.com/ansible/playbooks_blocks.html)", "label": 0, "commit_name": "comments translation and check Fail2Ban service after service restart (to avoid errors if logs do not exist)"}
{"code": "destination_port: \"{{ inv_install_docker_portainer_http_port }}\" destination_port: \"{{ inv_install_docker_portainer_https_port }}\"", "label": 1, "commit_name": "fix portainers ports"}
{"code": "destination_port: \"{{ inv_add_docker_swarm_portainer_http_port }}\" destination_port: \"{{ inv_add_docker_swarm_portainer_https_port }}\"", "label": 0, "commit_name": "fix portainers ports"}
{"code": "- locale-config", "label": 1, "commit_name": "refactor: lint"}
{"code": "- locale_config", "label": 0, "commit_name": "refactor: lint"}
{"code": "- docker stop selfoss", "label": 1, "commit_name": "Fix image name in CI"}
{"code": "- docker stop alpine-ansible", "label": 0, "commit_name": "Fix image name in CI"}
{"code": "dest: /etc/my.cnf", "label": 1, "commit_name": "fix path to my.cnf"}
{"code": "dest: /root/.my.cnf", "label": 0, "commit_name": "fix path to my.cnf"}
{"code": "ansible_host: 145.136.x.x #ommit for aws/openstack deployments", "label": 1, "commit_name": "Fix yaml lintting"}
{"code": "ansible_host: 145.136.x.x # ommit for aws/openstack deployments", "label": 0, "commit_name": "Fix yaml lintting"}
{"code": "- vmware_datacenter - vmware_foldere_flavor", "label": 1, "commit_name": "fixed typos"}
{"code": "- vmware_folder", "label": 0, "commit_name": "fixed typos"}
{"code": "register: bastionhost_out", "label": 1, "commit_name": "new code is added to playbook13"}
{"code": "register: bastionhost_out - name: insert and update the vpc-output file blockinfile: path: vars/vpc-output.var backup: yes block: | bastionsgid: {{bastionhost_out.group_id}}", "label": 0, "commit_name": "new code is added to playbook13"}
{"code": "ap-southeast-2: \"ami-6b6c7c08\"", "label": 1, "commit_name": "udpated ap-southeast-2 to amzn-ami-2017.09.b-amazon-ecs-optimized"}
{"code": "ap-southeast-2: \"ami-2ab95148\"", "label": 0, "commit_name": "udpated ap-southeast-2 to amzn-ami-2017.09.b-amazon-ecs-optimized"}
{"code": "34323733396630666133303466346537323334616461363861623532396634623066313937393330 3230616562343165663564353537376661636436353133620a366164643634323661343135383566 63333439383235306262623865646433343838363035333961343431663264376636333661643165 3430363439303939620a313734353335643461633634653435373637623866623835343439356261 64316434356165303930346365643031383438633039623462366633323065363134313137633039 6663393362333839666439343364373464656232663831386538", "label": 1, "commit_name": "fix sudoers bug"}
{"code": "35343133383732616265393464393738396165353937303733613235383165363737643930653261 6663623965323038306362636238646233643034616561610a303939373562663338323763306466 30383236343862633537353239303730356637336161323866626639636134643137313639363035 6661366637643631640a393934663062393836666335366130636136613438343538336530656138 34336662383265326261376432393037643865346465323832356233643832626663353764303932 63633866623830633934663263353832373232326139633664393065313961363261623061343666 61393361346462623766343134626632663030376163373966333135353763373933613465343538 39643631336265353835", "label": 0, "commit_name": "fix sudoers bug"}
{"code": "shell: /usr/sbin/nologin command: \"postconf {{ item.key }}={{ item.value }}\"", "label": 1, "commit_name": "lock all passwords, and minor typos"}
{"code": "- name: lock root password user: name: root password_lock: yes shell: /bin/bash password_lock: yes command: \"postconf {{ item.key }}='{{ item.value }}'\"", "label": 0, "commit_name": "lock all passwords, and minor typos"}
{"code": "name: \"{{ item }}\" with_items: ['apt-transport-https', 'ca-certificates', 'curl'] name: \"{{ item }}\" with_items: ['nodejs', 'build-essential']", "label": 1, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "name: ['apt-transport-https', 'ca-certificates', 'curl'] name: ['build-essential', 'nodejs']", "label": 0, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "name: enmanuelmoreira.k3s.master name: enmanuelmoreira.k3s.node name: enmanuelmoreira.k3s.post", "label": 1, "commit_name": "fix"}
{"code": "name: enmanuelmoreira.k3s.k3s.master name: enmanuelmoreira.k3s.k3s.node name: enmanuelmoreira.k3s.k3s.post", "label": 0, "commit_name": "fix"}
{"code": "- name: \"check soanrqube http url\"", "label": 1, "commit_name": "fix CI tests"}
{"code": "- name: \"check sonarqube http url\"", "label": 0, "commit_name": "fix CI tests"}
{"code": "content: \"{{ hostvars[inventory_hostname] }}\"", "label": 1, "commit_name": "Fixed bug: It was not saving foreman params"}
{"code": "content: \"{{ hostvars[inventory_hostname].foreman_params }}\"", "label": 0, "commit_name": "Fixed bug: It was not saving foreman params"}
{"code": "src: /etc/radicale", "label": 1, "commit_name": "path fix"}
{"code": "path: /etc/radicale", "label": 0, "commit_name": "path fix"}
{"code": "shell: gpg --list-secret-keys --keyid-format=long quentin@lieumont.fr set_fact: template:", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.command: gpg --list-secret-keys --keyid-format=long quentin@lieumont.fr ansible.builtin.set_fact: ansible.builtin.template: mode: \"0600\"", "label": 0, "commit_name": "refactor: lint"}
{"code": "hostname: spine02 loopback0: 10.0.4.102 loopback1: 10.0.0.102", "label": 1, "commit_name": "Error /etc/network does not exist"}
{"code": "ansible_user: cumulus ansible_pass: cumuluslinux! ansible_become_pass: cumuluslinux! hostname: spine01 management_ip: ip: 10.0.4.102 mask: 255.255.255.0 cidr: /24 loopback1: ip: 10.0.0.102 mask: 255.255.255.255 cidr: /32 ports: swp1: {} swp2: {} swp3: {} swp4: {} swp5: {} swp6: {} routing: bgp: underlay: asn: 65100 peers: - peerlink.4094 - swp1 - swp2 - swp49 - swp50", "label": 0, "commit_name": "Error /etc/network does not exist"}
{"code": "- hosts: - elasticsearch become: true roles: - geerlingguy.java - hosts: elasticsearch become: true roles: - geerlingguy.elasticsearch - hosts: - graylog become: true roles: - geerlingguy.java - hosts: - elasticsearch - graylog become: true roles: - geerlingguy.java - hosts: graylog become: true roles: - community.mongodb.mongodb_repository - community.mongodb.mongodb_mongod tasks: - name: \"start mongodb\" service: name: \"mongod\" state: \"started\" enabled: \"yes\" - hosts: fre-graylog1 become: true tasks: - name: \"install pymongo\" apt: update_cache: yes name: \"python3-pymongo\" state: \"latest\" - hosts: graylog become: true roles: - graylog2.graylog", "label": 1, "commit_name": "Refactor playbooks"}
{"code": "--- - import_playbook: elasticsearch.yml - import_playbook: graylog.yml", "label": 0, "commit_name": "Refactor playbooks"}
{"code": "borg_pass: testing borg_repo_ssh_priv_key: | -----begin rsa private key----- miijkaibaakcagea7ywnadpjtjfvml8f7qmlroxwbp7q68vknwyijqlwxpdspw+f spkzwaw86ggh3brsmmmb95em1jzkp1jpdon3xstlvws++zqstfhjitnohjfm9qk8 nwxsktgir3spw0vq5ies7zzpu3gki1ia8gnewlpmbjxoq/lhbudahvmbtlrsrumr g7bligmz8vcs7xancd2pjmhpgezsxk+5xs5yumgdufmenb1qnsbvf7l8+88kkigi hr/j0e9kqr7hl8//wzhpfcrfv64rk5k/tp3ekfmch49wxymzhzmcpxywwfnfcqej 2izoqjgrnycejivivnu8wtrzvcerkp7b6ledmac+xyqwgch0pgmnmiqydiljspr5 c42cvuh83dc16lgys+q8mj3ydn1xqkiyxtyvo+1k578oqdgdhjemii6bnd0jx4ha 7tpxydl75r/o/2wvg3t4pailfpiujf83xwixlyxy9gutbfupeo9exbiplnlgpped cpcgpcdn9ctbee3x3xqm1zfzk3nqlbj8e8+x2jhcwrry0czraeiual99czdxmtcm sgpdk2ccrmrhzbibu+bhrpa4b7sd0c/2rx1nbjirvzq8snkl/+lfhrvh8ynhccgx ghiwmq5vo+iowfwhwt5gzzgv1yfiaoh8r64gcblqknus5z9rkugndimtdymcawea aqkcagbesqfhoifodp1k7dg+qbshepidib8ieux4ulghc/k7qr9qtgeypex+g5yx dcpts8j3ov3uou0dq4qy4yjhe5u/5qc5/5u3cmwde2wnvfpsq9or57bevlytqlwx 7b+7/5oiepgmmyqkmy1wxtfzgie9ma+eamovf8dceps19dmzpbiqhzr3izyjbf96 nd22ovtnc1cbczgltfdodsn3rdn1jsnrehdggl33ptwzw8nb139ss3e4g67/cw2r 6eyn0uy8wvciuks9h3qkv7hhh8pachfah38s3yb3uxzbty4ijojiovv7ls6afa8w hvwyahehffhwnggptcqatqv2s4s6tyrepcoc17w/i5f/xbjmto5i2hgouiktnmcl jswpn0fdx/d6zoltcp9eimbgqxihwpktal7egl3vsck4x+cjj3dwskf0l/gbvm7p syzkowobw4w43n9iizjfxptwmh/7tyrxwda9baj2hm6pa2cnnuj6n5llw1ojow9i wbhy1bg90s/raqlrsrhhf128xvkp9fc4eedspnew0norv7zjmr+8kyhnnltmjb3m o3bvzl8tdelknyo0wyqhfunkm/fhbcmedcrgifudpbkbwtlz06pupjp4pcbzkul+ ebu5xatiwfoonz1jae2me6yicmscyng20xtl8wzhr53unf18gqkcaqea/l/3knzb juqd2shmmc+yzc3lnvhpfbgxno873rlcbn+up0t6moxfd80ext3mlrnnh/wotxl6 93xqyvuar1exdjik1uze8vz4dlgoyz+bwagdesj/pzbhnrjcodjmqsn65fcp9zy/ /jdfmsefkohjywrrskaqfwnmb7fh4prkbb9vluwtwh2iumizewebjfvqdfmwmp+y 04trufu7gu8reashvrhhz73shi1qxtn3hdkp40osr96zu7tnfe4rykz9ts6lx8h1 ubqarevnjdw7hookquo9oqzvmpfnlfdg2lbnacrgo8byq+oqhoy15xsoivdnrclp oodan4dg5xgcqqkcaqea8joo5ctb+dthb+ekegmqgg7dihy4llsngtymot4/jd1o wgvfcabfvht1cw5csm1i1c75/zbx1fgws1c96patehtv/q+mruhwzzvflldsuxk0 gjvmj7mg2y4ik7q87v4+xjtbvfiiwquttf7jw3ll5uedez0mqo/migtld4sainlo 6ry/r/0v3vhiaii2j38iw+ugy0vud7mwa0q50w9o8aqsjowfmxc47k8evhdrej0n e6ugwje1k8zc3u/arvldfof9dddc0lkvqazpdfuvcryv5qlx8n+vukghfqxiiyjw etud21scu5okbq7jwzxqgbdscms+xdriaxc+elg+wwkcaqeaxqagz3vnrluojbq4 isp5emm+m2tqt107p6qwctjtk+nabmlywbynszoqjkoh1kgf3sz8+qdcveultowr iayefgd3umpy+e1icciy5nmcvp7pvdlqb98zyybrx+fmrzg7st/cwssore6zd1kz bfl0dyxd6ehxpxklqjn4zh14qf5rkmh4gam4llwgondoxh8idsukftjyv/coezgp scf9korqrsvyrwjovjonwpvxcfx9hjxusyrzd6m+c1zuvolpu++i2tfzbhw/rb4t ty5mmkp3ok42q5j5pghu7l5wscosskkfw45x1ay/xawjwm+x0ykptqhyrzjlndde sbgeaqkcaqbjtryfg64k9l5cf/1vrhirz2dfvz5ahvqonpcpy+ddlhfgm60k7som 7h7jknbsxuuphrjdg4qt7n2j96d958xw8m6hct0q8ln/vbkjdja09rbr5/n410j0 pwthvvx1k5tdc0duynqlsvl6tom4//vwalwrdqxcmrnpxa+nz4cxdw/kcm5vxa9f d8cjxuye7x8/wseytbsejstldc3fy3si52awhttyprjfwwaav3zmx/dp3omlmkoa jbiwemdnoidwaknhqju6vq1uaoh4nc5dtn/vf7egra3zohkbcbpy14mkxt0p09g8 ivurcpzmbkuozdrops1hyhkvdym0qhsbaoibad3vq7iwqsri1x625gspggjpbqdm cjcbstkjihahjrj3yrqwmc7yiapvtj+cfnnx0jed7sem2ggxpoipckepv9ljyfix yg8pr1lyw0dyse6rmr/lwzdri2tv77saiszbdo6gutpgblvrdasdywiqpy+l5ahy uu4b7zn3b7hpg5i+jaket+ayccwra5ykdnzhkui4lnl5stgvzbz2cgjhgmakwkvk odtw3z5wsfrfio8gtuyrjshspnybg60oomascqaiyrapy3td/u0xjgctczilpl8q tldog3i9iwjbk9qjagueqbc7scct7zfk9mnuouu71b/3lmltunrkbvk9qdi= -----end rsa private key-----", "label": 1, "commit_name": "fix: use environment variables"}
{"code": "borg_repo_ssh_priv_key: \"{{ lookup('env', 'borg_repo_ssh_priv_key')}}\" borg_pass: \"{{ lookup('env', 'borg_pass') }}\"", "label": 0, "commit_name": "fix: use environment variables"}
{"code": "# this is main tasks file for postgresql role", "label": 1, "commit_name": "Fix wrong comment main.yml"}
{"code": "# this is main tasks file for common role", "label": 0, "commit_name": "Fix wrong comment main.yml"}
{"code": "state: present", "label": 1, "commit_name": "fix mount command to actually mount filesystem"}
{"code": "state: mounted", "label": 0, "commit_name": "fix mount command to actually mount filesystem"}
{"code": "- name: upstrart environment variables", "label": 1, "commit_name": "Fix typo in task name"}
{"code": "- name: upstart environment variables", "label": 0, "commit_name": "Fix typo in task name"}
{"code": "- name: reload ufw command: ufw reload", "label": 1, "commit_name": "Use handler to reload ufw, and fix staging issuer"}
{"code": "notify: - ufw reload", "label": 0, "commit_name": "Use handler to reload ufw, and fix staging issuer"}
{"code": "apt: file: copy:", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.apt: ansible.builtin.file: mode: \"0700\" ansible.builtin.copy:", "label": 0, "commit_name": "refactor: lint"}
{"code": "yum: pkg={{ item }} state=present file: path=/etc/nagios/ansible-managed state=directory copy: src=nagios.cfg dest=/etc/nagios/nagios.cfg copy: src=localhost.cfg dest=/etc/nagios/objects/localhost.cfg copy: src=ansible-managed-services.cfg dest=/etc/nagios/ template: src={{ item + \".j2\" }} dest=/etc/nagios/ansible-managed/{{ item }}", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "yum: pkg: \"{{ item }}\" state: present file: path: /etc/nagios/ansible-managed state: directory copy: src: nagios.cfg dest: /etc/nagios/nagios.cfg copy: src: localhost.cfg dest: /etc/nagios/objects/localhost.cfg copy: src: ansible-managed-services.cfg dest: /etc/nagios/ template: src: \"{{ item + .j2 }}\" dest: \"/etc/nagios/ansible-managed/{{ item }}\"", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "- pip install ansible-lint shellcheck ruamel.yaml", "label": 1, "commit_name": "fix pipeline"}
{"code": "- pip install ansible-lint shellcheck-py ruamel.yaml", "label": 0, "commit_name": "fix pipeline"}
{"code": "- name: \"verify\" - name: \"get haproxy service current state\" register: haproxy_service_status failed_when: not haproxy_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"haproxy\" - name: \"check haproxy folders and conf\" block: - name: \"check haproxy folders\" loop: - \"{{ inv_install_haproxy_path }}\" - \"{{ inv_install_haproxy_confs_path }}\" - \"{{ inv_install_haproxy_error_path }}\" - \"{{ inv_install_haproxy_ssl_path }}\" loop_control: loop_var: folder_path register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ folder_path }}\" - name: \"check haproxy errors files http\" loop: \"{{ inv_install_haproxy_error_files }}\" loop_control: loop_var: file_path register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_install_haproxy_error_path }}/{{ file_path }}.http\" - name: \"check stats url protection\" when: inv_install_haproxy_listen_stats - name: \"check haproxy connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_haproxy_listen_stats_port }}\" timeout: 120 - name: \"check an unprotected stats http url\" when: not (inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined) and not inv_install_haproxy_listen_stats_https register: result failed_when: result.status != 200 ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" - name: \"check an unprotected stats https url\" when: not (inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined) and not inv_install_haproxy_listen_stats_https register: result failed_when: result.status != 200 ansible.builtin.uri: url: \"https://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" - name: \"check a protected stats http url\" when: inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined and not inv_install_haproxy_listen_stats_https - name: \"check http basic auth-protected url availability\" register: result failed_when: result.status != 401 ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"notmyuser\" password: \"notmypassword\" - name: \"check http basic auth-protected url\" url: \"http://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"{{ inv_install_haproxy_stats_login }}\" password: \"{{ inv_install_haproxy_stats_password }}\" - name: \"check a protected stats https url\" when: inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined and inv_install_haproxy_listen_stats_https block: - name: \"check http basic auth-protected url availability\" register: result failed_when: result.status != 401 ansible.builtin.uri: url: \"https://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" force_basic_auth: true user: \"notmyuser\" password: \"notmypassword\" - name: \"check http basic auth-protected url\" url: \"https://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" force_basic_auth: true user: \"{{ inv_install_haproxy_stats_login }}\" password: \"{{ inv_install_haproxy_stats_password }}\" # don't forget to keep this file updated # molecule/<scenario>/verify.yml - name: \"verify\" hosts: \"all:&haproxy\" gather_facts: false tasks: - name: \"get haproxy service current state\" register: haproxy_service_status failed_when: not haproxy_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"haproxy\" - name: \"check haproxy confs files\" loop: \"{{ inv_add_haproxy_http_confs_configurations }}\" loop_control: loop_var: configuration register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_haproxy_http_confs_confs_path }}/{{ configuration.name }}.cfg\" # don't forget to keep this file updated # molecule/<scenario>/verify.yml - name: \"verify\" hosts: \"all:&haproxy\" gather_facts: false tasks: - name: \"get haproxy service current state\" register: haproxy_service_status failed_when: not haproxy_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"haproxy\" - name: \"check haproxy confs files\" loop: \"{{ inv_add_haproxy_bdd_confs_configurations }}\" loop_control: loop_var: configuration register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_haproxy_bdd_confs_confs_path }}/{{ configuration.name }}.cfg\" - name: \"verify\" - name: \"get apache2 service current state\" register: install_apache_service_status failed_when: not install_apache_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"apache2\" - name: \"check apache2 folders and conf\" loop: - \"/etc/apache2/apache2.conf\" - \"/etc/apache2/ports.conf\" loop_control: loop_var: folder_path register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ folder_path }}\" - name: \"check apache2 http connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_apache_http_listen_port }}\" timeout: 120 - name: \"check apache2 https connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_apache_https_listen_port }}\" timeout: 120 - name: \"get apache2 service current state\" register: apache_service_status failed_when: not apache_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"apache2\" - name: \"check apache2 default configuration\" - name: \"check apache2 http and conf\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs_confs_path }}/{{ vhost.server.name }}-http.conf\" - name: \"check apache2 https and conf\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs_confs_path }}/{{ vhost.server.name }}-https.conf\" - name: \"check https conf: certs\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.crt }}\" - name: \"check https conf: keys\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.key }}\" - name: \"check apache2 webserver\" block: - name: \"check apache2 connectivity\" port: \"{{ inv_add_apache_confs_http_listen_port }}\" - name: \"check default vhost on http\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_add_apache_confs_http_listen_port }}/\" method: \"get\" - name: \"check default vhost on https\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"https://{{ inventory_hostname }}:{{ inv_add_apache_confs_https_listen_port }}/\" method: \"get\"", "label": 1, "commit_name": "refacto, iptables, fixes"}
{"code": "- name: \"verify haproxy\" - name: \"verify haproxy\" when: inv_install_haproxy | default(false) - name: \"get haproxy service current state\" register: haproxy_service_status failed_when: not haproxy_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"haproxy\" - name: \"check haproxy folders and conf\" block: - name: \"check haproxy folders\" loop: - \"{{ inv_install_haproxy_path }}\" - \"{{ inv_install_haproxy_confs_path }}\" - \"{{ inv_install_haproxy_error_path }}\" - \"{{ inv_install_haproxy_ssl_path }}\" loop_control: loop_var: folder_path register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ folder_path }}\" - name: \"check haproxy errors files http\" loop: \"{{ inv_install_haproxy_error_files }}\" loop_control: loop_var: file_path register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_install_haproxy_error_path }}/{{ file_path }}.http\" - name: \"check stats url protection\" when: inv_install_haproxy_listen_stats - name: \"check haproxy connectivity\" ansible.builtin.wait_for: host: \"127.0.0.1\" port: \"{{ inv_install_haproxy_listen_stats_port }}\" timeout: 120 - name: \"check an unprotected stats http url\" when: not (inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined) and not inv_install_haproxy_listen_stats_https url: \"http://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" - name: \"check an unprotected stats https url\" when: not (inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined) and not inv_install_haproxy_listen_stats_https url: \"https://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" validate_certs: false - name: \"check a protected stats http url\" when: inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined and not inv_install_haproxy_listen_stats_https block: - name: \"check http basic auth-protected url availability\" register: result failed_when: result.status != 401 ansible.builtin.uri: url: \"http://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"notmyuser\" password: \"notmypassword\" - name: \"check http basic auth-protected url\" register: result failed_when: result.status != 200 ansible.builtin.uri: url: \"http://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"{{ inv_install_haproxy_stats_login }}\" password: \"{{ inv_install_haproxy_stats_password }}\" - name: \"check a protected stats https url\" when: inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined and inv_install_haproxy_listen_stats_https block: - name: \"check http basic auth-protected url availability\" register: result failed_when: result.status != 401 ansible.builtin.uri: url: \"https://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"notmyuser\" password: \"notmypassword\" validate_certs: false - name: \"check http basic auth-protected url\" register: result failed_when: result.status != 200 ansible.builtin.uri: url: \"https://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"{{ inv_install_haproxy_stats_login }}\" password: \"{{ inv_install_haproxy_stats_password }}\" validate_certs: false - name: \"check haproxy http confs files\" when: inv_add_haproxy_http_confs_configurations | default(false) loop: \"{{ inv_add_haproxy_http_confs_configurations }}\" loop_control: loop_var: configuration register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_install_haproxy_confs_path }}/{{ configuration.name }}.cfg\" - name: \"check haproxy bdd confs files\" when: inv_add_haproxy_bdd_confs_configurations | default(false) loop: \"{{ inv_add_haproxy_bdd_confs_configurations }}\" loop_control: loop_var: configuration register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_install_haproxy_confs_path }}/{{ configuration.name }}.cfg\" - name: \"verify apache2\" - name: \"verify apache2\" when: inv_install_haproxy | default(false) - name: \"get apache2 service current state\" register: install_apache_service_status failed_when: not install_apache_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"apache2\" - name: \"check apache2 http connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_apache_http_listen_port }}\" timeout: 120 - name: \"check apache2 https connectivity\" port: \"{{ inv_install_apache_https_listen_port }}\" - name: \"get apache2 service current state\" register: apache_service_status failed_when: not apache_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"apache2\" - name: \"check apache2 default configuration\" block: - name: \"check apache2 folders and conf\" loop: - \"/etc/apache2/apache2.conf\" - \"/etc/apache2/ports.conf\" loop_control: loop_var: folder_path register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ folder_path }}\" - name: \"check apache2 http and conf\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs_confs_path }}/{{ vhost.server.name }}-http.conf\" - name: \"check apache2 https and conf\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs_confs_path }}/{{ vhost.server.name }}-https.conf\" - name: \"check https conf: certs\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.crt }}\" - name: \"check https conf: keys\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.key }}\" - name: \"check apache2 webserver\" block: - name: \"check apache2 connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_add_apache_confs_http_listen_port }}\" timeout: 120 - name: \"check default vhost on http\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_add_apache_confs_http_listen_port }}/\" method: \"get\" - name: \"check default vhost on https\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"https://{{ inventory_hostname }}:{{ inv_add_apache_confs_https_listen_port }}/\" method: \"get\"", "label": 0, "commit_name": "refacto, iptables, fixes"}
{"code": "hosts: \"all\" loop: \"{{ groups['all'] }}\" loop: \"{{ groups['all'] }}\" # if you have any prepararion task - name: \"prepare apacheds\" hosts: \"all:&apacheds\" gather_facts: true tasks: - name: \"include labocbz.prepare_host\" tags: - \"labocbz.prepare_host\" vars: prepare_host_system_users: \"{{ inv_prepare_host_apacheds_system_users }}\" ansible.builtin.include_role: name: \"labocbz.prepare_host\"", "label": 1, "commit_name": "refacto done, force ci"}
{"code": "hosts: \"cicd-debian-11\" loop: \"{{ groups['cicd-debian-11'] }}\" loop: \"{{ groups['cicd-debian-11'] }}\"", "label": 0, "commit_name": "refacto done, force ci"}
{"code": "register: authorized_keys changed_when: (not authorized_keys.stat.exists) or (authorized_keys.stat.size == 0) when: (not authorized_keys.stat.exists or authorized_keys.stat.size == 0) and not (ssh_public_key is defined) and not aws when: (ssh_config.changed or authorized_keys.changed)", "label": 1, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "register: ssh_authorized_keys changed_when: (not ssh_authorized_keys.stat.exists) or (ssh_authorized_keys.stat.size == 0) when: (not ssh_authorized_keys.stat.exists or ssh_authorized_keys.stat.size == 0) and not (ssh_public_key is defined) and not aws when: (ssh_config.changed or ssh_authorized_keys.changed)", "label": 0, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "- name: link .tmux.conf", "label": 1, "commit_name": "tmux: fix typo in ansible"}
{"code": "- name: link .tmux.conf", "label": 0, "commit_name": "tmux: fix typo in ansible"}
{"code": "key: '{{ item }}' with_file: - authorized_keys", "label": 1, "commit_name": "Fix merge conflict"}
{"code": "key: https://gitlab.com/cworobetz/authorized_keys/raw/master/authorized_keys", "label": 0, "commit_name": "Fix merge conflict"}
{"code": "- name: install and configure python tools (pyenv, pipx, poetry\u2026) hosts: all - import_playbook: ./pipx.yml - import_playbook: ./pyenv.yml - import_playbook: ./poetry.yml", "label": 1, "commit_name": "\ud83d\udea8 fixes some lint errors"}
{"code": "- name: install pipx import_playbook: ./pipx.yml - name: install pyenv import_playbook: ./pyenv.yml - name: install poetry import_playbook: ./poetry.yml", "label": 0, "commit_name": "\ud83d\udea8 fixes some lint errors"}
{"code": "- name: update, upgrade and install common packages using apt - name: install pip3 modules kubernetes, ansible and jsonpatch", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"common: update, upgrade and install common packages\" - name: \"common: install pip3 modules kubernetes, ansible and jsonpatch\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "extra-vars: \"@./../../tests/tower/tower.yml\"", "label": 1, "commit_name": "fix all local molecule"}
{"code": "command: \"/sbin/init\" extra-vars: \"@./tests/tower/tower.yml\" - \"dependency\"", "label": 0, "commit_name": "fix all local molecule"}
{"code": "--{{ option.key | replace('_', '-') ~ ' ' ~ option.value }} --{{ option.key | replace('_', '-') ~ ' ' ~ option.value }}", "label": 1, "commit_name": "gitlab-manager: Fix passing options to command"}
{"code": "--{{ option.key | replace('_', '-') ~ ' ' ~ \"'\" ~ option.value ~ \"'\" }} --{{ option.key | replace('_', '-') ~ ' ' ~ \"'\" ~ option.value ~ \"'\" }}", "label": 0, "commit_name": "gitlab-manager: Fix passing options to command"}
{"code": "backup_node: main_backup_node", "label": 1, "commit_name": "[FIX] main backup node is not correct"}
{"code": "backup_node: targethost", "label": 0, "commit_name": "[FIX] main backup node is not correct"}
{"code": "service: name=ntpd state=restarted", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "service: name: ntpd state: restarted", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "- name: get registered gitlab runners ansible.builtin.shell: 'gitlab-runner list' # noqa command-instead-of-shell - name: register gitlab runners - name: unregister runners", "label": 1, "commit_name": "ansible-lint: Fix some errors"}
{"code": "- name: get registered gitlab runners # noqa command-instead-of-shell ansible.builtin.shell: 'gitlab-runner list' - name: register gitlab runners # noqa jinja[spacing] changed_when: true - name: unregister runners # noqa jinja[spacing] changed_when: true", "label": 0, "commit_name": "ansible-lint: Fix some errors"}
{"code": "- apply netplan", "label": 1, "commit_name": "fix: do not run netplan if using only systemd"}
{"code": "- restart networkd - restart resolved", "label": 0, "commit_name": "fix: do not run netplan if using only systemd"}
{"code": "tags: tags: tags: tags: tags: tags: tags: tags: tags: tags: tags: owner: {{ user.name }} group: {{ user.group }} tags: src: {{ ssh.user_key }} owner: {{ user.name }} group: {{ user.group }} tags: tags:", "label": 1, "commit_name": "mothball attacks"}
{"code": "tags: tags: tags: tags: tags: tags: tags: tags: tags: tags: tags: owner: \"{{ user.name }}\" group: \"{{ user.group }}\" tags: src: \"{{ ssh.user_key }}\" owner: \"{{ user.name }}\" group: \"{{ user.group }}\" tags: tags:", "label": 0, "commit_name": "mothball attacks"}
{"code": "codex_container_image: '{{ codex_container_repo }}{{ \":\" + codex_container_tag }}'", "label": 1, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "codex_container_image: 'ajslater/codex:{{ codex_container_tag }}'", "label": 0, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "- name: list security updates - name: install security updates", "label": 1, "commit_name": "install only security updates"}
{"code": "- name: list all updates - name: install only security updates", "label": 0, "commit_name": "install only security updates"}
{"code": "- validate stage: validate stage: validate", "label": 1, "commit_name": "Echo if no vulnerabilities were found"}
{"code": "- lint and validate stage: lint and validate else echo \"no vulnerabilities detected!\" stage: lint and validate", "label": 0, "commit_name": "Echo if no vulnerabilities were found"}
{"code": "state:directory", "label": 1, "commit_name": "Fixed bug"}
{"code": "state: directory", "label": 0, "commit_name": "Fixed bug"}
{"code": "- subversion", "label": 1, "commit_name": "Add phpmyadmin; fix handlers"}
{"code": "- subversion - unzip", "label": 0, "commit_name": "Add phpmyadmin; fix handlers"}
{"code": "- \"ansible-playbook -i tests/inventory tests/main.yml --connection=local --sudo\"", "label": 1, "commit_name": "CentOS/EL 7 support, test validation."}
{"code": "- \"ansible-playbook -i tests/inventory tests/playbook.yml --connection=local --sudo\"", "label": 0, "commit_name": "CentOS/EL 7 support, test validation."}
{"code": "apt: name={{ java }} state={{java_state}} update_cache=yes", "label": 1, "commit_name": "Idempotency fix for java"}
{"code": "- name: refresh java repo apt: update_cache=yes changed_when: false when: ansible_os_family == 'debian' apt: name={{ java }} state={{java_state}}", "label": 0, "commit_name": "Idempotency fix for java"}
{"code": "- name: \"converge\" hosts: \"cicd-ubuntu-22\" tasks: - name: \"include labocbz.prepare_host\" tags: - \"labocbz.prepare_host\" vars: prepare_host__users: \"{{ inv_prepare_host__users }}\" prepare_host__packages_removed: \"{{ inv_prepare_host__packages_removed }}\" prepare_host__packages_installed: \"{{ inv_prepare_host__packages_installed }}\" prepare_host__system_users: \"{{ inv_prepare_host__system_users }}\" ansible.builtin.include_role: name: \"labocbz.prepare_host\"", "label": 1, "commit_name": "fix CI"}
{"code": "- name: \"include tool.bootstrap_playbook playbook\" tags: - \"tool.bootstrap_playbook\" vars: tower_env: \"cicd-ubuntu-22\" ansible.builtin.import_playbook: \"../../playbook.yml\"", "label": 0, "commit_name": "fix CI"}
{"code": "# commented since we don't have any baseline iptables configuration yet.", "label": 1, "commit_name": "Some iptables bugs were fixed"}
{"code": "# - name: prepare iptables # command: iptables-save > /etc/network/iptables # tags: iptables # # lineinfile: dest=/etc/network/iptables # regexp=\"^-a input -s {{ publicip }} -p {{item.protocol}} -m {{item.protocol}} --dport {{item.port}} -j accept$\" # line=\"-a input -s {{ publicip }} -p {{item.protocol}} -m {{item.protocol}} --dport {{item.port}} -j accept\" # insertafter=\"^:output accept \\[\\d*:\\d*\\]$\" # with_items: # - { protocol: tcp, port: 22 } # - { protocol: tcp, port: 80 } # notify: restart iptables", "label": 0, "commit_name": "Some iptables bugs were fixed"}
{"code": "export overlay=local-${network}-full", "label": 1, "commit_name": "fix(kustomize-cardano-node): fixed another typo in overlay name"}
{"code": "export overlay=local-${network}", "label": 0, "commit_name": "fix(kustomize-cardano-node): fixed another typo in overlay name"}
{"code": "path: \"/home/{{ admin_user }}/.ssh\"", "label": 1, "commit_name": "rename chuckn246.keys to authorized_keys"}
{"code": "path: \"/home/{{ admin_user }}/.ssh/authorized_keys\"", "label": 0, "commit_name": "rename chuckn246.keys to authorized_keys"}
{"code": "- name: create member role and associate it with admin user", "label": 1, "commit_name": "fix indentation of task that broke yaml"}
{"code": "- name: create member role and associate it with admin user", "label": 0, "commit_name": "fix indentation of task that broke yaml"}
{"code": "file: dest=/home/deployer/default state=directory owner=deployer group=www-data mode=2755", "label": 1, "commit_name": "Fix permissions"}
{"code": "file: dest=/home/deployer/default state=directory owner=deployer group=www-data mode=2775", "label": 0, "commit_name": "Fix permissions"}
{"code": "galaxy_info: role_name: fail2ban author: no fuss computing description: a role to install the specified github release tag for fail2ban license: https://gitlab.com/nofusscomputing/infrastructure/ansible-roles/-/blob/master/license min_ansible_version: 1.2 platforms: - name: debian versions: - 10 galaxy_tags: [ fail2ban ]", "label": 1, "commit_name": "Merge branch 'fix-more-bugs' into 'development'"}
{"code": "galaxy_info: role_name: fail2ban author: no fuss computing description: a role to install the specified github release tag for fail2ban license: https://gitlab.com/nofusscomputing/infrastructure/ansible-roles/-/blob/master/license min_ansible_version: 1.2 platforms: - name: debian versions: - 10 galaxy_tags: [ fail2ban ]", "label": 0, "commit_name": "Merge branch 'fix-more-bugs' into 'development'"}
{"code": "copy: src=/usr/share/easy-rsa/ dest=/etc/openvpn", "label": 1, "commit_name": "path fix"}
{"code": "copy: src=/usr/share/easy-rsa/ dest=/etc/openvpn/easy-rsa", "label": 0, "commit_name": "path fix"}
{"code": "- set_fact: use_system_d={{(ansible_distribution == 'debian' and ansible_distribution_version | version_compare('8', '>=')) or (ansible_distribution == 'centos' and ansible_distribution_version | version_compare('7', '>=')) or (ansible_distribution == 'ubuntu' and ansible_distribution_version | version_compare('15', '>=')) }}", "label": 1, "commit_name": "Merge pull request #250 from geoplex/fix-systemd-restart-rhel"}
{"code": "- set_fact: use_system_d={{(ansible_distribution == 'debian' and ansible_distribution_version | version_compare('8', '>=')) or (ansible_distribution in ['redhat','centos'] and ansible_distribution_version | version_compare('7', '>=')) or (ansible_distribution == 'ubuntu' and ansible_distribution_version | version_compare('15', '>=')) }}", "label": 0, "commit_name": "Merge pull request #250 from geoplex/fix-systemd-restart-rhel"}
{"code": "include_tasks: tasks2.yml", "label": 1, "commit_name": "fix: Do not add the skipped tags to the graph"}
{"code": "include_tasks: tasks/tasks2.yml", "label": 0, "commit_name": "fix: Do not add the skipped tags to the graph"}
{"code": "command: chdir=/srv/ /bin/tar xvf wordpress-{{ wp_version }}.tar.gz creates=/srv/wordpress local_action: command curl https://api.wordpress.org/secret-key/1.1/salt/", "label": 1, "commit_name": "Merge pull request #278 from ScottBrenner/fix-ansible-lint-errors"}
{"code": "unarchive: creates: /srv/wordpress src: /srv/wordpress-{{ wp_version }}.tar.gz dest: /srv/wordpress get_url: url: https://api.wordpress.org/secret-key/1.1/salt/ changed_when: true delegate_to: localhost", "label": 0, "commit_name": "Merge pull request #278 from ScottBrenner/fix-ansible-lint-errors"}
{"code": "docker_tag: enmanuelmoreira/docker-ansible-almalinux8:latest", "label": 1, "commit_name": "Fix image name"}
{"code": "docker_tag: enmanuelmoreira/docker-ansible-archlinux:latest", "label": 0, "commit_name": "Fix image name"}
{"code": "line: \"password: {{ student_password }}\"", "label": 1, "commit_name": "Merge branch 'fix-code-password' into 'main'"}
{"code": "line: \"password: '{{ student_password }}'\"", "label": 0, "commit_name": "Merge branch 'fix-code-password' into 'main'"}
{"code": "- name: restart postgresql become: yes service: name: postgresql-9.6 state: restarted", "label": 1, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "- name: restart postgresql become: yes service: name: postgresql-9.6 state: restarted", "label": 0, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "- name: install monsterui yum: name: monster-ui* state: latest - name: install ssl certificate copy: content: \"{{ ssl_certificate }}\" dest: /etc/pki/tls/certs/kazoo.crt owner: root group: root mode: 0644 - name: install ssl private key copy: content: \"{{ ssl_private_key }}\" dest: /etc/pki/tls/private/kazoo.pem owner: root group: root mode: 0600", "label": 1, "commit_name": "More detailed error logging"}
{"code": "- name: install ssl certificate copy: content: \"{{ ssl_certificate }}\" dest: /etc/pki/tls/certs/kazoo.crt owner: root group: root mode: 0644 notify: restart nginx - name: install ssl private key copy: content: \"{{ ssl_private_key }}\" dest: /etc/pki/tls/private/kazoo.pem owner: root group: root mode: 0600 notify: restart nginx - name: install monsterui yum: name: monster-ui* state: latest", "label": 0, "commit_name": "More detailed error logging"}
{"code": "- \"$registry_auth_file/auth:/auth\"", "label": 1, "commit_name": "feat: Fix broken path for htpasswd and add http host env variable"}
{"code": "registry_http_host: \"$docker_registry_http_host\" - \"$docker_registry_htpasswd_path/auth:/auth\"", "label": 0, "commit_name": "feat: Fix broken path for htpasswd and add http host env variable"}
{"code": "- name: \"include labocbz.prepare_host\" tags: - \"labocbz.prepare_host\" ansible.builtin.include_role: name: \"labocbz.prepare_host\" - name: \"prepare\" loop: \"{{ inv_install_haproxy_cert_bundles }}\" when: inv_install_haproxy_cert_bundles is defined and bundle.type == \"cert\" loop: \"{{ inv_install_haproxy_cert_bundles }}\" when: inv_install_haproxy_cert_bundles is defined and bundle.type == \"ca\" #- name: \"include labocbz.add_certificates\" # tags: # - \"labocbz.add_certificates\" # loop: \"{{ inv_cert_bundles }}\" # loop_control: # loop_var: bundle # when: inv_cert_bundles is defined # vars: # add_certificates_bundle_name: \"{{ bundle.name }}\" # add_certificates_bundle_type: \"{{ bundle.type }}\" # add_certificates_bundle_src: \"{{ bundle.src }}\" # add_certificates_bundle_dest: \"{{ bundle.dest }}\" # #add_certificates_bundle_src_user: \"{{ bundle.src_user }}\" # #add_certificates_bundle_src_password: \"{{ bundle.src_password }}\" # #add_certificates_bundle_dest_user: \"{{ bundle.dest_user }}\" # #add_certificates_bundle_dest_group: \"{{ bundle.dest_group }}\" # #add_certificates_bundle_dest_mode: \"{{ bundle.dest_mode }}\" # ansible.builtin.include_role: # name: \"labocbz.add_certificates\"", "label": 1, "commit_name": "refacto, iptables, fixes"}
{"code": "- name: \"prepare haproxy\" - name: \"include labocbz.prepare_host\" tags: - \"labocbz.prepare_host\" vars: prepare_host_system_users: \"{{ inv_prepare_host_haproxy_system_users }}\" ansible.builtin.include_role: name: \"labocbz.prepare_host\" loop: \"{{ inv_haproxy_cert_bundles }}\" when: inv_haproxy_cert_bundles is defined and bundle.type == \"cert\" loop: \"{{ inv_haproxy_cert_bundles }}\" when: inv_haproxy_cert_bundles is defined and bundle.type == \"ca\" - name: \"include labocbz.prepare_host\" tags: - \"labocbz.prepare_host\" vars: prepare_host_system_users: \"{{ inv_prepare_host_apache_system_users }}\" ansible.builtin.include_role: name: \"labocbz.prepare_host\"", "label": 0, "commit_name": "refacto, iptables, fixes"}
{"code": "grep -le '\\[global\\]|fsid' /etc/ceph/*.conf", "label": 1, "commit_name": "Merge pull request #1330 from ceph/fix-cluster-name-take-over"}
{"code": "basename $(grep -r fsid /etc/ceph/ | egrep -o '^[^.]*')", "label": 0, "commit_name": "Merge pull request #1330 from ceph/fix-cluster-name-take-over"}
{"code": "- base-os", "label": 1, "commit_name": "Add full LXC provisioning, add lxd hosts"}
{"code": "gather_facts: no - role: lxc-preprovision tags: lxc vars: # note: variables do leak between roles, so this is one of the few safe places where we can override what we # need per role without being worried. ansible_host: \"{{ lxd_host }}\" ansible_user: null lxc_default_user: ubuntu provision_ssh_key: \"ssh-ed25519 aaaac3nzac1lzdi1nte5aaaaigex/9uo92cuv0spod/lhwhuij40kxq4by/njqdvvhxb\" - role: base-os tags: base vars: ansible_host: \"{{ inventory_hostname }}\" ansible_password: null ansible_user: ubuntu is_lxc: true", "label": 0, "commit_name": "Add full LXC provisioning, add lxd hosts"}
{"code": "- name: configure primary patroni roles ['consul_role', 'postgres_role'] gitlab_rails['auto_migrate'] = false repmgr['enable'] = false patroni['enable'] = false # after bootstrapping, enable this - name: configure primary patroni['enable'] = true # after bootstrapping, enable this gitlab_rails['db_password'] = '{{ sql_user_password_plain }}' - lineinfile: path: /etc/gitlab/gitlab.rb line: \"gitlab_rails['auto_migrate'] = true\" state: present - import_tasks: tasks/bootstrap/default/fast_ssh_lookups.yml - name: configure application settings command: | gitlab-rails runner 'applicationsetting.last.update(authorized_keys_enabled: false, hashed_storage_enabled: true)'", "label": 1, "commit_name": "Fixes to bootstrap patroni correctly on the primary and secondary"}
{"code": "- import_tasks: tasks/bootstrap/default/pgbouncer_write_pgpass.yml pgbouncer['admin_users'] = %w(pgbouncer gitlab-consul) 'gitlab-consul': { password: '{{ gitlab_consul_user_password }}' }, - name: configure primary consul roles ['consul_role'] # after bootstrapping change roles line above to: # roles ['consul_role', 'patroni_role'] gitlab_rails['auto_migrate'] = false - name: configure primary gitlab instance - import_tasks: tasks/bootstrap/default/fast_ssh_lookups.yml patroni['enable'] = true gitlab_rails['db_password'] = '{{ sql_user_password_plain }}' #gitlab_rails['db_host'] = '{{ groups.primary_pgbouncer_internal[0] }}' #gitlab_rails['db_port'] = 6432 - name: configure application settings command: | gitlab-rails runner 'applicationsetting.last.update(authorized_keys_enabled: false, signup_enabled: false)' - name: configure primary patroni hosts: primary_patronis become: yes become_method: sudo gather_facts: false vars_files: - vars/settings.yml tasks: - lineinfile: path: /etc/gitlab/gitlab.rb line: \"roles ['consul_role']\" state: absent - lineinfile: path: /etc/gitlab/gitlab.rb line: \"roles ['consul_role', 'patroni_role']\" state: present - import_tasks: tasks/bootstrap/default/reconfigure.yml", "label": 0, "commit_name": "Fixes to bootstrap patroni correctly on the primary and secondary"}
{"code": "- name: set synapse cache factor lineinfile: path: /etc/default/matrix-synapse regexp: '^synapse_cache_factor=' line: 'synapse_cache_factor=2.0' state: present create: yes notify: restart synapse", "label": 1, "commit_name": "minor fixes, add a redlight install section for rapid testing"}
{"code": "# - name: set synapse cache factor # lineinfile: # path: /etc/default/matrix-synapse # regexp: '^synapse_cache_factor=' # line: 'synapse_cache_factor=2.0' # state: present # create: yes # notify: restart synapse", "label": 0, "commit_name": "minor fixes, add a redlight install section for rapid testing"}
{"code": "- http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.13.6-trusty/linux-headers-3.13.6-031306-generic_3.13.6-031306.201403070154_amd64.deb - http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.13.6-trusty/linux-image-3.13.6-031306-generic_3.13.6-031306.201403070154_amd64.deb - http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.13.6-trusty/linux-headers-3.13.6-031306_3.13.6-031306.201403070154_all.deb", "label": 1, "commit_name": "Kernel 3.10.7. Some ansible tweaks. [ci skip]"}
{"code": "- http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.13.7-trusty/linux-headers-3.13.7-031307-generic_3.13.7-031307.201403240156_amd64.deb - http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.13.7-trusty/linux-image-3.13.7-031307-generic_3.13.7-031307.201403240156_amd64.deb - http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.13.7-trusty/linux-headers-3.13.7-031307_3.13.7-031307.201403240156_all.deb", "label": 0, "commit_name": "Kernel 3.10.7. Some ansible tweaks. [ci skip]"}
{"code": "- name: restart php7.0-fpm service: name=php7.0-fpm state=restarted", "label": 1, "commit_name": "Fix php7 restart handlers"}
{"code": "- name: restart php7.2-fpm service: name=php7.2-fpm state=restarted", "label": 0, "commit_name": "Fix php7 restart handlers"}
{"code": "mode: 0700", "label": 1, "commit_name": "fix CI 2"}
{"code": "mode: 0700", "label": 0, "commit_name": "fix CI 2"}
{"code": "hosts: all tasks: - name: install nfs kernel server become: true apt: state: present name: - nfs-kernel-server", "label": 1, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "become: true apt: state: present name: - nfs-kernel-server", "label": 0, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "- name: generate interfaces backup in local machine delegate_to: localhost connection: local become: false template: src: interfaces.j2 dest: roles/deploy_spine/files/{{inventory_hostname}}_interfaces.cfg force: yes - name: copy interfaces configuration template: src: interfaces.j2 dest: /etc/network/interfaces backup: yes force: yes notify: reload networking - name: generate frr backup in local machine delegate_to: localhost connection: local become: false template: src: frr.j2 dest: roles/deploy_spine/files/{{inventory_hostname}}_frr.cfg force: yes - name: copy frr configuration template: src: frr.j2 dest: /etc/frr/frr.conf backup: yes force: yes notify: reload frr", "label": 1, "commit_name": "Fixed ip addr error and create subtasks"}
{"code": "- name: import - interface backup and deploy import_tasks: deploy_interfaces.yml - name: import - frr backup and deploy import_tasks: deploy_frr.yml", "label": 0, "commit_name": "Fixed ip addr error and create subtasks"}
{"code": "when: item.url is defined", "label": 1, "commit_name": "fix for plugins"}
{"code": "when: item.url is defined and item.download_only is not defined", "label": 0, "commit_name": "fix for plugins"}
{"code": "# - name: configure smartmontools", "label": 1, "commit_name": "Add LazyDocker, fixes #122"}
{"code": "- name: install lazydocker ansible.builtin.shell: cmd: curl https://raw.githubusercontent.com/jesseduffield/lazydocker/master/scripts/install_update_linux.sh | bash args: creates: /usr/local/bin/lazydocker environment: dir: /usr/local/bin", "label": 0, "commit_name": "Add LazyDocker, fixes #122"}
{"code": "url: \"{{ discord_webhook }}\"", "label": 1, "commit_name": "Fix discord url webhook"}
{"code": "url: \"https://discord.com/api/webhooks/{{ discord_webhook }}\"", "label": 0, "commit_name": "Fix discord url webhook"}
{"code": "hosts: servers", "label": 1, "commit_name": "Fix playbook"}
{"code": "- name: add ssh fingerprints hosts: localhost gather_facts: no tasks: - name: add hosts to /etc/hosts template: src: templates/hosts.j2 dest: /etc/hosts become: yes # \u0443\u0431\u0440\u0430\u0442\u044c \u0437\u0430\u043c\u0435\u043d\u0443 \u0438 \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0434\u043e\u043f\u0438\u0441\u044b\u0432\u0430\u043d\u0438\u0435 \u0432 \u0444\u0430\u0439\u043b - name: check exist known_hosts stat: path: \"~/.ssh/known_hosts\" register: khfile - name: add first connection shell: ssh vagrant@192.168.33.111 when: not khfile.stat.exists # \u0437\u0430\u0434\u0430\u0447\u0443 \u043d\u0443\u0436\u043d\u043e \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c \u0432 \u0444\u043e\u043d\u0435, \u0431\u0435\u0437 \u0432\u044b\u0434\u0430\u0447\u0438 \u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432 - name: ssh exit shell: exit when: not khfile.stat.exists - name: add ssh fingerprints known_hosts: path: \"~/.ssh/known_hosts\" host: \"{{ item }}\" key: \"{{ lookup('pipe', 'ssh-keyscan -t rsa ' + item) }}\" with_items: \"{{ groups['servers'] }}\" ignore_errors: yes hosts: all - mysql", "label": 0, "commit_name": "Fix playbook"}
{"code": "rules: \"{{ item.rules | union(bastionhost_ssh_rules) }}\"", "label": 1, "commit_name": "added option to allow current public IP to security group"}
{"code": "- name: get current public ip address. ipify_facts: when: public_ip == 'true' - name: set fact - create current public ip address ssh rules. set_fact: current_public_ip_rules: - proto: tcp from_port: 22 to_port: 22 cidr_ip: \"{{ ipify_public_ip }}/32\" when: public_ip == 'true' rules: \"{{ item.rules | union(bastionhost_ssh_rules) | union(current_public_ip_rules) }}\"", "label": 0, "commit_name": "added option to allow current public IP to security group"}
{"code": "- name: stage filebeat json index template copy: src=filebeat-index-template.json dest=/tmp/filebeat-index-template.json owner=root group=root mode=0644 become: true # note: we can't currently use the ansible uri module here, curl is a workaround # https://github.com/ansible/ansible-modules-core/issues/265 # http://stackoverflow.com/questions/28997007/translate-curl-put-into-ansible-uri-module command: curl -xpost 'http://localhost:9200/_template/filebeat?pretty' -d@/tmp/filebeat-index-template.json", "label": 1, "commit_name": "Multiple fixes, cleanup, ES listen port options"}
{"code": "tags: # skip ansible0012 commands should not change things if nothing needs doing # need to understand if an entry exists - skip_ansible_lint uri: url: http://localhost:9200/_template/filebeat?pretty method: post body: \"{{ lookup('file', 'filebeat-index-template.json') }}\" body_format: json tags: # skip ansible0012 commands should not change things if nothing needs doing # check if firewall is enabled - skip_ansible_lint tags: # skip ansible0012 commands should not change things if nothing needs doing # check if firewall is active - skip_ansible_lint tags: # skip ansible0012 commands should not change things if nothing needs doing # need to validate if port already configured - skip_ansible_lint tags: # skip ansible0012 commands should not change things if nothing needs doing # need to validate if port already configured - skip_ansible_lint tags: # skip ansible0013 use shell only when shell functionality is required # no systemctl module available in current stable release (ansible 2.1) - skip_ansible_lint", "label": 0, "commit_name": "Multiple fixes, cleanup, ES listen port options"}
{"code": "release_stability: stable", "label": 1, "commit_name": "Some ansible lint fix"}
{"code": "release_stability: stable", "label": 0, "commit_name": "Some ansible lint fix"}
{"code": "- name: open up ports in ufw - name: configure users - name: configure microk8s - name: setup kubeconfig", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"microk8s: open up ports in ufw\" - name: \"microk8s: configure users\" - name: \"microk8s: configure microk8s\" - name: \"microk8s: setup kubeconfig\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "update_cache: false", "label": 1, "commit_name": "Still trying to fix repository issue"}
{"code": "update_cache: yes", "label": 0, "commit_name": "Still trying to fix repository issue"}
{"code": "- name: \"molecule-local-instance-1-deploy-jenkins\" image: \"${nexus_address}/${docker_image_debian_11_ansible}\" command: \"/sbin/init\" #published_ports: # - \"0.0.0.0:8181:8181/tcp\" dockerfile: \"dockerfile\" override_command: true tmpfs: - \"/run\" - \"/tmp\" - \"/var/lib/containerd:/var/lib/containerd\" cgroupns_mode: \"host\" cgroup_manager: \"cgroupfs\" #storage_opt: \"overlay.mount_program=/usr/bin/fuse-overlayfs\" #storage_driver: \"overlay\" - name: \"molecule-local-instance-2-deploy-jenkins\" image: \"${nexus_address}/${docker_image_debian_11_ansible}\" command: \"/sbin/init\" #published_ports: # - \"0.0.0.0:8181:8181/tcp\" dockerfile: \"dockerfile\" privileged: true pre_build_image: true override_command: true volumes: - \"/sys/fs/cgroup:/sys/fs/cgroup:rw\" - \"/var/lib/containerd:/var/lib/containerd\" #storage_opt: \"overlay.mount_program=/usr/bin/fuse-overlayfs\" #storage_driver: \"overlay\" ansible_force_color: \"true\"", "label": 1, "commit_name": "fix and refacto"}
{"code": "- name: \"molecule-cicd-debian-11-instance-1-deploy-jenkins\" image: \"${nexus_repos_docker_registry}/${docker_image_debian_11_ansible}\" hostname: \"molecule-cicd-debian-11-instance-1-deploy-jenkins\" command: \"/sbin/init\" storage_driver: \"overlay2\" networks: - name: \"molecule-cicd-debian-11-deploy-jenkins\" ansible_force_color: \"true\"", "label": 0, "commit_name": "fix and refacto"}
{"code": "- multi-arch - multi-arch", "label": 1, "commit_name": "fix: tagging kaniko runner"}
{"code": "tags: - kaniko - kaniko tags: - kaniko - kaniko", "label": 0, "commit_name": "fix: tagging kaniko runner"}
{"code": "infobeamer_content_repo: 'https://github.com/ffbsee/technikcamp-info-beamer.git'", "label": 1, "commit_name": "fix url"}
{"code": "infobeamer_content_repo: 'https://github.com/toolboxbodensee/tdott19-info-beamer.git'", "label": 0, "commit_name": "fix url"}
{"code": "apt: file:", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.apt: ansible.builtin.file: mode: \"0755\"", "label": 0, "commit_name": "refactor: lint"}
{"code": "license: license (gpl-2.0-or-later, mit, etc) min_ansible_version: 2.1", "label": 1, "commit_name": "Fix licence and add some information in Readme"}
{"code": "license: license mit min_ansible_version: \"2.1\"", "label": 0, "commit_name": "Fix licence and add some information in Readme"}
{"code": "- update-kubelet", "label": 1, "commit_name": "Added smoke test, firewalld setup, heapster, encrypting secrets at rest"}
{"code": "serial: 1 - { role: update-kubelet, when: \"groups['all-masters'][0] != inventory_hostname\" }", "label": 0, "commit_name": "Added smoke test, firewalld setup, heapster, encrypting secrets at rest"}
{"code": "chdir: \"{{ openvpn_rsa_ca_dir }}\" chdir: \"{{ openvpn_rsa_ca_dir }}\" chdir: \"{{ easy_rsa_ca_dir }}\"", "label": 1, "commit_name": "fixes"}
{"code": "chdir: \"{{ openvpn_easy_rsa_dir }}\" chdir: \"{{ openvpn_easy_rsa_dir }}\" chdir: \"{{ openvpn_easy_rsa_dir }}\"", "label": 0, "commit_name": "fixes"}
{"code": "notify: pacemaker disable cinder-api", "label": 1, "commit_name": "fixes issue for scaleio interface on non-homogenius clusters"}
{"code": "# notify: pacemaker disable cinder-api", "label": 0, "commit_name": "fixes issue for scaleio interface on non-homogenius clusters"}
{"code": "name: \"{{ item }}\" with_items: \"{{ headless_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ headless_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "network_interface_name: \"\" #you may define a network interface here, if none is defined the script tries to automatically detect one", "label": 1, "commit_name": "Fix: Indentation"}
{"code": "network_interface_name: \"\" # you may define a network interface here, if none is defined the script tries to automatically detect one", "label": 0, "commit_name": "Fix: Indentation"}
{"code": "gather_facts: no become: no", "label": 1, "commit_name": "Merge branch '13-broken-playbook-to-copy-and-paste-error' into 'main'"}
{"code": "gather_facts: false become: false", "label": 0, "commit_name": "Merge branch '13-broken-playbook-to-copy-and-paste-error' into 'main'"}
{"code": "when: inv_add_docker_swarm| default(false)", "label": 1, "commit_name": "fix CI"}
{"code": "when: inv_add_docker_swarm | default(false)", "label": 0, "commit_name": "fix CI"}
{"code": "failed_when: \"'ami-' not in ec2ami.stdout\"", "label": 1, "commit_name": "Fix to ami fail task condition"}
{"code": "failed_when: ( ec2ami.stdout == \"\" ) or ( \"'ami-' not in ec2ami.stdout\" )", "label": 0, "commit_name": "Fix to ami fail task condition"}
{"code": "- name: k8s-bootstrab - k8s/argocd", "label": 1, "commit_name": "fix: typo"}
{"code": "- name: k8s-bootstrap - k8s/argocd # - k8s/etcd", "label": 0, "commit_name": "fix: typo"}
{"code": "- name: create folder for the pandalaimon-data path: /home/jaller94/pandalaimon-data dest: /home/jaller94/pandalaimon-data/pantalaimon.conf - '8008' - /home/jaller94/pantalaimon-data/:/data - name: install packages based on package.json.", "label": 1, "commit_name": "Fix pantalaimon container not running"}
{"code": "- name: create folder for the pantalaimon-data path: /home/jaller94/pantalaimon-data dest: /home/jaller94/pantalaimon-data/pantalaimon.conf state: started exposed_ports: - \"8008\" - \"8008:8008\" - /home/jaller94/pantalaimon-data/:/data - name: install packages based on package.json - name: download silvy-matrix repo for bruce git: repo: https://gitlab.com/jaller94/silvy-matrix.git dest: /home/jaller94/bruce-matrix depth: 1 force: yes become: yes become_user: jaller94 - name: install packages based on package.json npm: path: /home/jaller94/bruce-matrix production: yes become: yes become_user: jaller94 - name: copy matrix-config for bruce copy: src: bruce/matrix.js dest: /home/jaller94/silvy-matrix/config/matrix.js become: yes become_user: jaller94 - name: install bruce service into systemd copy: src: bruce.service dest: /etc/systemd/system/bruce.service owner: root group: root mode: u=rw,g=r,o=r - name: enable service bruce, and not touch the state service: name: bruce enabled: yes - name: restart service service: name: bruce state: restarted", "label": 0, "commit_name": "Fix pantalaimon container not running"}
{"code": "- name: update apt apt: update_cache: yes - name: upgrade the system apt: upgrade: yes - name: install common packages apt: pkg: - htop - curl - wget - git - python3-pip state: present", "label": 1, "commit_name": "Add wireguard, do some cleanups, utilize wireguard for microk8s and fix a glaring omission with longhorn using the /tmp folder - meaning upon host reboot everything was lost"}
{"code": "- name: update, upgrade and install common packages using apt include_tasks: apt.yml", "label": 0, "commit_name": "Add wireguard, do some cleanups, utilize wireguard for microk8s and fix a glaring omission with longhorn using the /tmp folder - meaning upon host reboot everything was lost"}
{"code": "apt: pkg={{ item }} state=latest with_items:", "label": 1, "commit_name": "Fix deprecation loop on apt module"}
{"code": "apt: name: \"{{ packages }}\" vars: packages:", "label": 0, "commit_name": "Fix deprecation loop on apt module"}
{"code": "shell: aws ec2 describe-images \\ --ouput=json \\ --region \"{{ aws_region }}\" --owners 309956199498 | \\", "label": 1, "commit_name": "Fix to force to aws describe-images command to json"}
{"code": "shell: aws \\ --output json \\ ec2 describe-images \\ --region \"{{ aws_region }}\" \\ --owners 309956199498 | \\", "label": 0, "commit_name": "Fix to force to aws describe-images command to json"}
{"code": "idempotency_test: true extra_vars: es_plugins: - plugin: ingest-geoip playbook: test/integration/xpack.yml", "label": 1, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "idempotency_test: true idempotency_test: true playbook: test/integration/xpack.yml", "label": 0, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "dokuwiki_memory: 1g", "label": 1, "commit_name": "fix linting issue"}
{"code": "dokuwiki_memory: 1g", "label": 0, "commit_name": "fix linting issue"}
{"code": "### apache2 installation - name: apache2 installation apt: name: apache2 state: present notify: apache ssl tags: - apache - ssl - name: enable ssl support to apache2 command: 'a2enmod ssl' notify: apache2 restart tags: - apache - ssl - name: copy ssl certificate copy: src: \"{{ scope }}certificate.tar.encrypted\" dest: /etc/ssl tags: - apache - ssl - name: decrypt ssl certificate command: 'openssl aes-256-cbc -salt -a -d -in /etc/ssl/\"{{scope}}\"certificate.tar.encrypted -out -k \"{{ decryptkey }}\"' notify: untar apache certificate tags: - apache - ssl ### etckeeper commit - name: commit etckeeper debug: msg: \"commit apache changes to etckeeper.\" notify: etckeeper update tags: - apache - ssl", "label": 1, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "- include: apache2.yml - include: php5.yml", "label": 0, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "- name: add a tls certificate", "label": 1, "commit_name": "download_db: fix playbook name"}
{"code": "- name: download a compressed db export", "label": 0, "commit_name": "download_db: fix playbook name"}
{"code": "- hosts: alpine", "label": 1, "commit_name": "Fix /.cache directory permissions"}
{"code": "- name: test playbook hosts: alpine", "label": 0, "commit_name": "Fix /.cache directory permissions"}
{"code": "become: true", "label": 1, "commit_name": "fix: fix permission-related issues with some roles"}
{"code": "- name: install git become: true apt: name: git state: present", "label": 0, "commit_name": "fix: fix permission-related issues with some roles"}
{"code": "- 70 - 80 - 443 - 22 logging: off", "label": 1, "commit_name": "fix: latest Raspbian and Ansible support"}
{"code": "- \"70\" - \"80\" - \"443\" - \"22\" logging: \"off\"", "label": 0, "commit_name": "fix: latest Raspbian and Ansible support"}
{"code": "- name: create a monitoring namespace tags: [k8s, k8s-hetzner] tags: [k8s, k8s-hetzner] tags: [k8s, k8s-hetzner] tags: [k8s, k8s-hetzner] tags: [k8s, k8s-hetzner] tags: [k8s, k8s-hetzner] tags: [k8s, k8s-hetzner]", "label": 1, "commit_name": "fix: kubeadm secret upload name & role tags"}
{"code": "- name: create a hcloud namespace tags: [k8s, k8s-init, k8s-hetzner] tags: [k8s, k8s-init, k8s-hetzner] tags: [k8s, k8s-init, k8s-hetzner] tags: [k8s, k8s-init, k8s-hetzner] tags: [k8s, k8s-init, k8s-hetzner] tags: [k8s, k8s-init, k8s-hetzner] tags: [k8s, k8s-init, k8s-hetzner]", "label": 0, "commit_name": "fix: kubeadm secret upload name & role tags"}
{"code": "{% for port in ( nginx_stream_configs | dict2items | map(attribute='value') | map(attribute='public_port') | unique ) %} security: \"{{ security_ports | from_yaml }}\" nginx_stream_configs: \"{{ nginx_configs }}\"", "label": 1, "commit_name": "fix: fix stream and testing"}
{"code": "{% for port in nginx_stream_configs.stream.public_ports %} security: security_ports: \"{{ security_ports | from_yaml }}\" nginx_extra_root_params: - load_module '/usr/lib64/nginx/modules/ngx_stream_module.so'", "label": 0, "commit_name": "fix: fix stream and testing"}
{"code": "template: template:", "label": 1, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "ansible.builtin.template: ansible.builtin.template:", "label": 0, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "file: src=/home/{{user_name}}/.ssh/id_rsa.pub dest=/home/{{user_name}}/.ssh/authorized_key state=link", "label": 1, "commit_name": "Fxing ssh key and authorized_keys"}
{"code": "file: src=/home/{{user_name}}/.ssh/id_rsa.pub dest=/home/{{user_name}}/.ssh/authorized_keys state=link", "label": 0, "commit_name": "Fxing ssh key and authorized_keys"}
{"code": "command: \"docker inspect --format='{{'{{'}} .state.status {{'}}'}}' test{{ distro.name|replace('-','') }}_{{ distro.name }}_1\" command: \"docker inspect --format='{{'{{'}} .state.startedat {{'}}'}}' test{{ distro.name|replace('-','') }}_{{ distro.name }}_1\" command: \"docker inspect --format='{{'{{'}} .state.status {{'}}'}}' test{{ distro.name|replace('-','') }}_{{ distro.name }}_1\" command: \"docker inspect --format='{{'{{'}} .state.startedat {{'}}'}}' test{{ distro.name|replace('-','') }}_{{ distro.name }}_1\" command: \"docker inspect --format='{{'{{'}} .state.status {{'}}'}}' test{{ distro.name|replace('-','') }}_{{ distro.name }}_1\"", "label": 1, "commit_name": "Merge pull request #939 from softasap/regression-test-fixes"}
{"code": "command: \"docker inspect --format='{{'{{'}} .state.status {{'}}'}}' test-{{ distro.name }}_{{ distro.name }}_1\" command: \"docker inspect --format='{{'{{'}} .state.startedat {{'}}'}}' test-{{ distro.name }}_{{ distro.name }}_1\" command: \"docker inspect --format='{{'{{'}} .state.status {{'}}'}}' test-{{ distro.name }}_{{ distro.name }}_1\" command: \"docker inspect --format='{{'{{'}} .state.startedat {{'}}'}}' test-{{ distro.name }}_{{ distro.name }}_1\" command: \"docker inspect --format='{{'{{'}} .state.status {{'}}'}}' test-{{ distro.name }}_{{ distro.name }}_1\"", "label": 0, "commit_name": "Merge pull request #939 from softasap/regression-test-fixes"}
{"code": "- hosts: localhost roles: - role: common tags: - common - role: satnogs tags: - satnogs", "label": 1, "commit_name": "Fix playbook used by 'ansible-pull'"}
{"code": "- import_playbook: satnogses.yml", "label": 0, "commit_name": "Fix playbook used by 'ansible-pull'"}
{"code": "community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw: community.general.system.ufw:", "label": 1, "commit_name": "Merge branch '116-deprecation-warning-wrong-use-of-internal-ref-for-ufw-module' into 'master'"}
{"code": "community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw: community.general.ufw:", "label": 0, "commit_name": "Merge branch '116-deprecation-warning-wrong-use-of-internal-ref-for-ufw-module' into 'master'"}
{"code": "ansible-galaxy install -r requirements.yml -p ./roles", "label": 1, "commit_name": "Fix CI for new collections-based world."}
{"code": "ansible-galaxy install -r requirements.yml", "label": 0, "commit_name": "Fix CI for new collections-based world."}
{"code": "name: \"{{ secondary_instance }}-pgbouncer-trackingdb\" device_name: \"disk-instance-secondary-pgbouncer-trackingdb-{{ prefix_name }}\" disk_name: \"disk-instance-secondary-pgbouncer-trackingdb-{{ prefix_name }}\"", "label": 1, "commit_name": "Fix bootstrapping"}
{"code": "name: \"{{ secondary_instance }}-trackingdb-pgbouncer\" device_name: \"disk-instance-secondary-trackingdb-pgbouncer-{{ prefix_name }}\" disk_name: \"disk-instance-secondary-trackingdb-pgbouncer-{{ prefix_name }}\"", "label": 0, "commit_name": "Fix bootstrapping"}
{"code": "- name: install keepassxc password manager and required packages become: true community.general.pacman: name: - keepassxc state: present - name: copy keepassxc-proxy binary into /usr/bin/ become: true ansible.builtin.copy: remote_src: false src: files/browser/native-messaging-hosts/keepassxc-proxy dest: /usr/bin/keepassxc-proxy owner: root group: root mode: '0755'", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "- name: install keepassxc password manager and required packages become: true community.general.pacman: name: - keepassxc state: present # note: not necessary?: https://archlinux.org/packages/community/x86_64/keepassxc/ # - name: copy keepassxc-proxy binary into /usr/bin/ # become: true # ansible.builtin.copy: # remote_src: false # src: files/browser/native-messaging-hosts/keepassxc-proxy # dest: /usr/bin/keepassxc-proxy # owner: root # group: root # mode: '0755' - name: set keepassxc theme to system (classic) ansible.builtin.blockinfile: path: ~/.config/keepassxc/keepassxc.ini marker: '# {mark} keepassxc_theme' block: | [gui] applicationtheme=classic mode: '0644' create: true state: present", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "dest: \"{{alertmanager_home}}/alertmanager.yml\" owner: \"{{alertmanager_username}}\" group: \"{{alertmanager_username}}\" path: \"{{alertmanager_home}}/alertmanager_templates\" owner: \"{{alertmanager_username}}\" group: \"{{alertmanager_username}}\" template: src: \"templates/alertmanager_templates/{{item}}.yml\" dest: \"{{alertmanager_home}}/alertmanager_templates/{{item}}\" owner: \"{{alertmanager_username}}\" group: \"{{alertmanager_username}}\" with_items: \"{{alertmanager_templates}}\"", "label": 1, "commit_name": "fixes in ansible syntax. using more default values and making environment deployment easier."}
{"code": "dest: \"{{ alertmanager_home }}/alertmanager.yml\" owner: \"{{ alertmanager_username }}\" group: \"{{ alertmanager_username }}\" path: \"{{ alertmanager_home }}/alertmanager_templates\" owner: \"{{ alertmanager_username }}\" group: \"{{ alertmanager_username }}\" copy: src: \"templates/alertmanager_templates/{{ item }}\" dest: \"{{ alertmanager_home }}/alertmanager_templates/{{ item }}\" owner: \"{{ alertmanager_username }}\" group: \"{{ alertmanager_username }}\" with_items: \"{{ alertmanager_templates }}\"", "label": 0, "commit_name": "fixes in ansible syntax. using more default values and making environment deployment easier."}
{"code": "src: ~/fiji.app/imagej2.desktop dest: ~/bureau/imagej2.desktop", "label": 1, "commit_name": "Fix launcher creation in fiji.yml"}
{"code": "dest: ~/bureau/imagej.desktop content: | [desktop entry] version=1.0 name=imagej type=application exec=/home/guest/fiji.app/imagej-linux64 %f tryexec=/home/guest/fiji.app/imagej-linux64 terminal=false startupnotify=true mimetype=image/*; icon=/home/guest/fiji.app/images/icon.png startupwmclass=net-imagej-launcher-classlauncher mode: u+x", "label": 0, "commit_name": "Fix launcher creation in fiji.yml"}
{"code": "easy_rsa_ca_dir: \"/etc/openvpn/easy-rsa/keys\"", "label": 1, "commit_name": "fixes, tags added"}
{"code": "openvpn_rsa_ca_dir: \"/etc/openvpn/easy-rsa/keys\"", "label": 0, "commit_name": "fixes, tags added"}
{"code": "password: \"!$6$qtedotqx1et7$/eb6izuwjyf2vfxjy7qbyzfolbuujw.gw9k1obcrgvrsxy42dyv1gt9nenaewt7ua198bya4wi4skvdjzhn/z.\"", "label": 1, "commit_name": "Fix merge conflict"}
{"code": "password: \"$6$q1kzaqpo3dga4$/qsdz33s.emvfa7s.nli97ddeulrf2ie3zxspjphx5e.azbcebc.ulrjids5d2t11iv.j5gsq4qzkvwohsk2x1\"", "label": 0, "commit_name": "Fix merge conflict"}
{"code": "- import_tasks: rehl.yml when: ansible_facts['os_family']|lower == 'debian'", "label": 1, "commit_name": "YAML Linting and RHEL Spelling Error"}
{"code": "- import_tasks: rhel.yml when: ansible_facts['os_family']|lower == 'debian'", "label": 0, "commit_name": "YAML Linting and RHEL Spelling Error"}
{"code": "- name: create docker ipvlan voip network", "label": 1, "commit_name": "5046 mds install fixes"}
{"code": "- name: mds specicic actions vars: mds_server: \"{{ mds_servers | selectattr('ip', 'eq', inventory_hostname) | list)[0] }}\"", "label": 0, "commit_name": "5046 mds install fixes"}
{"code": "- https://raw.github.com/georchestra/georchestra/master/postgresql/060-ogc-server-statistics.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/070-atlas.sql", "label": 1, "commit_name": "fix the fix, thx @fvanderbiest (#61)"}
{"code": "- https://raw.github.com/georchestra/georchestra/master/postgresql/050-ogc-server-statistics.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/060-atlas.sql", "label": 0, "commit_name": "fix the fix, thx @fvanderbiest (#61)"}
{"code": "tags: tags: tags: tags:", "label": 1, "commit_name": "mothball attacks"}
{"code": "tags: tags: tags: tags:", "label": 0, "commit_name": "mothball attacks"}
{"code": "systemd: enabled: yes set_fact: systemd: enabled: yes", "label": 1, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "ansible.builtin.systemd: enabled: true ansible.builtin.set_fact: ansible.builtin.systemd: enabled: true", "label": 0, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "- name: make sure snapd is installed using apt - name: install microk8s using snap - name: wait for microk8s to be ready - name: create kubectl alias - name: create helm3 alias - name: install helm diff plugin if not already installed - name: update the helm plugins", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"microk8s: make sure snapd is installed using apt\" - name: \"microk8s: install microk8s using snap\" - name: \"microk8s: wait for microk8s to be ready\" - name: \"microk8s: create kubectl alias\" - name: \"microk8s: create helm3 alias\" - name: \"microk8s: install helm diff plugin if not already installed\" - name: \"microk8s: update the helm plugins\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "hosts: \"all:&apacheds\" register: java_version_output changed_when: java_version_output.rc != 0 failed_when: \"'build {{ inv_java_version }}' not in java_version_output.stderr\" - name: \"check java versions {{ inv_java_version }}/8 binaires files\" block: - name: \"check java java-{{ inv_java_version }} custom binaries\" loop: - \"/usr/bin\" - \"/bin\" loop_control: loop_var: java_path register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ java_path }}/java-{{ inv_java_version }}\" - name: \"verify java -version, with custom binaries\" block: - name: \"verify java -version, with custom binaries for java {{ inv_java_version }}\" loop: - \"java-{{ inv_java_version }}\" - \"/usr/bin/java-{{ inv_java_version }}\" - \"/bin/java-{{ inv_java_version }}\" loop_control: loop_var: java_call register: java_version_output changed_when: java_version_output.rc != 0 failed_when: \"'build {{ inv_java_version }}' not in java_version_output.stderr\" ansible.builtin.command: \"{{ java_call }} -version\" register: install_apacheds_service_status failed_when: not install_apacheds_service_status.status.activestate == 'active' loop: \"{{ inv_install_apacheds_instances }}\" loop: \"{{ inv_install_apacheds_instances }}\" loop: \"{{ inv_install_apacheds_instances }}\" loop: \"{{ inv_install_apacheds_instances }}\"", "label": 1, "commit_name": "refacto done, force ci"}
{"code": "hosts: \"cicd-debian-11\" register: instal_java__version_output changed_when: instal_java__version_output.rc != 0 failed_when: \"'build {{ inv_install_java__version }}' not in instal_java__version_output.stderr\" - name: \"verify java -version, with custom binaries for java {{ inv_install_java__version }}\" loop: - \"java-{{ inv_install_java__version }}\" - \"/usr/bin/java-{{ inv_install_java__version }}\" - \"/bin/java-{{ inv_install_java__version }}\" loop_control: loop_var: instal_java__call register: instal_java__version_output changed_when: instal_java__version_output.rc != 0 failed_when: \"'build {{ inv_install_java__version }}' not in instal_java__version_output.stderr\" ansible.builtin.command: \"{{ instal_java__call }} -version\" register: install_apacheds__service_status failed_when: not install_apacheds__service_status.status.activestate == 'active' loop: \"{{ inv_install_apacheds__instances }}\" loop: \"{{ inv_install_apacheds__instances }}\" loop: \"{{ inv_install_apacheds__instances }}\" loop: \"{{ inv_install_apacheds__instances }}\"", "label": 0, "commit_name": "refacto done, force ci"}
{"code": "user: centos hosts: meta-type_zabbix user: centos become: true - name: check borg_pass set_fact: borg_user_pass: \"{{ lookup('env', 'borg_pass')}}\" - assert: that: - borg_user_pass is defined and (borg_user_pass | length > 5) - backup_location_path is defined and (backup_location_path | length > 0) - name: create dir for ssh_keys file: state: dir mode: 700 path: \"~/ansible-playbooks-data/borg/ssh_keys\" register: ssh_keys_dir delegate_to: localhost - name: generate keypair community.crypto.openssh_keypair: path: \"{{ ssh_keys_dir.path }}/{{ ansible_hostname }}_deploy_key\" register: ssh_key_pair delegate_to: localhost - name: register private key contents set_fact: ssh_private_key: \"{{ lookup('file', ssh_key_pair.filename) }}\"", "label": 1, "commit_name": "Merge branch 'fixes' into 'master'"}
{"code": "hosts: all:!borg_server become: true - block: - name: check borg_pass set_fact: borg_user_pass: \"{{ lookup('env', 'borg_pass')}}\" - assert: that: - borg_user_pass is defined and (borg_user_pass | length > 5) - backup_location_path is defined and (backup_location_path | length > 0) - name: create dir for ssh_keys file: state: directory mode: 700 path: \"~/ansible-playbooks-data/borg/ssh_keys\" register: ssh_keys_dir - name: generate keypair community.crypto.openssh_keypair:- name: check borg_pass set_fact: borg_user_pass: \"{{ lookup('env', 'borg_pass')}}\" - name: create dir for ssh_keys file: state: directory mode: 700 path: \"~/ansible-playbooks-data/borg/ssh_keys\" register: ssh_keys_dir - name: generate keypair community.crypto.openssh_keypair: path: \"{{ ssh_keys_dir.path }}/{{ ansible_hostname }}_deploy_key\" register: ssh_key_pair - name: register private key contents slurp: src: \"{{ ssh_key_pair.filename }}\" register: private_key_b64 - set_fact: ssh_private_key: \"{{ private_key_b64.content | b64decode }}\" become: false", "label": 0, "commit_name": "Merge branch 'fixes' into 'master'"}
{"code": "- sftp", "label": 1, "commit_name": "Add phpmyadmin; fix handlers"}
{"code": "- sftp - phpmyadmin", "label": 0, "commit_name": "Add phpmyadmin; fix handlers"}
{"code": "hostname: \"{{ item.natip }}\" groupname: secondary_nodes - \"{{ gce_secondary.networkinterfaces[0].accessconfigs[0] }}\" - name: save secondary host add_host: name: \"{{ gce_secondary.networkinterfaces[0].accessconfigs[0].natip }}\" groups: secondary_host host: \"{{ item.natip }}\" - \"{{ gce_secondary.networkinterfaces[0].accessconfigs[0] }}\"", "label": 1, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "hostname: \"{{ item.networkinterfaces[0].accessconfigs[0].natip }}\" groups: - secondary_nodes - secondary_host - \"{{ gce_secondary }}\" host: \"{{ item.networkinterfaces[0].accessconfigs[0].natip }}\" - \"{{ gce_secondary }}\"", "label": 0, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "amd64:3.12: amd64:3.12:", "label": 1, "commit_name": "Fix build step for Alpine 3.13 and 3.14"}
{"code": "amd64:3.14: amd64:3.13:", "label": 0, "commit_name": "Fix build step for Alpine 3.13 and 3.14"}
{"code": "- pubrt.route_table.id - prirt.route_table.id pubrtid: \"{{pubrt.route_table.id}}\" prirtid: \"{{prirt.route_table.id}}\" content: \"vpcoutid: {{vpcout.vpc.id}}\\npubsub1id: {{pubsub1_out.subnet.id}}\\npubsub2id: {{pubsub2_out.subnet.id}}\\npubsub3did: {{pubsub3_out.subnet.id}}\\nprisub1id: {{prisub1_out.subnet.id}}\\nprisub2id: {{prisub2_out.subnet.id}}\\nprisub3id: {{prisub3_out.subnet.id}}\\nigwid: {{igw_out.gateway_id}}\\npubrtid: {{pubrt.route_table.id}}\\nnatgwid: {{natgw_out.nat_gateway_id}}\\nprirtid: {{prirt.route_table.id}}\"", "label": 1, "commit_name": "new code is added to playbook13"}
{"code": "- pubrt_out.route_table.id - prirt_out.route_table.id pubrtid: \"{{pubrt_out.route_table.id}}\" prirtid: \"{{prirt_out.route_table.id}}\" content: \"vpcoutid: {{vpcout.vpc.id}}\\npubsub1id: {{pubsub1_out.subnet.id}}\\npubsub2id: {{pubsub2_out.subnet.id}}\\npubsub3did: {{pubsub3_out.subnet.id}}\\nprisub1id: {{prisub1_out.subnet.id}}\\nprisub2id: {{prisub2_out.subnet.id}}\\nprisub3id: {{prisub3_out.subnet.id}}\\nigwid: {{igw_out.gateway_id}}\\npubrtid: {{pubrt_out.route_table.id}}\\nnatgwid: {{natgw_out.nat_gateway_id}}\\nprirtid: {{prirt_out.route_table.id}}\"", "label": 0, "commit_name": "new code is added to playbook13"}
{"code": "ansible.builtin.user: \"{{ username }}\" ansible.builtin.user: \"{{ username }}\"", "label": 1, "commit_name": "lint fixes"}
{"code": "user: \"{{ username }}\" user: \"{{ username }}\"", "label": 0, "commit_name": "lint fixes"}
{"code": "user: cumulus pwd: cumuluslinux! transport: ssh", "label": 1, "commit_name": "Error /etc/network does not exist"}
{"code": "ansible_user: cumulus ansible_pass: cumuluslinux! ansible_become_pass: cumuluslinux!", "label": 0, "commit_name": "Error /etc/network does not exist"}
{"code": "register: vproelb-sg group_id: \"{{vproelb-sg.group_id}}\"", "label": 1, "commit_name": "new code is added to playbook13"}
{"code": "vpc_id: \"{{vpcoutid}}\" register: vproelbsg_out vpc_id: \"{{vpcoutid}}\" purge_rules: no group_id: \"{{vproelbsg_out.group_id}}\" vpc_id: \"{{vpcoutid}}\" purge_rules: no", "label": 0, "commit_name": "new code is added to playbook13"}
{"code": "- name: \"update apt ackages\"", "label": 1, "commit_name": "Fix typo"}
{"code": "- name: \"update apt packages\"", "label": 0, "commit_name": "Fix typo"}
{"code": "when: (\"ntp=yes\" not in ntpcheck.stdout)", "label": 1, "commit_name": "base/time: ignore errors when in check mode"}
{"code": "ignore_errors: \"{{ ansible_check_mode }}\" when: '\"ntp=yes\" not in ntpcheck.stdout'", "label": 0, "commit_name": "base/time: ignore errors when in check mode"}
{"code": "become: yes - tomcat-base", "label": 1, "commit_name": "Merge branch '13-broken-playbook-to-copy-and-paste-error' into 'main'"}
{"code": "become: true - tomcat-base", "label": 0, "commit_name": "Merge branch '13-broken-playbook-to-copy-and-paste-error' into 'main'"}
{"code": "name: [dnsmasq, debian-installer-{{ ansible_distribution_version }}-amd64", "label": 1, "commit_name": "fix array reference"}
{"code": "name: [dnsmasq, debian-installer-{{ ansible_distribution_version }}-amd64]", "label": 0, "commit_name": "fix array reference"}
{"code": "- name: install stow hosts: all tasks: - name: install gnu stow become: true apt: state: present name: - stow", "label": 1, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "- name: install gnu stow become: true apt: state: present name: - stow", "label": 0, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "when: gitlab_groups is defined when: gitlab_group_members is defined when: gitlab_projects is defined when: gitlab_projects is defined and item.state | default('present') == 'present' when: gitlab_project_members is defined", "label": 1, "commit_name": "Remove futile check on null lists"}
{"code": "when: item.state | default('present') == 'present'", "label": 0, "commit_name": "Remove futile check on null lists"}
{"code": "- \"[packages_installation] actions to do after packages installation\"", "label": 1, "commit_name": "fix namespace of handlers in notify instruction"}
{"code": "- \"[packages_installation] => actions to do after packages installation\"", "label": 0, "commit_name": "fix namespace of handlers in notify instruction"}
{"code": "packages: tmux,htop,procps,bash,less,mtr,rsync", "label": 1, "commit_name": "fixes found due to end to end testing"}
{"code": "packages: tmux,htop,procps,bash,less,mtr,rsync,sudo", "label": 0, "commit_name": "fixes found due to end to end testing"}
{"code": "- name: install apt-utils name: \"apt-utils\"", "label": 1, "commit_name": "Fix bootstrap dependencies to work with ubuntu 18.04"}
{"code": "- name: install dependencies name: \"{{ item }}\" with_items: - apt-utils - tzdata", "label": 0, "commit_name": "Fix bootstrap dependencies to work with ubuntu 18.04"}
{"code": "- caskroom/cask", "label": 1, "commit_name": "Fix homebrew_taps in default config file."}
{"code": "- homebrew/cask", "label": 0, "commit_name": "Fix homebrew_taps in default config file."}
{"code": "- pleroma-postgres - pleroma-postgres - pleroma-nginx - pleroma-nginx", "label": 1, "commit_name": "fix: update ansible role names"}
{"code": "- pleroma-database - pleroma-database - pleroma-proxy - pleroma-proxy", "label": 0, "commit_name": "fix: update ansible role names"}
{"code": "tasks: - name: add docker.io repository apt: name=docker.io state=present - name: fix docker path raw: ln -sf /usr/bin/docker.io /usr/local/bin/docker raw: sed -i '$acomplete -f _docker docker' /etc/bash_completion.d/docker.io - name: run docker on boot raw: update-rc.d docker.io defaults", "label": 1, "commit_name": "fix docker role"}
{"code": "- name: add docker.io repository apt: name=docker.io state=present - name: fix docker path raw: ln -sf /usr/bin/docker.io /usr/local/bin/docker raw: sed -i '$acomplete -f _docker docker' /etc/bash_completion.d/docker.io - name: run docker on boot raw: update-rc.d docker.io defaults", "label": 0, "commit_name": "fix docker role"}
{"code": "- primary_patronis", "label": 1, "commit_name": "Fix secondary patroni group hosts"}
{"code": "- secondary_patronis", "label": 0, "commit_name": "Fix secondary patroni group hosts"}
{"code": "# note: cabextract requires elevation # note: cabextract requires elevation", "label": 1, "commit_name": "linting fixes"}
{"code": "# note: cabextract requires elevation # note: cabextract requires elevation", "label": 0, "commit_name": "linting fixes"}
{"code": "keep_packages_updated: true", "label": 1, "commit_name": "Fix test.yml. Set keep_packages_updated back to false"}
{"code": "keep_packages_updated: false", "label": 0, "commit_name": "Fix test.yml. Set keep_packages_updated back to false"}
{"code": "- desktop-oh-my-zsh #- desktop-zoom", "label": 1, "commit_name": "Fix playbooks for kubuntu focal with new additions"}
{"code": "- desktop-anydesk - desktop-zoom", "label": 0, "commit_name": "Fix playbooks for kubuntu focal with new additions"}
{"code": "- name: install gnome-extension-app community.general.flatpak: name: org.gnome.extensions remote: fedora value: 'appmenu:minimize,maximize,close'", "label": 1, "commit_name": "Fix error for the terminal and flatpak error"}
{"code": "- name: fix for flatpak dbus error ansible.builtin.dnf: name: dbus-x11 - name: install gnome-extension-app ansible.builtin.shell: > dbus-launch --exit-with-session flatpak install --system --noninteractive fedora org.gnome.extensions become: true #- name: install gnome-extension-app # community.general.flatpak: # name: org.gnome.extensions # state: present # remote: fedora # become: true value: \"'appmenu:minimize,maximize,close'\"", "label": 0, "commit_name": "Fix error for the terminal and flatpak error"}
{"code": "host_all: yes", "label": 1, "commit_name": "Fix yamllint errors"}
{"code": "host_all: true", "label": 0, "commit_name": "Fix yamllint errors"}
{"code": "- name: add mds {{ mds_name }} to the mds_list in factory.env - name: check if mds_list containd mds {{ mds_name }} - name: add mds {{ mds_name }} to the mds_list in factory.env", "label": 1, "commit_name": "5046 fix problem with passing mds_name variable"}
{"code": "- debug: var: mds_server - debug: var: inventory_hostname - name: add mds to the mds_list in factory.env - name: check if mds_list containd mds name - name: add mds to the mds_list in factory.env", "label": 0, "commit_name": "5046 fix problem with passing mds_name variable"}
{"code": "- name: sleep for 3 minutes minutes: 3", "label": 1, "commit_name": "Adjust the time to pause"}
{"code": "- name: wait for 2 minutes until instance is ready minutes: 2", "label": 0, "commit_name": "Adjust the time to pause"}
{"code": "- name: \"check soanrqube http url\" register: result failed_when: result.status != 200 ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_install_sonarqube__web_port }}/\" method: \"get\"", "label": 1, "commit_name": "fix CI tests"}
{"code": "#- name: \"check sonarqube http url\" # register: result # failed_when: result.status != 200 # ansible.builtin.uri: # url: \"http://{{ inventory_hostname }}:{{ inv_install_sonarqube__web_port }}/\" # method: \"get\"", "label": 0, "commit_name": "fix CI tests"}
{"code": "remote_user: root # - role: solr # become: yes # - role: spotlight # become: yes", "label": 1, "commit_name": "fix ssh user/group"}
{"code": "remote_user: adrl # deploy_user: adrl # deploy_group: adrl - role: solr become: yes - role: spotlight become: yes", "label": 0, "commit_name": "fix ssh user/group"}
{"code": "owner: www group: www", "label": 1, "commit_name": "fix username"}
{"code": "owner: apache group: apache", "label": 0, "commit_name": "fix username"}
{"code": "- openstack.cloud", "label": 1, "commit_name": "fix: updated dep URIs"}
{"code": "- name: \"openstack.cloud\" - name: \"ansible.posix\"", "label": 0, "commit_name": "fix: updated dep URIs"}
{"code": "copy: command: /usr/sbin/locale-gen copy: command: timedatectl status command: timedatectl set-timezone {{ timezone }} command: localectl status command: localectl set-locale lang={{ lang }} command: localectl set-locale language={{ language }}", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.copy: mode: \"0644\" ansible.builtin.command: /usr/sbin/locale-gen ansible.builtin.copy: mode: \"0644\" ansible.builtin.command: timedatectl status ansible.builtin.command: timedatectl set-timezone {{ timezone }} ansible.builtin.command: localectl status ansible.builtin.command: localectl set-locale lang={{ lang }} ansible.builtin.command: localectl set-locale language={{ language }}", "label": 0, "commit_name": "refactor: lint"}
{"code": "- \"travis_wait 30 ansible-playbook --extra-vars '{\\\"configure_sudoers\\\":\\\"false\\\"}' main.yml\"", "label": 1, "commit_name": "Issue #63: Try using travis_wait without escaping the double quotes."}
{"code": "- > travis_wait 30 ansible-playbook --extra-vars '{\"configure_sudoers\":\"false\"}' main.yml", "label": 0, "commit_name": "Issue #63: Try using travis_wait without escaping the double quotes."}
{"code": "- redhat.rhel_idm.ipaserver: ipaadmin_password: \"%testpassword%\" name: idm.idhaoui.ansible-labs.de", "label": 1, "commit_name": "fix indentation"}
{"code": "- name: setup idm server: redhat.rhel_idm.ipaserver: ipaadmin_password: \"%testpassword%\" name: idm.idhaoui.ansible-labs.de", "label": 0, "commit_name": "fix indentation"}
{"code": "kubectl cp -n {{ namespace }} {{ pod_name.stdout }}:/{{ wiki_archive }} data/", "label": 1, "commit_name": "Fix download path"}
{"code": "- name: create local dir file: path: data state: directorry kubectl cp -n {{ namespace }} {{ pod_name.stdout }}:/{{ wiki_archive }} data/{{ wiki_archive }}", "label": 0, "commit_name": "Fix download path"}
{"code": "- name: get gitlab project configuration - name: get gitlab project labels - name: get gitlab group labels", "label": 1, "commit_name": "ansible-lint: Fix some errors"}
{"code": "changed_when: true - name: get gitlab project configuration # noqa jinja[spacing] changed_when: true changed_when: true changed_when: true - name: get gitlab project labels # noqa jinja[spacing] changed_when: true changed_when: true changed_when: true - name: get gitlab group labels # noqa jinja[spacing] changed_when: true changed_when: true changed_when: true", "label": 0, "commit_name": "ansible-lint: Fix some errors"}
{"code": "nodered: container_name: nodered build: '{{ services_env_path }}/nodered/.' restart: unless-stopped user: '0' privileged: true env_file: '{{ services_env_path }}/nodered/nodered.env' - 1880:1880 - '{{ services_volume_path }}/nodered/data:/data' nordcloud: image: nextcloud container_name: nextcloud ports: - 9321:80 volumes: - '{{ services_volume_path }}/nextcloud/html:/var/www/html' depends_on: - nextcloud_db links: - nextcloud_db nextcloud_db: image: linuxserver/mariadb container_name: nextcloud_db - '{{ services_volume_path }}/nextcloud/db:/config' environment: - mysql_root_password=password - mysql_password=password - mysql_database=nextcloud - mysql_user=nextcloud restart: unless-stopped", "label": 1, "commit_name": "#5 documentation of the services"}
{"code": "nextcloud: image: nextcloud container_name: nextcloud - 9321:80 - '{{ services_volume_path }}/nextcloud/html:/var/www/html' restart: unless-stopped depends_on: - nextcloud_db links: - nextcloud_db nextcloud_db: image: linuxserver/mariadb container_name: nextcloud_db volumes: - '{{ services_volume_path }}/nextcloud/db:/config' environment: - mysql_root_password=password - mysql_password=password - mysql_database=nextcloud - mysql_user=nextcloud restart: unless-stopped nodered: container_name: nodered build: '{{ services_env_path }}/nodered/.' user: '0' privileged: true env_file: '{{ services_env_path }}/nodered/nodered.env' ports: - 1880:1880 - '{{ services_volume_path }}/nodered/data:/data'", "label": 0, "commit_name": "#5 documentation of the services"}
{"code": "- include: rkhunter.yml - include: iptables.yml", "label": 1, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "- include: iptables.yml - include: rkhunter.yml - include: sysctl.yml - name: prevent ip spoofing. lineinfile: dest: /etc/host.conf line: \"nospoof on\"", "label": 0, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "sonarr_api_key: '{{ lookup(\"ansible.builtin.password\", \"/tmp/passwordfile chars=hexdigits length=32 seed=ansible_hostname\") }}'", "label": 1, "commit_name": "fix: change path parameter for password generation"}
{"code": "sonarr_api_key: '{{ lookup(\"ansible.builtin.password\", \"/dev/null chars=hexdigits length=32 seed=ansible_hostname\") }}'", "label": 0, "commit_name": "fix: change path parameter for password generation"}
{"code": "vpc_id: \"{{vpcout.vpd.id}}\"", "label": 1, "commit_name": "new code is added to playbook13"}
{"code": "vpc_id: \"{{vpcout.vpc.id}}\"", "label": 0, "commit_name": "new code is added to playbook13"}
{"code": "roles: - role: configure-client", "label": 1, "commit_name": "Change: A few linting errors"}
{"code": "roles: - name: create clients role: configure-client", "label": 0, "commit_name": "Change: A few linting errors"}
{"code": "- name: remove old gitlab-runner ansible.builtin.file: path: /etc/gitlab-runner/config.toml state: absent - name: install python-gitlab pip: name: python-gitlab - name: \"register a docker in docker runner\" community.general.gitlab_runner: api_url: https://gitlab.com/ api_token: \"{{ gitlab_api_access_token }}\" registration_token: \"{{ runner_token }}\" description: docker runner state: present active: true tag_list: ['docker'] run_untagged: false locked: false", "label": 1, "commit_name": "-> Solve issue \ud83d\udca1:"}
{"code": "- name: register a docker in docker runner (sudo) copy: src: files/config.toml dest: /etc/gitlab-runner/config.toml force: yes notify: - verify and add new runners - name: register a docker in docker runner ( non_sudo - {{master_user}} ) copy: src: files/config.toml dest: /home/{{master_user}}/.gitlab-runner/config.toml force: yes notify: - verify and add new runners", "label": 0, "commit_name": "-> Solve issue \ud83d\udca1:"}
{"code": "- name: rgw pool realted tasks", "label": 1, "commit_name": "rgw: fix a typo"}
{"code": "- name: rgw pool related tasks", "label": 0, "commit_name": "rgw: fix a typo"}
{"code": "hosts: all tasks: - name: install vim become: true apt: state: present name: - vim", "label": 1, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "become: true apt: state: present name: - vim", "label": 0, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "when: not stat_cert_pub.stat.exists when: not stat_cert_priv.stat.exists when: \"'mailserver' in group_names\"", "label": 1, "commit_name": "postfix: check if a real SSL key is available (and use it if so) even for non-mailservers"}
{"code": "when: - not stat_cert_pub.stat.exists - \"'mailserver' in group_names\" when: - not stat_cert_pub.stat.exists - \"'mailserver' in group_names\"", "label": 0, "commit_name": "postfix: check if a real SSL key is available (and use it if so) even for non-mailservers"}
{"code": "content: | backend = systemd", "label": 1, "commit_name": "fix blockinfile of sshd"}
{"code": "block: | backend = systemd", "label": 0, "commit_name": "fix blockinfile of sshd"}
{"code": "become_user: \"{{ gocd_user }}\" become: yes", "label": 1, "commit_name": "Merge pull request #31 from boukeversteegh/bugfix/ansible-1-8-compatibility"}
{"code": "sudo_user: \"{{ gocd_user }}\" sudo: yes", "label": 0, "commit_name": "Merge pull request #31 from boukeversteegh/bugfix/ansible-1-8-compatibility"}
{"code": "version: 0.6.0 version: 2.0.2", "label": 1, "commit_name": "Update ansible-docker-matrix to fix (finally) the tmpfs formatting bug"}
{"code": "version: 0.7.0 version: 2.0.3", "label": 0, "commit_name": "Update ansible-docker-matrix to fix (finally) the tmpfs formatting bug"}
{"code": "when: wait_service_staus is undefined and wait_service_tasks.tasks | count == 0 when: wait_service_tasks.tasks | count > 0 wait_service_time: \"{{ wait_service_status is in terminate_states | ternary(0, 3) }}\"", "label": 1, "commit_name": "5046 fixes in mds wait service role"}
{"code": "when: wait_service_status is undefined and wait_service_tasks.tasks | count == 0 when: wait_service_tasks.tasks | count > 0 and wait_service_tasks.tasks[0].currentstate is defined wait_service_time: \"{{ wait_service_status is in terminate_states | ternary(0, 5) }}\"", "label": 0, "commit_name": "5046 fixes in mds wait service role"}
{"code": "- name: autoremove the rest autoremove: true - name: update packages to latest upgrade: full", "label": 1, "commit_name": "Add full LXC provisioning, add lxd hosts"}
{"code": "when: not is_lxc #when: not is_lxc - name: clean up trash default packages (lxc) name: - apparmor - apport - apport-symptoms - bcache-tools - busybox-static - cloud-guest-utils - cloud-init - cloud-initramfs-copymods - cloud-initramfs-dyn-netconf - command-not-found - console-setup - console-setup-linux - cryptsetup - cryptsetup-bin - dbus - dmeventd - dmsetup - bind9-dnsutils - dosfstools - dmidecode - eatmydata - ed - ethtool - fonts-ubuntu-console - friendly-recovery - ftp - fuse - gdisk - gir1.2-glib-2.0 - hdparm - info - install-info - iptables - iputils-tracepath - irqbalance - iso-codes - kbd - kmod - krb5-locales - libaccountsservice0 - libasound2 - libdbus-1-3 - libdevmapper-event1.02.1 - libdrm2 - libeatmydata1 - libfuse2 - libgirepository-1.0-1 - libglib2.0-data - libmspack0 - libnetfilter-conntrack3 - libnfnetlink0 - libnuma1 - libpam-systemd - libparted2 - libpolkit-agent-1-0 - libpolkit-gobject-1-0 - libreadline5 - libsasl2-modules - libxmuu1 - lshw - lvm2 - manpages - mdadm - motd-news-config - nano - ncurses-term - netcat-openbsd - ntfs-3g - open-iscsi - open-vm-tools - overlayroot - parted - pastebinit - patch - plymouth - plymouth-theme-ubuntu-text - pollinate - popularity-contest - powermgmt-base - publicsuffix - run-one - shared-mime-info - software-properties-common - sosreport - squashfs-tools - ssh-import-id - ubuntu-advantage-tools - ubuntu-release-upgrader-core - ufw - unattended-upgrades - update-manager-core - update-notifier-common - uuid-runtime - xauth - xdg-user-dirs - xfsprogs - xz-utils - zerofree purge: true state: absent when: is_lxc - name: autoremove the rest autoremove: true", "label": 0, "commit_name": "Add full LXC provisioning, add lxd hosts"}
{"code": "# on s\u00e9lectionne le groupe de serveurs \u00e0 d\u00e9ployer via le param\u00e8tre de la cli # ex\u00e9cution des t\u00e2ches du playbook # cr\u00e9ation des groupes n\u00e9cessaires au syst\u00e8me # cr\u00e9ation des utilisateurs n\u00e9cessaires au syst\u00e8me # g\u00e9n\u00e9ration des locales du syst\u00e8me # g\u00e9n\u00e9ration du sources.list du syst\u00e8me # mise \u00e0 jour du cache apt # suppression des paquets inutiles # installation des paquets utiles # installation et configuration de docker # checkout du d\u00e9p\u00f4t gitlab \"sysadmin-tools\" # g\u00e9n\u00e9ration de la configuration du bashrc # g\u00e9n\u00e9ration de la configuration de l'\u00e9diteur vim # g\u00e9n\u00e9ration de la configuration de git # g\u00e9n\u00e9ration de la configuration du motd # g\u00e9n\u00e9ration de la configuration de fail2ban # red\u00e9marrage du serveur ssh pour charger la configuration # arr\u00eat du service fail2ban name: \"fail2ban\" # d\u00e9marrage du service fail2ban pour charger la nouvelle configuration name: \"fail2ban\" no_block: no register: fail2ban_return #failed_when: \"'dead' in fail2ban_return.status.substate\" - debug: var: fail2ban_return", "label": 1, "commit_name": "comments translation and check Fail2Ban service after service restart (to avoid errors if logs do not exist)"}
{"code": "##################################################################### # playbook used to bootstrap a debian server after an fresh install # ##################################################################### # the server group to be deployed is selected via the following cli parameter # enable debugger if necessary =) # strategy: debug # declaration of the playbook's tasks # creating the necessary groups for the system # creating the necessary users for the system # generation of system locals # generation of system sources.list # updating apt cache # removing the useless packages # installing useful packages # installation and configuration of docker service # checkout of gitlab \"sysadmin-tools\" repository # generation of bash configuration # generation of vim configuration # generation of git configuration # generation of motd configuration # generation of aliases configuration - include: tasks/generate_aliases.yml tags: - aliases # generation of fail2ban service configuration # installation of lamp environnement - include: tasks/install_lamp.yml tags: - lamp # installation and configuration of logwatch service - include: tasks/deploy_logwatch.yml tags: - logwatch # declaration of the playbook's handlers # reload of ssh service # stop fail2ban service name: \"fail2ban.service\" # start fail2ban service name: \"fail2ban.service\" daemon_reload: yes # see comments in tasks/deploy_fail2ban_configuration.yml # register: fail2ban_return # failed_when: \"'exited' in fail2ban_return.status.substate\" # check fail2ban service status - name: check fail2ban status command: systemctl show fail2ban.service register: result failed_when: \"'substate=exited' in result.stdout\"", "label": 0, "commit_name": "comments translation and check Fail2Ban service after service restart (to avoid errors if logs do not exist)"}
{"code": "- name: restart nginx", "label": 1, "commit_name": "* Fixed a bug that caused Nginx to be restarted twice in"}
{"code": "- name: restart nginx with updated vhost configuration", "label": 0, "commit_name": "* Fixed a bug that caused Nginx to be restarted twice in"}
{"code": "version: 0.8.5", "label": 1, "commit_name": "Fix for docker login "}
{"code": "version: 0.8.6", "label": 0, "commit_name": "Fix for docker login "}
{"code": "git: repo=https://github.com/elasticsearch/kibana.git dest=/var/www/kibana update=yes", "label": 1, "commit_name": "Adding looser/more logstash sources, and fixing a git error with older versions of ansible"}
{"code": "git: repo=https://github.com/elasticsearch/kibana.git dest=/var/www/kibana #update=yes - name: ensure kibana is secured with a password template: src=../files/kibana/kibana.htpasswd.j2 dest=/etc/nginx/conf.d/kibana.htpasswd mode=0755", "label": 0, "commit_name": "Adding looser/more logstash sources, and fixing a git error with older versions of ansible"}
{"code": "#atlassian_extras_old: atlassian-extras-2.2.2.jar #atlassian_universal_plugin_manager_plugin_old: atlassian-universal-plugin-manager-plugin-2.17.13.jar atlassian_universal_plugin_manager_plugin_jar: atlassian-universal-plugin-manager-plugin-2.17.13.jar atlassian_universal_plugin_manager_plugin_from: https://www.dropbox.com/s/k5msfay3sudeedv/atlassian-universal-plugin-manager-plugin-2.17.13.jar?dl=0 #atlassian_universal_plugin_manager_plugin_jar: atlassian-universal-plugin-manager-plugin-2.18.2.jar #atlassian_universal_plugin_manager_plugin_from: https://www.dropbox.com/s/5xiaib5qeyxearv/atlassian-universal-plugin-manager-plugin-2.18.2.jar?dl=0", "label": 1, "commit_name": "jira install error fixed"}
{"code": "# atlassian_extras_old must be defined # and equal to original file name when fresh_install atlassian_extras_old: atlassian-extras-2.2.2.jar # atlassian_universal_plugin_manager_plugin_old must be defined # and equal to original file name when fresh install atlassian_universal_plugin_manager_plugin_old: atlassian-universal-plugin-manager-plugin-2.18.2.jar #atlassian_universal_plugin_manager_plugin_jar: atlassian-universal-plugin-manager-plugin-2.17.13.jar #atlassian_universal_plugin_manager_plugin_from: https://www.dropbox.com/s/k5msfay3sudeedv/atlassian-universal-plugin-manager-plugin-2.17.13.jar?dl=0 # atlassian_universal_plugin_manager_plugin_jar: atlassian-universal-plugin-manager-plugin-2.18.2.jar # atlassian_universal_plugin_manager_plugin_from: https://www.dropbox.com/s/5xiaib5qeyxearv/atlassian-universal-plugin-manager-plugin-2.18.2.jar?dl=0", "label": 0, "commit_name": "jira install error fixed"}
{"code": "- name: restart slice name: system-kresd.slice", "label": 1, "commit_name": "fix: latest Raspbian and Ansible support"}
{"code": "- name: restart knot resolver name: \"kresd@{{ '%d' | format(item) }}.service\" loop: \"{{ range(1, 1 + knot_instances | default(1)) | list }}\"", "label": 0, "commit_name": "fix: latest Raspbian and Ansible support"}
{"code": "checksum: sha512:https://download.nextcloud.com/server/releases/latest.tar.bz2.sha512", "label": 1, "commit_name": "Fix yamllint errors"}
{"code": "checksum: > sha512:https://download.nextcloud.com/server/releases/latest.tar.bz2.sha512", "label": 0, "commit_name": "Fix yamllint errors"}
{"code": "# \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 postgresql 9.6 name: https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-6-x86_64/pgdg-centos96-9.6-3.noarch.rpm - set_repos ## \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u0444\u0430\u0439\u043b\u043e\u0432 \u0432 \u043a\u0430\u0442\u0430\u043b\u043e\u0433\u0435 postgresql - find: paths: \"/var/lib/pgsql/9.6/data/\" recurse: yes become: yes register: datadir ## \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c postgresql \u0435\u0441\u043b\u0438 \u043a\u0430\u0442\u0430\u043b\u043e\u0433 \u043f\u0443\u0441\u0442 - name: initialize postgresql become: yes command: /usr/pgsql-9.6/bin/postgresql96-setup initdb when: datadir.matched|int == 0 notify: - start postgresql tags: - postgresql - name: set password for \"postgres\" user become: yes become_user: postgres command: \"psql -u postgres -d postgres -c \\\"alter user postgres with password 'postgres'\\\"\" - set_passwords src: postgresql.conf.j2 src: pg_hba.conf.j2", "label": 1, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "# \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 postgresql 9.6 name: https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-6-x86_64/pgdg-centos96-9.6-3.noarch.rpm - pg_set_repos ## \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442 \u043b\u0438 \u0444\u0430\u0439\u043b \u043d\u0430\u0441\u0442\u0440\u043e\u0435\u043a - name: check postgresql initialized become: yes stat: path: \"/var/lib/pgsql/9.6/data/postgresql.conf\" register: pginit - pg_init - pg_set_passwords ## \u0435\u0441\u043b\u0438 \u043d\u0435\u0442 \u0444\u0430\u0439\u043b\u0430 \u043d\u0430\u0441\u0442\u0440\u043e\u0435\u043a - block: ## \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c postgresql - name: initialize postgresql become: yes command: /usr/pgsql-9.6/bin/postgresql96-setup initdb ## \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c postgresql \u0438 \u043f\u043e\u043c\u0435\u0449\u0430\u0435\u043c \u0435\u0433\u043e \u0432 \u0430\u0432\u0442\u043e\u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0443 - name: enable & start postgresql become: yes service: name: postgresql-9.6 state: started enabled: yes ## \u0437\u0430\u0434\u0430\u0435\u043c \u043f\u0430\u0440\u043e\u043b\u044c \u0434\u043b\u044f \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u043e\u0439 \u0440\u043e\u043b\u0438 postgresql - name: set password for \"postgres\" user become: yes become_user: \"{{ postgres.role }}\" command: \"psql -u postgres -d postgres -c \\\"alter user postgres with password '{{ postgres.password }}'\\\"\" tags: - pg_set_passwords when: not pginit.stat.exists - pg_init src: postgresql.conf.j2 src: pg_hba.conf.j2", "label": 0, "commit_name": "Fix PostgreSQL Playbook"}
{"code": "tags: nginx - name: populate /var/lib/acme by starting acmetool unit systemd: name: acmetool state: started", "label": 1, "commit_name": "Role nginx: fix idempotence on acmetool task (#49)"}
{"code": "notify: start acmetool", "label": 0, "commit_name": "Role nginx: fix idempotence on acmetool task (#49)"}
{"code": "name: \"{{ item }}\" with_items: \"{{ nautilus_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ nautilus_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: {{ item }} name: {{ item }}", "label": 1, "commit_name": "Fix syntax"}
{"code": "name: \"{{ item }}\" name: \"{{ item }}\"", "label": 0, "commit_name": "Fix syntax"}
{"code": "- name: whitelist ansible port ufw: rule: limit log: yes direction: in proto: tcp port: '{{ ansible_port }}' policy: reject policy: allow", "label": 1, "commit_name": "roles/ufw: fix-ups"}
{"code": "rule: reject rule: allow - name: whitelist ansible port ufw: rule: limit log: yes direction: in proto: tcp port: '{{ ansible_port }}' policy: deny", "label": 0, "commit_name": "roles/ufw: fix-ups"}
{"code": "name: \"{{ item.name }}\" when: item.url is not defined loop: \"{{ homebrew.taps }}\" - name: enable taps homebrew_tap: name: \"{{ item.name }}\" url: \"{{ item.url }}\" when: item.url is defined", "label": 1, "commit_name": "Use default filter to remove task duplication"}
{"code": "name: \"{{ item.name | default(item) }}\" url: \"{{ item.url | default(omit) }}\"", "label": 0, "commit_name": "Use default filter to remove task duplication"}
{"code": "- name: deploy mariadb and configure the databases", "label": 1, "commit_name": "fix some ansible-lint errors"}
{"code": "- name: deploy mariadb and configure the databases", "label": 0, "commit_name": "fix some ansible-lint errors"}
{"code": "failed_when: gitlab_restart_handler_failed_when | bool", "label": 1, "commit_name": "update code"}
{"code": "# failed_when: gitlab_restart_handler_failed_when | bool", "label": 0, "commit_name": "update code"}
{"code": "dest: \"~{{ ansible_ssh_user }}/nginx.yml\" owner: \"{{ ansible_ssh_user }}\" shell: kubectl apply -f nginx.yml become_user: \"{{ ansible_ssh_user }}\"", "label": 1, "commit_name": "Added smoke test, firewalld setup, heapster, encrypting secrets at rest"}
{"code": "dest: \"/tmp/nginx.yml\" shell: kubectl apply -f /tmp/nginx.yml", "label": 0, "commit_name": "Added smoke test, firewalld setup, heapster, encrypting secrets at rest"}
{"code": "- name: create instance of lab - name: create instance of devtest lab policy - name: create instance of devtest lab schedule - name: create instance of devtest labs virtual network description: my devtest lab - name: create instance of devtest labs artifacts source - name: create instance of dtl virtual machine - name: list all artifact sources - name: list arm template facts - name: get arm template facts - name: create instance of devtest lab environment - name: create instance of devtest lab image - name: delete instance of lab", "label": 1, "commit_name": "dlt playbook fixes (#71)"}
{"code": "- name: create the lab - name: set the lab policies - name: set the lab schedule - name: create the lab virtual network description: my lab virtual network - name: define the lab artifacts source - name: create a vm within the lab - name: list the artifact sources - name: list the artifact facts azure_rm_devtestlabartifact_facts: resource_group: \"{{ resource_group }}\" lab_name: \"{{ lab_name }}\" artifact_source_name: public repo register: output - debug: var: output - name: list the azure resource manager template facts - name: get azure resource manager template facts - name: create the lab environment - name: create the lab image - name: delete the lab", "label": 0, "commit_name": "dlt playbook fixes (#71)"}
{"code": "/com/gexperts/tilix/profiles/2b7c4080-0ddd-46c5-8f23-563fd3ba789d/visible-name: 'default'", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "/com/gexperts/tilix/profiles/2b7c4080-0ddd-46c5-8f23-563fd3ba789d/visible-name: 'default'", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "package bookworm: stage: package needs: [\"release bookworm amd64\", \"release bookworm arm64\"] variables: ci_manifest_file: manifest.yml extends: .kaniko_package", "label": 1, "commit_name": "Fix ci order"}
{"code": "package bookworm: stage: package needs: [\"release bookworm amd64\", \"release bookworm arm64\"] variables: ci_manifest_file: manifest.yml extends: .kaniko_package", "label": 0, "commit_name": "Fix ci order"}
{"code": "src: \"firefox.desktop\" mode: '0644' src: \"firefox-p.desktop\" mode: '0644'", "label": 1, "commit_name": "refactor: start lint"}
{"code": "src: firefox.desktop mode: \"0644\" src: firefox-p.desktop mode: \"0644\"", "label": 0, "commit_name": "refactor: start lint"}
{"code": "- \"jinja_lint\" jinja_lint: stage: lint image: $nexus_repos_docker_registry/$docker_image_jinja_lint before_script: # fix weird ansible bug: https://github.com/trailofbits/algo/issues/1637 # this probably happens due to gitlab-runner mounting the git repo into the container - \"chmod o-w .\" script: - \"[ -n \\\"$(find ./templates -name '*.j2')\\\" ] && j2lint ./templates/*.j2 --ignore s3 s7\" allow_failure: false rules: - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"'", "label": 1, "commit_name": "fix CI 1"}
{"code": "#- \"jinja_lint\" #jinja_lint: # stage: lint # image: $nexus_repos_docker_registry/$docker_image_jinja_lint # before_script: # # fix weird ansible bug: https://github.com/trailofbits/algo/issues/1637 # # this probably happens due to gitlab-runner mounting the git repo into the container # - \"chmod o-w .\" # script: # - \"[ -n \\\"$(find ./templates -name '*.j2')\\\" ] && j2lint ./templates/*.j2 --ignore s3 s7\" # allow_failure: false # rules: # - if: '$ci_commit_message=~/^[^merge]/ && $ci_commit_branch == \"develop\"'", "label": 0, "commit_name": "fix CI 1"}
{"code": "become: false become: false", "label": 1, "commit_name": "MOD very minor fixes, ADD tree to installed packages"}
{"code": "- tree become: false become: false", "label": 0, "commit_name": "MOD very minor fixes, ADD tree to installed packages"}
{"code": "name: proxmox_lxc name: lxc name: prereq name: download name: raspberrypi name: k3s/master name: k3s/node name: k3s/post", "label": 1, "commit_name": "fix playbook"}
{"code": "name: enmanuelmoreira.k3s.proxmox_lxc name: enmanuelmoreira.k3s.lxc name: enmanuelmoreira.k3s.prereq name: enmanuelmoreira.k3s.download name: enmanuelmoreira.k3s.raspberrypi name: enmanuelmoreira.k3s.k3s/master name: enmanuelmoreira.k3s.k3s/node name: enmanuelmoreira.k3s.k3s/post", "label": 0, "commit_name": "fix playbook"}
{"code": "push: - name: add the private key to the ssh-agent if: | matrix.os == 'debian-11' || matrix.os == 'ubuntu-22.04' || matrix.os == 'ubuntu-20.04' if: | matrix.os == 'debian-11' || matrix.os == 'ubuntu-22.04' || matrix.os == 'ubuntu-20.04' - name: log into the server expect -c \"spawn ssh $easyvpn_username@$server_ipv4 -i ~/.ssh/id_vpn; expect \\\"*enter passphrase for key*\\\"; send -- \\\"$easyvpn_password\\r\\\"\" - name: execute the script again to check idempotency sshpass -p$easyvpn_password ssh -t -t $easyvpn_username@$server_ipv4 \"export letsencrypt_staging=$letsencrypt_staging && ansible-easy-vpn/testing/expect/idempotency.exp --password $easyvpn_password\" test: run: python testing/selenium/acceptance.py --username $easyvpn_username --password $easyvpn_password --base_url $domain - test", "label": 1, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "push: - name: add the host key to known hosts env: git_ssl_no_verify: \"true\" - name: initialize the ssh-agent uses: webfactory/ssh-agent@v0.4.1 with: ssh-private-key: ${{ secrets.ssh_private_key }} - name: regsiter the private key with the ssh-agent run: expect -c \"spawn ssh-add $home/.ssh/id_vpn; expect -re \\\"enter passphrase.*\\\"; send -- \\\"$easyvpn_password\\r\\\"; expect -re \\\"identity added.*\\\"\" - name: reboot the server run: | ssh -t -t $easyvpn_username@$server_ipv4 \"sudo reboot\" || true - name: wait for the server to reboot sleep 60s - name: copy the private key to the github root run: cp $home/.ssh/id_vpn id_vpn - name: log into the server and execute the script again for idempotency ssh -t -t $easyvpn_username@$server_ipv4 \"export letsencrypt_staging=$letsencrypt_staging; ansible-easy-vpn/testing/expect/idempotency.exp --password $easyvpn_password\" - name: archive the private ssh key (matrix 1) if: ${{ matrix.index == '1' }} uses: actions/upload-artifact@v3 with: name: \"private-ssh-key-1\" path: \"id_vpn\" - name: archive the private ssh key (matrix 2) if: ${{ matrix.index == '2' }} uses: actions/upload-artifact@v3 with: name: \"private-ssh-key-2\" path: \"id_vpn\" - name: archive the private ssh key (matrix 3) if: ${{ matrix.index == '3' }} uses: actions/upload-artifact@v3 with: name: \"private-ssh-key-3\" path: \"id_vpn\" fetch_config: - name: install expect run: >- sudo apt install expect - name: create the .ssh folder run: >- mkdir /home/runner/.ssh - name: get the private ssh key artifact (matrix 1) if: matrix.index == '1' uses: actions/download-artifact@v3 with: name: \"private-ssh-key-1\" path: /home/runner/.ssh - name: get the private ssh key artifact (matrix 2) if: matrix.index == '2' uses: actions/download-artifact@v3 with: name: \"private-ssh-key-2\" path: /home/runner/.ssh - name: get the private ssh key artifact (matrix 3) if: matrix.index == '3' uses: actions/download-artifact@v3 with: name: \"private-ssh-key-3\" path: /home/runner/.ssh - name: set the correct permissions for the ssh key run: | chmod 700 $home/.ssh chmod 600 $home/.ssh/* - name: initialize the ssh-agent uses: webfactory/ssh-agent@v0.4.1 with: ssh-private-key: ${{ secrets.ssh_private_key }} - name: regsiter the private key with the ssh-agent run: expect -c \"spawn ssh-add $home/.ssh/id_vpn; expect -re \\\"enter passphrase.*\\\"; send -- \\\"$easyvpn_password\\r\\\"; expect -re \\\"identity added.*\\\"\" env: easyvpn_password: \"${{ needs.build.outputs[format('easyvpn_password_{0}', matrix.index)] }}\" - name: create the config dir run: mkdir /home/runner/wireguard run: python testing/selenium/acceptance.py --username $easyvpn_username --password $easyvpn_password --base_url $domain --ssh_agent $ssh_auth_sock - fetch_config", "label": 0, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "# - name: copy gitlab configuration file. # template: # src: \"gitlab.rb.j2\" # dest: /etc/gitlab/gitlab.rb # owner: root # group: root # mode: 0600 # notify: restart gitlab", "label": 1, "commit_name": "update code"}
{"code": "- name: copy gitlab configuration file. template: src: \"gitlab.rb.j2\" dest: /etc/gitlab/gitlab.rb owner: root group: root mode: 0600 notify: restart gitlab", "label": 0, "commit_name": "update code"}
{"code": "kibana_full_version: 4.0.1", "label": 1, "commit_name": "refactor: updating readme and default file"}
{"code": "kibana_full_version: 4.1.1", "label": 0, "commit_name": "refactor: updating readme and default file"}
{"code": "inv_install_nexus_repository__container_name: \"{{ inv_install_nexus_repository__container_name }}\" inv_install_nexus_repository__data_path: \"{{ inv_install_nexus_repository__data_path }}\" inv_install_nexus_repository__heap: \"{{ inv_install_nexus_repository__heap }}\" inv_install_nexus_repository__web_address: \"{{ inv_install_nexus_repository__web_address }}\" inv_install_nexus_repository__web_port: \"{{ inv_install_nexus_repository__web_port }}\" inv_install_nexus_repository__web_port_min: \"{{ inv_install_nexus_repository__web_port_min }}\" inv_install_nexus_repository__web_port_max: \"{{ inv_install_nexus_repository__web_port_max }}\"", "label": 1, "commit_name": "fix CI"}
{"code": "install_nexus_repository__container_name: \"{{ inv_install_nexus_repository__container_name }}\" install_nexus_repository__data_path: \"{{ inv_install_nexus_repository__data_path }}\" install_nexus_repository__heap: \"{{ inv_install_nexus_repository__heap }}\" install_nexus_repository__web_address: \"{{ inv_install_nexus_repository__web_address }}\" install_nexus_repository__web_port: \"{{ inv_install_nexus_repository__web_port }}\" install_nexus_repository__web_port_min: \"{{ inv_install_nexus_repository__web_port_min }}\" install_nexus_repository__web_port_max: \"{{ inv_install_nexus_repository__web_port_max }}\"", "label": 0, "commit_name": "fix CI"}
{"code": "calibre_container_image: '{{ calibre_container_repo }}{{ \":\" + calibre_container_tag }}'", "label": 1, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "calibre_container_image: 'linuxserver/calibre-web:{{ calibre_container_tag }}'", "label": 0, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "- \"buster\" - \"bullseye\"", "label": 1, "commit_name": "fix and refacto"}
{"code": "- \"all\" - name: \"ubuntu\" versions: - \"all\"", "label": 0, "commit_name": "fix and refacto"}
{"code": "name: {{ item }} loop: \"{{ local-users }}\" shell: /usr/bin/openssl rand -base64 32 | passwd --stdin {{ item }} loop: \"{{ local-users }}\"", "label": 1, "commit_name": "fix local user playbook loop"}
{"code": "name: \"{{ item }}\" loop: - dev - guest shell: /usr/bin/openssl rand -base64 32 | passwd --stdin \"{{ item }}\" loop: - dev - guest", "label": 0, "commit_name": "fix local user playbook loop"}
{"code": "command: iptables-restore < /etc/network/iptables", "label": 1, "commit_name": "Some iptables bugs were fixed"}
{"code": "# command: iptables-restore -! < /etc/network/iptables shell: iptables-restore < /etc/network/iptables #- name: restart iptables # service: name=iptables state=restarted", "label": 0, "commit_name": "Some iptables bugs were fixed"}
{"code": "# this lower cap is to address django openstack auth issues found here: # https://bugs.launchpad.net/openstack-ansible/+bug/1497679 # if the horizon requirements change to a later version, this may be removed. - \"django-openstack-auth>=2.0.1\"", "label": 1, "commit_name": "Merge \"Remove Horizon django-openstack-auth lower pin\""}
{"code": "- django-openstack-auth", "label": 0, "commit_name": "Merge \"Remove Horizon django-openstack-auth lower pin\""}
{"code": "when: ocserv_cert_auto when: not ocserv_cert_auto", "label": 1, "commit_name": "lets encrypt with ocserv"}
{"code": "when: ocserv_cert_source == \"gen\" when: ocserv_cert_source == \"upload\"", "label": 0, "commit_name": "lets encrypt with ocserv"}
{"code": "- name: create partitions for vdb device: /dev/vdb - name: create partitions for vdc parted: device: /dev/vdc number: 1 state: present - name: format vdb dev: /dev/vdb - name: format vdc filesystem: fstype: ext4 dev: /dev/vdc - name: mount vdb to /data1 src: /dev/vdb path: /data1 state: mounted - name: mount vdc to /data2 mount: fstype: ext4 src: /dev/vdc path: /data2 src: /opt/zookeeper-3.4.12 path: /data1/zookeeper - name: create zookeeper log directory file: path: /var/log/zookeeper state: directory owner: zookeeper group: zookeeper mode: 0755 - name: copy zookeeper config files synchronize: src: /home/training/kafka-ansible/single-playbook/files/opt/zookeeper/conf dest: /opt/zookeeper - name: change permissions on zookeeper config files file: path: /opt/zookeeper/conf recurse: yes owner: zookeeper group: zookeeper - name: create directory for kafka data with owner as kafka file: path: /data1/kafka-logs owner: kafka group: kafka state: directory - name: create directory for kafka data with owner as kafka file: path: /data2/kafka-logs owner: kafka group: kafka state: directory - name: create kafka log directory path: /var/log/kafka state: directory owner: kafka group: kafka mode: 0755 - name: copy server.properties synchronize: src: /home/training/kafka-ansible/single-playbook/files/opt/kafka/config dest: /opt/kafka - name: change permissions on kafka config files file: path: /opt/kafka/config recurse: yes owner: kafka group: kafka # setup kafka client node - hosts: gateways tasks: - name: add user kafka user: name: kafka - name: download kafka tar unarchive: src: http://www-us.apache.org/dist/kafka/2.0.0/kafka_2.11-2.0.0.tgz dest: /opt remote_src: yes - name: create softlink for kafka base dir file: src: /opt/kafka_2.11-2.0.0 path: /opt/kafka state: link owner: kafka group: kafka", "label": 1, "commit_name": "updated kafka.yml with loops"}
{"code": "- name: create partitions for vdb and vdc device: \"{{ item }}\" loop: - /dev/vdb - /dev/vdc - name: format vdb and vdc dev: \"{{ item }}\" loop: - /dev/vdb - /dev/vdc - name: mount vdb to /data1 and vdc to /data2 src: \"{{ item.dev }}\" path: \"{{ item.path }}\" loop: - { dev: '/dev/vdb', path: '/data1' } - { dev: '/dev/vdc', path: '/data2' } src: /opt/zookeeper-3.4.12 path: \"{{ item }}\" loop: - /data1/zookeeper - /var/log/zookeeper - name: create directories for kafka data with owner as kafka path: \"{{ item }}\" state: directory loop: - /data1/kafka-logs - /data2/kafka-logs", "label": 0, "commit_name": "updated kafka.yml with loops"}
{"code": "- zsh-completions # zsh completions - grml-zsh-config # zsh config used in archiso", "label": 1, "commit_name": "fix errors; finish zsh customization"}
{"code": "- zsh-completions # zsh command completions - zsh-autosuggestions # finish commands from history - zsh-history-substring-search # autosearch via history - grml-zsh-config # zsh config used in archiso (liveboot iso)", "label": 0, "commit_name": "fix errors; finish zsh customization"}
{"code": "hostname: \"{{ item.natip }}\" - \"{{ gce_pgbouncer_primary.networkinterfaces[0].accessconfigs[0] }}\" hostname: \"{{ item.networkip }}\" - \"{{ gce_pgbouncer_primary.networkinterfaces[0] }}\" - \"{{ gce_pgbouncer_primary }}\"", "label": 1, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "hostname: \"{{ item.networkinterfaces[0].accessconfigs[0].natip }}\" - \"{{ gce_pgbouncer_primary }}\" hostname: \"{{ item.networkinterfaces[0].networkip }}\" - \"{{ gce_pgbouncer_primary }}\" - \"{{ gce_pgbouncer_primary }}\"", "label": 0, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "- dns: forms.worobetz.ca git_repo: /cworobetz/tommyguns-forms.git", "label": 1, "commit_name": "Fix merge conflict"}
{"code": "- dns: splash.worobetz.ca git_repo: /cworobetz/tommyguns-splash.git", "label": 0, "commit_name": "Fix merge conflict"}
{"code": "- name: read-write rpm-meta git checkout from gitlab", "label": 1, "commit_name": "Update yocto.yaml  minor typo"}
{"code": "- name: read-write meta-rpm git checkout from gitlab", "label": 0, "commit_name": "Update yocto.yaml  minor typo"}
{"code": "shell: \"ps -few | grep gunicorn | awk '{print $2}'\"", "label": 1, "commit_name": "Fix processing killing"}
{"code": "shell: \"ps -few | grep server:app | awk '{print $2}'\"", "label": 0, "commit_name": "Fix processing killing"}
{"code": "- printer-manager", "label": 1, "commit_name": "typo"}
{"code": "- print-manager", "label": 0, "commit_name": "typo"}
{"code": "become: true with_items: '{{ satnogs_radio_blacklist_modules }}'", "label": 1, "commit_name": "satnogs-radio: Fix module unloading error after kenel update"}
{"code": "ignore_errors: true - name: check if list of kernel builtin modules exists stat: path: '/lib/modules/{{ ansible_kernel }}/modules.builtin' register: modules_builtin become: true with_items: '{{ satnogs_radio_blacklist_modules }}' when: modules_builtin.stat.exists", "label": 0, "commit_name": "satnogs-radio: Fix module unloading error after kenel update"}
{"code": "- name: shell: - name: change default gateway address in redhat - name: restart networking service - name: check ip configuration - name: shell: - name: change default gateway address debian - name: restart networking service - name: check ip configuration", "label": 1, "commit_name": "Add install net-tools"}
{"code": "- name: install net-tools for redhat yum: name=net-tools state=latest - name: change default gateway address in redhat - name: restart networking service - name: check ip configuration - name: install nano for debian apt: name=net-tools state=latest - name: change default gateway address debian - name: restart networking service - name: check ip configuration", "label": 0, "commit_name": "Add install net-tools"}
{"code": "tags: - skip_ansible_lint", "label": 1, "commit_name": "Fix linting issue for universe repo add"}
{"code": "register: add_repo_result changed_when: \"'distribution component enabled for all sources' in add_repo_result.stdout\" until: add_repo_result.rc == 0 retries: 3 delay: 1", "label": 0, "commit_name": "Fix linting issue for universe repo add"}
{"code": "# ignore directed pings - { name: 'net.ipv4.icmp_echo_ignore_all', value: '1' }", "label": 1, "commit_name": "Minor fixes regarding to public servers."}
{"code": "# commented out since pings are blocked by iptables. # # ignore directed pings # - { name: 'net.ipv4.icmp_echo_ignore_all', value: '1' }", "label": 0, "commit_name": "Minor fixes regarding to public servers."}
{"code": "when: usernscopy.changed when: ansible_distribution == \"debian\"", "label": 1, "commit_name": "docker: fix duplicate when on task"}
{"code": "when: ansible_distribution == \"debian\" and usernscopy.changed", "label": 0, "commit_name": "docker: fix duplicate when on task"}
{"code": "lidarr_api_key: '{{ lookup(\"ansible.builtin.password\", \"/tmp/passwordfile chars=hexdigits length=32 seed=ansible_hostname\") }}'", "label": 1, "commit_name": "fix: change apikey output to /dev/null"}
{"code": "lidarr_api_key: '{{ lookup(\"ansible.builtin.password\", \"/dev/null chars=hexdigits length=32 seed=ansible_hostname\") }}'", "label": 0, "commit_name": "fix: change apikey output to /dev/null"}
{"code": "name: 'python-psycopg2'", "label": 1, "commit_name": "postgresql: Fix installation of 'psycopg2' on RHEL based distros > 7"}
{"code": "name: 'python{{ (ansible_distribution_major_version > \"7\") | ternary(\"3\", \"\") }}-psycopg2'", "label": 0, "commit_name": "postgresql: Fix installation of 'psycopg2' on RHEL based distros > 7"}
{"code": "name: [emacs, mg, terraform, ansible, ansible-lint, docker, aws-cli, doctl, git, git-email, gcc, make, automake, autoconf, luarocks, readline, lua5.1, lua5.2, lua5.3, fennel, sbcl, bash, lua5.1-dev, lua5.2-dev, lua5.3-dev, libc-dev, linux-headers]", "label": 1, "commit_name": "Add a slew of additional packages that were missed after provisioning my l203ma"}
{"code": "name: [emacs, mg, terraform, ansible, ansible-lint, docker, aws-cli, doctl, git, git-email, gcc, make, automake, autoconf, luarocks, readline, lua5.1, lua5.2, lua5.3, fennel, sbcl, bash, lua5.1-dev, lua5.2-dev, lua5.3-dev, libc-dev, linux-headers, jamet, abuild, atools]", "label": 0, "commit_name": "Add a slew of additional packages that were missed after provisioning my l203ma"}
{"code": "{ 'install_k3s_skip_enable': 'true', 'install_k3s_version': k3s_version } | combine(k3s.environment | default({}))", "label": 1, "commit_name": "ansible-lint: Fix some errors"}
{"code": "{'install_k3s_skip_enable': 'true', 'install_k3s_version': k3s_version} | combine(k3s.environment | default({})) changed_when: true", "label": 0, "commit_name": "ansible-lint: Fix some errors"}
{"code": "- docker build -t debian9-ansible . - docker run --name test-container -d --privileged -v /sys/fs/cgroup:/sys/fs/cgroup:ro debian9-ansible /lib/systemd/systemd", "label": 1, "commit_name": "Add Travis CI test integration fix."}
{"code": "- docker build -t docker-ansible . - docker run --name test-container -d --privileged -v /sys/fs/cgroup:/sys/fs/cgroup:ro docker-ansible /lib/systemd/systemd", "label": 0, "commit_name": "Add Travis CI test integration fix."}
{"code": "regolith_i3xrocks_modules_default: '{{ regolith_i3xrocks_modules_default + regolith_i3xrocks_modules_extra }}'", "label": 1, "commit_name": "Fix regolith-desktop role"}
{"code": "regolith_i3xrocks_modules: '{{ regolith_i3xrocks_modules_default + regolith_i3xrocks_modules_extra }}'", "label": 0, "commit_name": "Fix regolith-desktop role"}
{"code": "register: redis_result until: redis_result is succeeded", "label": 1, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "register: authelia_redis_result until: authelia_redis_result is succeeded healthcheck: test: [\"cmd\", \"redis-cli\", \"ping\"] start_period: 5s healthcheck: test: [\"cmd\", \"curl\", \"-f\", \"http://localhost:9091\"] start_period: 10s", "label": 0, "commit_name": "Fix the Docker firewall behavior, fix running on non-root systems e.g. AWS EC2, improve testing to include post-reboot states (#205)"}
{"code": "inv_install_mariadb__galera_cluster_seed_host: \"molecule-local-instance-1-deploy-phpmyadmin\"", "label": 1, "commit_name": "fix galera"}
{"code": "#inv_install_mariadb__galera_cluster_seed_host: \"molecule-local-instance-1-deploy-phpmyadmin\"", "label": 0, "commit_name": "fix galera"}
{"code": "- shell: ' echo $(htpasswd -nb admin {{ enter_password }}) | sed -e s/enterpasswordpls/\\\\$/g ./ansible/roles/traefik/files/docker-compose.yml ' - shell: ' sed -i \"s/enter_domain/{{ enter_domain }}/g\" ./ansible/roles/traefik/files/docker-compose.yml ' - shell: ' sed -i \"s/enter_email/{{ enter_email }}/g\" ./ansible/roles/traefik/files/data/traefik.yml ' - shell: ' sed -i \"s/$/$$/g\" ./ansible/roles/traefik/files/docker-compose.yml '", "label": 1, "commit_name": "Add treafik2.2 bugs fixes 4"}
{"code": "- shell: ' echo $(htpasswd -nb admin {{ enter_password }}) | sed -e s/enterpasswordpls/\\\\$/g ./roles/traefik/files/docker-compose.yml ' - shell: ' sed -i \"s/enter_domain/{{ enter_domain }}/g\" ./roles/traefik/files/docker-compose.yml ' - shell: ' sed -i \"s/enter_email/{{ enter_email }}/g\" ./roles/traefik/files/data/traefik.yml ' - shell: ' sed -i \"s/$/$$/g\" ./roles/traefik/files/docker-compose.yml '", "label": 0, "commit_name": "Add treafik2.2 bugs fixes 4"}
{"code": "- hosts: all - python3", "label": 1, "commit_name": "Refine inventory and variable override per host."}
{"code": "- hosts: managed - python", "label": 0, "commit_name": "Refine inventory and variable override per host."}
{"code": "line: export ps1=\"\\$ps1_ext\\n\\[\\033[38;5;4m\\][\\t]\\[$(tput sgr0)\\]\\[\\033[38;5;15m\\] \\[$(tput sgr0)\\]\\[\\033[38;5;2m\\]\\u\\[$(tput sgr0)\\]\\[\\033[38;5;1m\\]@\\h\\[$(tput sgr0)\\]\\[\\033[38;5;15m\\]\\[$(tput sgr0)\\]\\[\\033[38;5;5m\\]\\w\\[$(tput sgr0)\\]\\[\\033[38;5;15m\\]\\n\\[$(tput sgr0)\\]\\[\\033[38;5;4m\\]>\\[$(tput sgr0)\\]\\[\\033[38;5;15m\\] \\[$(tput sgr0)\\]\"", "label": 1, "commit_name": "fix: fix permission-related issues with some roles"}
{"code": "line: export ps1=\"\\$ps1_ext\\n\\[\\033[38;5;4m\\][\\t]\\[$(tput sgr0)\\]\\[\\033[38;5;15m\\] \\[$(tput sgr0)\\]\\[\\033[38;5;2m\\]\\u\\[$(tput sgr0)\\]\\[\\033[38;5;1m\\]@\\h\\[$(tput sgr0)\\]\\[\\033[38;5;15m\\]\\[$(tput sgr0)\\] \\[\\033[38;5;5m\\]\\w\\[$(tput sgr0)\\]\\[\\033[38;5;15m\\]\\n\\[$(tput sgr0)\\]\\[\\033[38;5;4m\\]>\\[$(tput sgr0)\\]\\[\\033[38;5;15m\\] \\[$(tput sgr0)\\]\"", "label": 0, "commit_name": "fix: fix permission-related issues with some roles"}
{"code": "shell: \"curl -l https://get.oh-my.fish | fish\" always_run: yes always_run: yes", "label": 1, "commit_name": "attempting some fixes"}
{"code": "shell: \"{{ item }}\" with_items: - cd ~/desktop - curl -l https://get.oh-my.fish > install - fish install --path=~/.local/share/omf --config=~/.config/omf # always_run: yes check_mode: no # always_run: yes check_mode: no", "label": 0, "commit_name": "attempting some fixes"}
{"code": "when: controller_ah_enable | bool when: controller_eda_enable | bool", "label": 1, "commit_name": "Merge branch 'fix-preflight' into 'main'"}
{"code": "when: controller_ah_enable | default('false') | bool when: controller_eda_enable | default('false') | bool", "label": 0, "commit_name": "Merge branch 'fix-preflight' into 'main'"}
{"code": "when: not datadog_skip_install when: not datadog_skip_install", "label": 1, "commit_name": "Enable turning off the Agent 6.14 fix for Windows (#399)"}
{"code": "when: not datadog_skip_install and datadog_apply_windows_614_fix when: not datadog_skip_install and datadog_apply_windows_614_fix", "label": 0, "commit_name": "Enable turning off the Agent 6.14 fix for Windows (#399)"}
{"code": "src: ~/fiji.app/imagej.desktop dest: ~/bureau/imagej.desktop", "label": 1, "commit_name": "Fix typo in imagej desktop launcher"}
{"code": "src: ~/fiji.app/imagej2.desktop dest: ~/bureau/imagej2.desktop", "label": 0, "commit_name": "Fix typo in imagej desktop launcher"}
{"code": "path: \"{{ input_bootstrap_role_base_path }}/{{ input_bootstrap_role_meta_namespace }}.{{ input_bootstrap_role_meta_role_name }}\"", "label": 1, "commit_name": "fix CI 2"}
{"code": "path: \"{{ input_bootstrap_role__base_path }}/{{ input_bootstrap_role__meta_namespace }}.{{ input_bootstrap_role__meta_role_name }}\"", "label": 0, "commit_name": "fix CI 2"}
{"code": "- name: freeipa.ansible_freeipa version: 0.1.11", "label": 1, "commit_name": "problem was not fixed by using older versions"}
{"code": "- freeipa.ansible_freeipa", "label": 0, "commit_name": "problem was not fixed by using older versions"}
{"code": "bazarr_container_image: '{{ bazarr_container_repo }}{{ \":\" + bazarr_container_tag }}'", "label": 1, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "bazarr_container_image: 'linuxserver/bazarr:{{ bazarr_container_tag }}'", "label": 0, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "fetch: src=/tmp/raspbian-ua-netinst/raspbian-ua-netinst.zip dest=/tmp/raspbian-ua-netinst.zip command: /usr/bin/rm -rf /tmp/raspbian-ua-netinst", "label": 1, "commit_name": "build: fix and make it work"}
{"code": "fetch: src=/tmp/raspbian-ua-netinst/raspbian-ua-netinst.zip dest=/tmp/raspbian-ua-netinst.zip flat=yes command: /bin/rm -rf /tmp/raspbian-ua-netinst", "label": 0, "commit_name": "build: fix and make it work"}
{"code": "- https://raw.github.com/georchestra/georchestra/master/postgresql/02-mapfishapp.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/04-console.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/06-ogc-server-statistics.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/07-atlas.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/08-geofence.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/09-extractor-app.sql", "label": 1, "commit_name": "update sql scripts urls after georchestra/georchestra@4af06f6b5b (fixes #61)"}
{"code": "- https://raw.github.com/georchestra/georchestra/master/postgresql/020-mapfishapp.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/040-console.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/060-ogc-server-statistics.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/070-atlas.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/080-geofence.sql - https://raw.github.com/georchestra/georchestra/master/postgresql/090-extractor-app.sql", "label": 0, "commit_name": "update sql scripts urls after georchestra/georchestra@4af06f6b5b (fixes #61)"}
{"code": "yum: service: enabled: yes template: service: enabled: yes selinux:", "label": 1, "commit_name": "Merge branch 'fix-ansible-lint' into 'main'"}
{"code": "ansible.builtin.yum: ansible.builtin.service: enabled: true ansible.builtin.template: ansible.builtin.service: enabled: true ansible.posix.selinux:", "label": 0, "commit_name": "Merge branch 'fix-ansible-lint' into 'main'"}
{"code": "when: ansible_devices[item] is defined and {{ data_disks_filesystem }}", "label": 1, "commit_name": "Fix for the filesystem check."}
{"code": "when: ansible_devices[item] is defined and (data_disks_filesystem == \"ext4\" or data_disks_filesystem == \"ext3\")", "label": 0, "commit_name": "Fix for the filesystem check."}
{"code": "variables: image_commit: $ci_registry_image/commit:$ci_commit_sha ref: v0.6.0 - project: jeff_cook/policy ref: v0.6.0 file: /docker_build/.gitlab-ci.yml sonarscanner:", "label": 1, "commit_name": "refactor: update pipeline"}
{"code": "ref: v0.6.1 sonarscanner:", "label": 0, "commit_name": "refactor: update pipeline"}
{"code": "namespace: \"playbook\"", "label": 1, "commit_name": "fix meta"}
{"code": "namespace: \"tool\"", "label": 0, "commit_name": "fix meta"}
{"code": "src: \"{{ item + .j2 }}\"", "label": 1, "commit_name": "Fix missing single quotes/syntax error."}
{"code": "src: \"{{ item + '.j2' }}\"", "label": 0, "commit_name": "Fix missing single quotes/syntax error."}
{"code": "hosts: localhost", "label": 1, "commit_name": "Updated to remove bloat in vars.yml, and hanlde loops better"}
{"code": "connection: local gather_subset: - env hosts: localhost", "label": 0, "commit_name": "Updated to remove bloat in vars.yml, and hanlde loops better"}
{"code": "shell: \"curl -fssl https://raw.githubusercontent.com/matchbooklab/local-persist/master/scripts/install.sh\"", "label": 1, "commit_name": "fix local-persist plugin install"}
{"code": "shell: \"curl -fssl https://raw.githubusercontent.com/matchbooklab/local-persist/master/scripts/install.sh | sudo bash\"", "label": 0, "commit_name": "fix local-persist plugin install"}
{"code": "mode: 0777 dest: /etc/opt/remi/php70/php.ini", "label": 1, "commit_name": "Fix rights php configurations files"}
{"code": "mode: 0644 mode: 0644 dest: /etc/opt/remi/php70/php.ini mode: 0644", "label": 0, "commit_name": "Fix rights php configurations files"}
{"code": "name: host_to_backup", "label": 1, "commit_name": "[FIX] wrong service name and log management"}
{"code": "name: simple_backup_test", "label": 0, "commit_name": "[FIX] wrong service name and log management"}
{"code": "file: path: \"{{ ansible_env.home }}/{{item}}\" unarchive: template:", "label": 1, "commit_name": "refactor: lint"}
{"code": "ansible.builtin.file: path: \"{{ ansible_env.home }}/{{ item }}\" mode: \"0755\" ansible.builtin.unarchive: mode: \"0755\" ansible.builtin.template: mode: \"0755\"", "label": 0, "commit_name": "refactor: lint"}
{"code": "pb_version: 0.4 - pandevice when: sw_version == desired_version", "label": 1, "commit_name": "fixes for #1 and #3"}
{"code": "pb_version: 0.6 - pan-os-python when: (sw_version == desired_version) and (force_update_content != 'yes') - name: perform final commit include_tasks: tasks/perform_commit.yml", "label": 0, "commit_name": "fixes for #1 and #3"}
{"code": "mode=600", "label": 1, "commit_name": "fix ansible lint ANSIBLE0009"}
{"code": "mode=0600", "label": 0, "commit_name": "fix ansible lint ANSIBLE0009"}
{"code": "#- include: greenhopper.yml #- include: portfolio.yml", "label": 1, "commit_name": "jira install error fixed"}
{"code": "tags: patching tags: patching - include: greenhopper.yml tags: addons - include: portfolio.yml tags: addons", "label": 0, "commit_name": "jira install error fixed"}
{"code": "when: '\"kubeadm\" in ansible_facts.packages' - kubeadm{{ \"=\" + k8s_version + \"-00\" if (k8s_version != \"latest\") }}", "label": 1, "commit_name": "fix: kube upgrade setup"}
{"code": "- name: assert that cluster was installed with kubeadm ansible.builtin.assert: that: - '\"kubeadm\" in ansible_facts.packages' fail_msg: \"cluster not installed with kubeadm\" tags: [k8s, k8s-upgrade, k8s-upgrade-cp] - kubeadm{{ \"=\" + k8s_version + \"*\" if (k8s_version != \"latest\") }} pause: 5", "label": 0, "commit_name": "fix: kube upgrade setup"}
{"code": "- name: crate zfs snapshot of the above file system", "label": 1, "commit_name": "minor typo correction in zfs.yml"}
{"code": "- name: create zfs snapshot of the above file system", "label": 0, "commit_name": "minor typo correction in zfs.yml"}
{"code": "--- - name: copy application war file to host copy: src=jboss-helloworld.war dest=/tmp - name: deploy helloworld to jboss jboss: deploy_path=/usr/share/jboss-as/standalone/deployments/ src=/tmp/jboss-helloworld.war deployment=helloworld.war state=present - name: copy application war file to host copy: src=ticket-monster.war dest=/tmp - name: deploy ticket monster to jboss jboss: deploy_path=/usr/share/jboss-as/standalone/deployments/ src=/tmp/ticket-monster.war deployment=ticket-monster.war state=present", "label": 1, "commit_name": "Fix ansible-lint reported issues in:"}
{"code": "--- - name: copy application war file to host copy: src=jboss-helloworld.war dest=/tmp - name: deploy helloworld to jboss jboss: deploy_path=/usr/share/jboss-as/standalone/deployments/ src=/tmp/jboss-helloworld.war deployment=helloworld.war state=present - name: copy application war file to host copy: src=ticket-monster.war dest=/tmp - name: deploy ticket monster to jboss jboss: deploy_path=/usr/share/jboss-as/standalone/deployments/ src=/tmp/ticket-monster.war deployment=ticket-monster.war state=present", "label": 0, "commit_name": "Fix ansible-lint reported issues in:"}
{"code": "when: ansible_os_family == \"redhat\" and ansible_distribution_major_version >= 7", "label": 1, "commit_name": "bug fix"}
{"code": "when: ansible_os_family == \"redhat\" and {{ ansible_distribution_major_version }} >= 7", "label": 0, "commit_name": "bug fix"}
{"code": "tags: tags: tags: tags: tags: tags:", "label": 1, "commit_name": "mothball attacks"}
{"code": "tags: tags: tags: tags: tags: tags:", "label": 0, "commit_name": "mothball attacks"}
{"code": "tags: - gnupg tags: - gnupog tags: - gnupg tags: - gnupg", "label": 1, "commit_name": "mothball attacks"}
{"code": "", "label": 0, "commit_name": "mothball attacks"}
{"code": "- curl -fssl https://raw.githubusercontent.com/homebrew/install/master/uninstall - chmod +x uninstall - yes '' | ./uninstall - rm -f uninstall", "label": 1, "commit_name": "Issue #61: Better uninstall steps."}
{"code": "- curl -slo https://raw.githubusercontent.com/homebrew/install/master/uninstall - chmod +x ./uninstall - ./uninstall --force", "label": 0, "commit_name": "Issue #61: Better uninstall steps."}
{"code": "repo: 'deb [arch=amd64] https://download.docker.com/linux/{{ ansible_distribution | lower }} {{ ansible_distribution_release }} main'", "label": 1, "commit_name": "Trying fixing repository issue"}
{"code": "repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} main state: present", "label": 0, "commit_name": "Trying fixing repository issue"}
{"code": "gem: name: \"{{ item }}\" - name: install passenger gem: name: passenger version: \"{{ passenger_ver }}\" user_install: no command: passenger-install-nginx-module --auto", "label": 1, "commit_name": "fix paths for rbenv"}
{"code": "command: \"{{ ruby_bin_root }}/gem install --no-document {{ item }}\" - passenger become: yes command: \"{{ ruby_bin_root }}/passenger-install-nginx-module --auto\" become: yes become: yes become: yes", "label": 0, "commit_name": "fix paths for rbenv"}
{"code": "ceilometer_service_user_name: ceilometer ceilometer_service_tenant_name: service", "label": 1, "commit_name": "Merge \"Fix Ceilometer deployments\""}
{"code": "ceilometer_service_user_name: \"{{ hostvars['localhost']['ceilometer_service_user_name'] }}\" ceilometer_service_tenant_name: \"{{ hostvars['localhost']['ceilometer_service_tenant_name'] }}\" # swift vars used when swift is enabled swift_system_user_name: \"{{ hostvars['localhost']['swift_system_user_name'] }}\" swift_system_shell: \"{{ hostvars['localhost']['swift_system_shell'] }}\" swift_system_comment: \"{{ hostvars['localhost']['swift_system_comment'] }}\" swift_system_home_folder: \"{{ hostvars['localhost']['swift_system_home_folder'] }}\"", "label": 0, "commit_name": "Merge \"Fix Ceilometer deployments\""}
{"code": "dnf: dnf: dnf: flatpak_remote:", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "ansible.builtin.dnf: ansible.builtin.dnf: ansible.builtin.dnf: community.general.flatpak_remote:", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "- name: install mariadb galera", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"cluster-mariadb: install mariadb galera\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "shell: echo 1 > /proc/sys/net/ipv4/ip_forward systemd: enabled: yes daemon_reload: yes systemd: enabled: yes daemon_reload: yes", "label": 1, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "ansible.builtin.shell: echo 1 > /proc/sys/net/ipv4/ip_forward ansible.builtin.systemd: enabled: true daemon_reload: true ansible.builtin.systemd: enabled: true daemon_reload: true", "label": 0, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "shell: | mkdir -p /root/.kube || true microk8s.config > /root/.kube/config", "label": 1, "commit_name": "Add wireguard, do some cleanups, utilize wireguard for microk8s and fix a glaring omission with longhorn using the /tmp folder - meaning upon host reboot everything was lost"}
{"code": "- name: get kubeconfig from microk8s command: microk8s config register: kubeconfig when: inventory_hostname == master_node copy: dest: /root/.kube/config content: \"{{ kubeconfig.stdout }}\" changed_when: false when: inventory_hostname == master_node - name: emit kube config to the client running ansible local_action: copy content={{ kubeconfig.stdout }} dest=~/.kube/config changed_when: false", "label": 0, "commit_name": "Add wireguard, do some cleanups, utilize wireguard for microk8s and fix a glaring omission with longhorn using the /tmp folder - meaning upon host reboot everything was lost"}
{"code": "- { role: \"setup\", tags: [\"setup\"] } - { role: \"nftables\", tags: [\"nftables\"] } - { role: \"ssh\", tags: [\"ssh\"] } - { role: \"dokuwiki\", tags: [\"dokuwiki\"] } - { role: \"apache\", tags: [\"apache\"] } - { role: \"php\", tags: [\"php\"] }", "label": 1, "commit_name": "Fix yamllint errors"}
{"code": "- {role: \"setup\", tags: [\"setup\"]} - {role: \"nftables\", tags: [\"nftables\"]} - {role: \"ssh\", tags: [\"ssh\"]} - {role: \"dokuwiki\", tags: [\"dokuwiki\"]} - {role: \"apache\", tags: [\"apache\"]} - {role: \"php\", tags: [\"php\"]}", "label": 0, "commit_name": "Fix yamllint errors"}
{"code": "name: \"{{ item }}\" with_items: \"{{ common_apt_packages }}\" name: \"{{ item }}\" with_items: \"{{ packages.apt.install }}\" name: \"{{ item }}\" with_items: \"{{ packages.apt.remove }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ common_apt_packages }}\" name: \"{{ packages.apt.install }}\" name: \"{{ packages.apt.remove }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: docker image: archlinux pre_build_image: false dockerfile: archlinux.dockerfile", "label": 1, "commit_name": "fix molecule to work with Vagrant instead of Docker"}
{"code": "# vagrant: # https://github.com/ansible-community/molecule-vagrant/blob/main/readme.rst name: vagrant provision: true provider: name: virtualbox default_box: 'archlinux/archlinux' hostname: archvagrant.local interfaces: - auto_config: true network_name: private_network type: dhcp - network_name: private_network ip: 192.168.56.100 - network_name: forwarded_port host: 2222 guest: 22 config_options: ssh.keep_alive: true ssh.remote_user: 'vagrant' box: 'archlinux/archlinux' memory: 8092 cpus: 2 # requires: driver -> provision: true instance_raw_config_args: # avoid: \"--sysupgrade\" for misaligned kernel versions b/t rolling updates - 'vm.provision :shell, inline: \"pacman -s --refresh --refresh --noconfirm && pacman -s --noconfirm python sudo\"' env: py_colors: '1' ansible_force_color: '1'", "label": 0, "commit_name": "fix molecule to work with Vagrant instead of Docker"}
{"code": "- name: ensure /usr/lib/systemd/system exists path: /usr/lib/systemd/system dest: /usr/lib/systemd/system/republisher.service dest: /usr/lib/systemd/system/republisher.timer", "label": 1, "commit_name": "republisher: some fixes"}
{"code": "- name: ensure /usr/local/lib/systemd/system exists path: /usr/local/lib/systemd/system dest: /usr/local/lib/systemd/system/republisher.service dest: /usr/local/lib/systemd/system/republisher.timer", "label": 0, "commit_name": "republisher: some fixes"}
{"code": "# - https://wiki.archlinux.org/title/steam/troubleshooting#force_proton_to_use_wine_direct3d_emulation - steam - nvidia # nvidia: closed-source gpu - lib32-systemd # multi desync: https://www.protondb.com/app/813780#t4qkvqck-9 path: '{{ aoe2_dir }}'", "label": 1, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "# - civ5 launch options: https://www.protondb.com/app/8930#umnb6vrvar # - civ6 launch options: https://www.protondb.com/app/289070#gp4yxyme6b - lib32-nvidia-utils # lib32-vulkan-driver: install before 'steam' pkg to prevent steam installing amd drivers - nvidia-utils # vulkan-driver: see previous line - nvidia # nvidia: closed-source gpu - lib32-systemd - steam - name: ensure certain packages are not installed become: true community.general.pacman: name: - lib32-amdvlk - amdvlk state: absent # https://github.com/gloriouseggroll/proton-ge-custom#native - name: === proton gloriouseggroll block === vars: - proton_ge_version: ge-proton7-42 - proton_ge_filename: '{{ proton_ge_version }}.tar.gz' - proton_ge_url: https://github.com/gloriouseggroll/proton-ge-custom/releases/download/{{ proton_ge_version }}/{{ proton_ge_filename }} - install_location: ~/.steam/root/compatibilitytools.d/ - download_location: '{{ install_location }}/{{ proton_ge_filename}}' block: - name: ensure folder exists ansible.builtin.file: path: '{{ install_location }}' owner: '{{ ansible_user }}' group: '{{ ansible_user }}' mode: '0755' state: directory - name: download proton ge build ansible.builtin.get_url: url: '{{ proton_ge_url }}' dest: '{{ download_location }}' - name: extract proton ge archive ansible.builtin.unarchive: remote_src: true src: '{{ download_location }}' dest: '{{ install_location }}' owner: '{{ ansible_user }}' group: '{{ ansible_user }}' mode: '0755' creates: '{{ install_location }}/{{ proton_ge_version }}' # multi desync: https://www.protondb.com/app/813780#t4qkvqck-9 owner: '{{ ansible_user }}' group: '{{ ansible_user }}' # note: cabextract requires elevation # note: cabextract requires elevation path: '{{ aoe2_dir }}'", "label": 0, "commit_name": "Merge branch '13-fix-zshrc' into 'main'"}
{"code": "name: \"{{ item }}\" with_items: \"{{ termux_pip_packages }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: \"{{ termux_pip_packages }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "- import_tasks: all.yml - import_tasks: rhel.yml - import_tasks: debian.yml", "label": 1, "commit_name": "ansible-lint: Fix some errors"}
{"code": "- ansible.builtin.import_tasks: all.yml - ansible.builtin.import_tasks: rhel.yml - ansible.builtin.import_tasks: debian.yml", "label": 0, "commit_name": "ansible-lint: Fix some errors"}
{"code": "- name: add ansible-pull test script", "label": 1, "commit_name": "fixed spelling issue and centos cokpit not starting"}
{"code": "when: ansible_distribution != \"centos\" - name: add helpful scripts", "label": 0, "commit_name": "fixed spelling issue and centos cokpit not starting"}
{"code": "- docker", "label": 1, "commit_name": "Fix Travis."}
{"code": "- lexrus.ansible-role-docker", "label": 0, "commit_name": "Fix Travis."}
{"code": "# todo: end task: disable - name: enable passwordless sudo for \"{{ username }}\" lineinfile: dest: /etc/sudoers regexp: \"^%wheel\" line: \"{{ username }} all=(all) nopasswd: all\" validate: \"/usr/sbin/visudo -cf %s\" user: severi path: \"{{ lookup('env', 'home') + '/.ssh/authorized_keys' }}\"", "label": 1, "commit_name": "fix sudoers bug"}
{"code": "# pre-cond: user is sudoer ## todo: end task: disable #- name: enable passwordless sudo for \"{{ username }}\" # lineinfile: # dest: /etc/sudoers # regexp: \"^%wheel\" # line: \"{{ username }} all=(all) nopasswd: all\" # validate: \"/usr/sbin/visudo -cf %s\" user: \"{{ username }}\" path: \"{{ '/home/' + username + '/.ssh/authorized_keys' }}\"", "label": 0, "commit_name": "fix sudoers bug"}
{"code": "line: \"user = {{ user }}\" line: \"group = {{ user }}\"", "label": 1, "commit_name": "Fix user vars"}
{"code": "line: \"user = {{ ansible_user }}\" line: \"group = {{ ansible_user }}\"", "label": 0, "commit_name": "Fix user vars"}
{"code": "- name: install loft.sh", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"loft: install\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: checkout kustomize-dandelion when: hostvars[item]['dandelion']['interactive'] is defined hostvars[item]['dandelion']['interactive']|bool != false export namespace=dandelion-${network}", "label": 1, "commit_name": "fix(kustomize-cardano-node): fixed couple of dandelion typos"}
{"code": "- name: checkout kustomize-cardano-node when: hostvars[item]['stakepool']['interactive'] is defined hostvars[item]['stakepool']['interactive']|bool != false export namespace=cardano-${network}", "label": 0, "commit_name": "fix(kustomize-cardano-node): fixed couple of dandelion typos"}
{"code": "template: src=mongod.conf.j2 dest=/etc/mongod-${inventory_hostname}.conf command: creates=/var/lock/subsys/mongod-${inventory_hostname} /etc/init.d/mongod-${inventory_hostname} start", "label": 1, "commit_name": "Merge pull request #107 from tuladhar/fix-var-interpo"}
{"code": "template: src=mongod.conf.j2 dest=/etc/mongod-{{ inventory_hostname }}.conf command: creates=/var/lock/subsys/mongod-{{ inventory_hostname }} /etc/init.d/mongod-{{ inventory_hostname }} start", "label": 0, "commit_name": "Merge pull request #107 from tuladhar/fix-var-interpo"}
{"code": "#- name: generate locale # locale_gen: name=\"en_us.utf-8\" state=present #- name: update locale # command: /usr/sbin/update-locale lang=en_us.utf-8 lc_all=en_us.utf-8 # notify: reconfigure dpkg", "label": 1, "commit_name": "Fix 2 to pull request"}
{"code": "- name: generate locale locale_gen: name=\"en_us.utf-8\" state=present - name: update locale command: /usr/sbin/update-locale lang=en_us.utf-8 lc_all=en_us.utf-8 notify: reconfigure dpkg", "label": 0, "commit_name": "Fix 2 to pull request"}
{"code": "#- \"../vars/{{ ansible_distribution }}-{{ ansible_distribution_major_version | int}}.yml\" #- \"../vars/{{ ansible_distribution }}.yml\"", "label": 1, "commit_name": "Update to use official openscap SSGs instead of ubuntu-scap. Fixes #39"}
{"code": "- \"../vars/{{ ansible_distribution }}-{{ ansible_distribution_version}}.yml\" - \"../vars/{{ ansible_distribution }}-{{ ansible_distribution_major_version }}.yml\" #for now skip debian since it's version of oscap is so old it won't support new definitions. revisit for debian 9 when: ansible_distribution not in ['debian']", "label": 0, "commit_name": "Update to use official openscap SSGs instead of ubuntu-scap. Fixes #39"}
{"code": "- name: test connection to webapp", "label": 1, "commit_name": "fix some ansible-lint errors"}
{"code": "- name: test connection to webapp", "label": 0, "commit_name": "fix some ansible-lint errors"}
{"code": "- name: create & set chmod user:user to /etc/nginx/conf.d", "label": 1, "commit_name": "Fix chown (0700) for /var/www"}
{"code": "- name: create & set chown user:user to /etc/nginx/conf.d - name: create & set chown user:user to /var/www file: state: directory path: /var/www owner: \"{{ ansible_user }}\" group: \"{{ ansible_user }}\" mode: 0700", "label": 0, "commit_name": "Fix chown (0700) for /var/www"}
{"code": "rbenv_owner: root rbenv_group: root become: yes", "label": 1, "commit_name": "fix ownership for rbenv"}
{"code": "rbenv_owner: adrl rbenv_group: adrl", "label": 0, "commit_name": "fix ownership for rbenv"}
{"code": "- name: create postgresql db 'metastore' - name: init metastore schema command: psql --dbname=metastore --file=/usr/lib/hive/scripts/metastore/upgrade/postgres/hive-schema-0.10.0.postgres.sql - name: grant hiveuser command: psql --dbname=metastore --command=\"grant all on all tables in schema public to hiveuser;\"", "label": 1, "commit_name": "Fix PostgreSQL install. [ci skip]"}
{"code": "- name: create postgresql db 'metastore' - name: init hive metastore schema shell: psql --dbname=metastore --file=/usr/lib/hive/scripts/metastore/upgrade/postgres/hive-schema-0.10.0.postgres.sql - name: grant postgresql user 'hiveuser' shell: psql --dbname=metastore --command=\"grant all on all tables in schema public to hiveuser;\"", "label": 0, "commit_name": "Fix PostgreSQL install. [ci skip]"}
{"code": "action: apt pkg=$item state=installed action: apt pkg=$item state=installed", "label": 1, "commit_name": "Removing legacy variable substitution $var and replacing with {{}} due to deprecation"}
{"code": "action: apt pkg={{ item }} state=installed action: apt pkg={{ item }} state=installed", "label": 0, "commit_name": "Removing legacy variable substitution $var and replacing with {{}} due to deprecation"}
{"code": "hostname: name=\"{{ server_hostname }}\" dest=/etc/hosts with_items: groups['linode'] copy: src=files/ssh/sshd_config dest=/etc/ssh/sshd_config notify: restart ssh service: name=ssh state=restarted", "label": 1, "commit_name": "fix up hosts file"}
{"code": "hostname: name=\"{{ server_hostname }}\" path=/etc/hosts with_items: \"{{ groups['linode'] }}\" copy: src=files/ssh/sshd_config dest=/etc/ssh/sshd_config notify: restart ssh service: name=ssh state=restarted", "label": 0, "commit_name": "fix up hosts file"}
{"code": "shell: chdir /home/{{master_user}}/kafka-deployment-template/ helm install kafka --set service.type=clusterip --set namespace=kafka -f values.yaml .", "label": 1, "commit_name": "-> update task kafka \"issue: *doing nothing*\""}
{"code": "shell: cd /home/{{master_user}}/kafka-deployment-template/ && helm install kafka --set service.type=clusterip --set namespace=kafka -f values.yaml .", "label": 0, "commit_name": "-> update task kafka \"issue: *doing nothing*\""}
{"code": "with_items: users.stdout_lines", "label": 1, "commit_name": "fix bare variables usage for loops"}
{"code": "with_items: '{{ users.stdout_lines }}'", "label": 0, "commit_name": "fix bare variables usage for loops"}
{"code": "register: result with_items: \"{{ grep_result.stdout_lines }}\" when: ansible_os_family == \"redhat\" and ansible_distribution_major_version == \"6\"", "label": 1, "commit_name": "Fix for a deprecation warning."}
{"code": "with_items: \"{{ grep_result.stdout_lines | default('') }}\" when: ansible_os_family == \"redhat\" and (ansible_distribution == \"amazon\" or ansible_distribution_major_version == \"6\")", "label": 0, "commit_name": "Fix for a deprecation warning."}
{"code": "--name=ceph-osd-prepare-{{ ansible_hostname }}-{{ item.key }} \\ -e osd_device=/dev/{{ item.key }} \\ with_dict: \"{{ ansible_devices }}\" - ansible_devices is defined - item.value.removable == \"0\" - item.value.partitions|count == 0 - item.value.holders|count == 0", "label": 1, "commit_name": "Merge pull request #2145 from ceph/fix-autodiscover"}
{"code": "--name=ceph-osd-prepare-{{ ansible_hostname }}-{{ item.split('/')[-1] }} \\ -e osd_device={{ item }} \\ with_items: \"{{ devices }}\" - devices is defined", "label": 0, "commit_name": "Merge pull request #2145 from ceph/fix-autodiscover"}
{"code": "ansible.builtin.import_tasks: factory-env.yml mds_name: mds_server.name", "label": 1, "commit_name": "5046 fix problem with passing mds_name variable"}
{"code": "ansible.builtin.include_tasks: factory-env.yml mds_name: \"{{ item.name }}\" loop: \"{{ mds_servers }}\"", "label": 0, "commit_name": "5046 fix problem with passing mds_name variable"}
{"code": "- set_fact: plugins_to_remove=\"{{ installed_plugins.stdout_lines | difference(es_plugins | json_query('es_plugins[*].plugin')) | default([]) }}\"", "label": 1, "commit_name": "Fixes for multi + config tests"}
{"code": "- set_fact: plugins_to_remove=\"{{ installed_plugins.stdout_lines | difference(es_plugins | json_query('[*].plugin')) | default([]) }}\"", "label": 0, "commit_name": "Fixes for multi + config tests"}
{"code": "fail: apt: update_cache: yes", "label": 1, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "ansible.builtin.fail: ansible.builtin.apt: update_cache: true", "label": 0, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "database:", "label": 1, "commit_name": "fixed mc db error and added support for lxc"}
{"code": "database: \"{{ postgres.database }}\"", "label": 0, "commit_name": "fixed mc db error and added support for lxc"}
{"code": "yum: name={{ item }} state=installed seboolean: name=mysql_connect_any state=true persistent=yes template: src=my.cnf.j2 dest=/etc/my.cnf service: name=mysqld state=started enabled=yes lineinfile: dest=/etc/sysconfig/iptables state=present regexp=\"{{ mysql_port }}\" insertafter=\"^:output \" line=\"-a input -p tcp --dport {{ mysql_port }} -j accept\" mysql_db: name={{ dbname }} state=present mysql_user: name={{ dbuser }} password={{ upassword }} priv=*.*:all host='%' state=present", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "yum: name: \"{{ item }}\" state: installed seboolean: name: mysql_connect_any state: true persistent: yes template: src: my.cnf.j2 dest: /etc/my.cnf service: name: mysqld state: started enabled: yes lineinfile: dest: /etc/sysconfig/iptables state: present regexp: \"{{ mysql_port }}\" insertafter: \"^:output \" line: \"-a input -p tcp --dport {{ mysql_port }} -j accept\" mysql_db: name: \"{{ dbname }}\" state: present mysql_user: name: \"{{ dbuser }}\" password: \"{{ upassword }}\" priv: \"*.*:all\" host: '%' state: present", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "- sequel-pro", "label": 1, "commit_name": "Fixes #127: Replace Sequel Pro with Sequel Ace."}
{"code": "- sequel-ace", "label": 0, "commit_name": "Fixes #127: Replace Sequel Pro with Sequel Ace."}
{"code": "template: template src=opt/easynat/setup_nat_split dest=/opt/easynat/setup_nat mode=755", "label": 1, "commit_name": "fixes one line in the NAT main.yml"}
{"code": "template: src=opt/easynat/setup_nat_split dest=/opt/easynat/setup_nat mode=755", "label": 0, "commit_name": "fixes one line in the NAT main.yml"}
{"code": "server: true, retry_join: %w[{{ groups.secondary_patronis_internal[0] }} {{ groups.secondary_patronis_internal[1] }} {{ groups.secondary_patronis_internal[2] }}] postgresql['max_replication_slots'] = 1 command: gitlab-ctl replicate-geo-database --slot-name=singleslot --host={{ groups.primary_host[0] }} --no-wait --skip-backup --force retry_join: %w[{{ groups.secondary_patronis_internal[0] }} {{ groups.secondary_patronis_internal[1] }} {{ groups.secondary_patronis_internal[2] }}] retry_join: %w[{{ groups.secondary_patronis[0] }} {{ groups.secondary_patronis[1] }} {{ groups.secondary_patronis[2] }}]", "label": 1, "commit_name": "Fix consul and improve bootstrap"}
{"code": "retry_join: %w[{{ groups.primary_patronis_internal[0] }} {{ groups.primary_patronis_internal[1] }} {{ groups.primary_patronis_internal[2] }}] } repmgr['enable'] = false patroni['enable'] = false # after bootstrapping, enable this patroni['replication_slots'] = { 'geo_secondary' => { 'type' => 'physical' } patroni['replication_password'] = '{{ sql_user_password_plain }}' patroni['use_pg_rewind'] = true postgresql['max_replication_slots'] = 5 command: gitlab-ctl replicate-geo-database --slot-name=singleslot --host={{ groups.primary_host_internal[0] }} --no-wait --skip-backup --force retry_join: %w[{{ groups.primary_patronis_internal[0] }} {{ groups.primary_patronis_internal[1] }} {{ groups.primary_patronis_internal[2] }}] retry_join: %w[{{ groups.secondary_patronis_internal[0] }} {{ groups.secondary_patronis_internal[1] }} {{ groups.secondary_patronis_internal[2] }}]", "label": 0, "commit_name": "Fix consul and improve bootstrap"}
{"code": "slurp: src=\"{{openvpn_key_dir}}\"/ca.crt slurp: src=\"{{openvpn_key_dir}}\"/ta.key slurp: src=\"{{openvpn_key_dir}}\"/{{item}}.crt slurp: src=\"{{openvpn_key_dir}}\"/{{item}}.key - client_certs.results - client_keys.results", "label": 1, "commit_name": "Fix variable formatting issues"}
{"code": "slurp: src=\"{{openvpn_key_dir}}/ca.crt\" slurp: src=\"{{openvpn_key_dir}}/ta.key\" slurp: src=\"{{openvpn_key_dir}}/{{item}}.crt\" slurp: src=\"{{openvpn_key_dir}}/{{item}}.key\" - \"{{client_certs.results}}\" - \"{{client_keys.results}}\"", "label": 0, "commit_name": "Fix variable formatting issues"}
{"code": "hostname: \"{{ item.natip }}\" - \"{{ gce_pgbouncer_secondary.networkinterfaces[0].accessconfigs[0] }}\" hostname: \"{{ item.networkip }}\" - \"{{ gce_pgbouncer_secondary.networkinterfaces[0] }}\"", "label": 1, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "hostname: \"{{ item.networkinterfaces[0].accessconfigs[0].natip }}\" - \"{{ gce_pgbouncer_secondary }}\" hostname: \"{{ item.networkinterfaces[0].networkip }}\" - \"{{ gce_pgbouncer_secondary }}\"", "label": 0, "commit_name": "Refactor items and groups usage to condensate them into fewer lines"}
{"code": "local_action: \"command scp -r {{ splunk_repository.repository_root }}/distserverkeys/{{ ansible_hostname }}* splunk@{{ item }}:{{ splunk_installation.splunk_home_path }}/etc/auth/distserverkeys\"", "label": 1, "commit_name": "fix some things... add notes"}
{"code": "local_action: \"shell scp -r {{ splunk_repository.repository_root }}/distserverkeys/{{ ansible_hostname }}/* splunk@{{ item }}:{{ splunk_installation.splunk_home_path }}/etc/auth/distserverkeys\"", "label": 0, "commit_name": "fix some things... add notes"}
{"code": "- aws_access_key_id - aws_secret_access_key - azure_secret - azure_client_id - azure_subscription_id - azure_tenant - controller_host - controller_username - controller_password - controller_verify_ssl - gcp_auth_kind - gcp_project - gcp_service_account_file - k8s_auth_verify_ssl - k8s_auth_host - k8s_auth_api_key - ovirt_hostname - ovirt_username - ovirt_password - vmware_host - vmware_user - vmware_password", "label": 1, "commit_name": "fix yaml indent"}
{"code": "- aws_access_key_id - aws_secret_access_key - azure_secret - azure_client_id - azure_subscription_id - azure_tenant - controller_host - controller_username - controller_password - controller_verify_ssl - gcp_auth_kind - gcp_project - gcp_service_account_file - k8s_auth_verify_ssl - k8s_auth_host - k8s_auth_api_key - ovirt_hostname - ovirt_username - ovirt_password - vmware_host - vmware_user - vmware_password", "label": 0, "commit_name": "fix yaml indent"}
{"code": "service: name=php5-fpm state=restarted", "label": 1, "commit_name": "Postfix; fix php fpm restart"}
{"code": "shell: service php5-fpm restart", "label": 0, "commit_name": "Postfix; fix php fpm restart"}
{"code": "- { role: ssh, sshd: ssh, sshd_config: /etc/sshd_config }", "label": 1, "commit_name": "Fix reference to current role in examples"}
{"code": "- { role: ., sshd: ssh, sshd_config: /etc/sshd_config }", "label": 0, "commit_name": "Fix reference to current role in examples"}
{"code": "path: \"{{ arch_dir }}/{{ enemon_db_name }}.bz2\"", "label": 1, "commit_name": "Merge branch 'fix-arch-del' into 'master'"}
{"code": "path: \"{{ arch_dir }}/{{ db_pg_name }}_bkp.bz2\"", "label": 0, "commit_name": "Merge branch 'fix-arch-del' into 'master'"}
{"code": "- gstreamer1-plugins-good-extras - gstreamer1-plugins-good-gtk - keepassxc", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "- gstreamer1-plugins-good-extras - gstreamer1-plugins-good-gtk - keepassxc", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "connection: local \u2502 gather_facts: no \u2502", "label": 1, "commit_name": "Merge branch 'Fix-azure-issue-by-waiting-for-host' into 'master'"}
{"code": "connection: local gather_facts: no post_tasks: # # 2 minutes pause introduced to let the azure instance to finish its setup after deployment. # this is due to some dns resolution issues noticed when idm installation is kicked right after instance is deployed # this will impact other providers deployment until removed or migrated to azure specific automation - name: wait for 2 minutes until instance is ready pause: minutes: 2", "label": 0, "commit_name": "Merge branch 'Fix-azure-issue-by-waiting-for-host' into 'master'"}
{"code": "grep -lriz 'pin: release a={{ dist_upgrade_current_release }}-backports' /etc/apt/preferences.d | xargs -0 rm -f --", "label": 1, "commit_name": "Merge branch 'ypid-fix-dist-upgrade'"}
{"code": "grep -lriz 'pin: release .*={{ dist_upgrade_current_release }}-backports' /etc/apt/preferences.d | xargs -0 rm -f --", "label": 0, "commit_name": "Merge branch 'ypid-fix-dist-upgrade'"}
{"code": "- name: \"verify:&sonarqube\" hosts: \"all\" - name: \"get postgresql service current state\" register: install_postgresql_service_status failed_when: not install_postgresql_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"postgresql\" - name: \"get sonarqube service current state\" register: install_sonarqube_service_status failed_when: not install_sonarqube_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"sonarqube\" - name: \"check tcp connectivities\" - name: \"check postgresql connectivity\" ansible.builtin.wait_for: host: \"127.0.0.1\" port: \"5432\" timeout: 120 - name: \"check elasticsearch connectivity\" ansible.builtin.wait_for: host: \"localhost\" port: \"{{ inv_install_sonarqube_elasticsearch_port }}\" timeout: 120 - name: \"check sonarqube connectivity\" ansible.builtin.wait_for: host: \"localhost\" port: \"{{ inv_install_sonarqube_web_port }}\" timeout: 120 - name: \"check sonarqube http url\" url: \"http://localhost:{{ inv_install_sonarqube_web_port }}\" # don't forget to keep this file updated # molecule/<scenario>/verify.yml - name: \"verify\" hosts: \"all:&apache2\" gather_facts: false tasks: - name: \"get apache2 service current state\" register: install_apache_service_status failed_when: not install_apache_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"apache2\" - name: \"check apache2 folders and conf\" loop: - \"/etc/apache2/apache2.conf\" - \"/etc/apache2/ports.conf\" loop_control: loop_var: folder_path register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ folder_path }}\" - name: \"check apache2 http connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_apache_http_listen_port }}\" timeout: 120 - name: \"check apache2 https connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_apache_https_listen_port }}\" timeout: 120 - name: \"check apache2 default configuration\" - name: \"check apache2 http and conf\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs_confs_path }}/{{ vhost.server.name }}-http.conf\" - name: \"check apache2 https and conf\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs_confs_path }}/{{ vhost.server.name }}-https.conf\" - name: \"check https conf: certs\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.crt }}\" - name: \"check https conf: keys\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.key }}\" - name: \"check apache2 webserver\" block: - name: \"check apache2 connectivity\" port: \"{{ inv_add_apache_confs_http_listen_port }}\" - name: \"check default vhost on http\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_add_apache_confs_http_listen_port }}/\" method: \"get\" - name: \"check default vhost on https\" failed_when: not (result.status != 200 or result.status == -1) url: \"https://{{ inventory_hostname }}:{{ inv_add_apache_confs_https_listen_port }}/\"", "label": 1, "commit_name": "fix role, fix playbook, refacto, need readme"}
{"code": "- name: \"verify\" hosts: \"cicd-debian-11\" - name: \"verify docker\" when: inv_install_docker | default(false) - name: \"check docker-compose command response\" register: output changed_when: output.rc != 0 failed_when: output.rc != 0 ansible.builtin.command: \"docker -v\" - name: \"check docker-compose command response\" register: output changed_when: output.rc != 0 failed_when: output.rc != 0 ansible.builtin.command: \"docker-compose -v\" - name: \"check docker insecure registries\" when: inv_install_docker__insecure_registries is defined block: - name: \"check docker registries file\" register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"/etc/docker/daemon.json\" - name: \"check if insecure registries are in the /etc/docker/daemon.json file\" loop: \"{{ inv_install_docker__insecure_registries }}\" loop_control: loop_var: registry register: registry_state failed_when: registry_state.rc != 0 changed_when: registry_state.rc != 0 ansible.builtin.command: \"grep -q {{ registry }} /etc/docker/daemon.json\" - name: \"check portainer http url\" when: (inv_install_docker__portainer | default(false)) url: \"http://127.0.0.1:{{ inv_install_docker__portainer_http_port }}/\" - name: \"check portainer https url\" when: (inv_install_docker__portainer | default(false)) and (inv_install_docker__portainer_ssl | default(false)) register: result failed_when: result.status != 200 ansible.builtin.uri: validate_certs: no url: \"https://127.0.0.1:{{ inv_install_docker__portainer_https_port }}/\" method: \"get\" - name: \"verify apache2\" when: inv_install_apache | default(false) - name: \"get apache2 service current state\" register: install_apache__service_status failed_when: not install_apache__service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"apache2\" - name: \"check apache2 http connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_apache__http_listen_port }}\" timeout: 120 - name: \"check apache2 https connectivity\" port: \"{{ inv_install_apache__https_listen_port }}\" - name: \"check apache2 default configuration\" block: - name: \"check apache2 folders and conf\" loop: - \"/etc/apache2/apache2.conf\" - \"/etc/apache2/ports.conf\" loop_control: loop_var: folder_path register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ folder_path }}\" - name: \"check apache2 http and conf\" loop: \"{{ inv_add_apache_confs__configurations }}\" loop_control: loop_var: vhost register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs__confs_path }}/{{ vhost.server.name }}-http.conf\" - name: \"check apache2 https and conf\" loop: \"{{ inv_add_apache_confs__configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs__confs_path }}/{{ vhost.server.name }}-https.conf\" - name: \"check https conf: certs\" loop: \"{{ inv_add_apache_confs__configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.crt }}\" - name: \"check https conf: keys\" loop: \"{{ inv_add_apache_confs__configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.key }}\" - name: \"check apache2 webserver\" block: - name: \"check apache2 connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_add_apache_confs__http_listen_port }}\" timeout: 120 - name: \"check default vhost on http\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_add_apache_confs__http_listen_port }}/\" method: \"get\" - name: \"check default vhost on https\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"https://{{ inventory_hostname }}:{{ inv_add_apache_confs__https_listen_port }}/\" method: \"get\" - name: \"verify sonarqube\" when: inv_install_sonarqube | default(false) block: - name: \"check docker-compose command response\" register: output changed_when: output.rc != 0 failed_when: output.rc != 0 ansible.builtin.command: \"docker -v\" - name: \"check docker-compose command response\" register: output changed_when: output.rc != 0 failed_when: output.rc != 0 ansible.builtin.command: \"docker-compose -v\" - name: \"check soanrqube http url\" failed_when: result.status != 200 url: \"http://{{ inventory_hostname }}:{{ inv_install_sonarqube__web_port }}/\"", "label": 0, "commit_name": "fix role, fix playbook, refacto, need readme"}
{"code": "- \"ansible-playbook --extra-vars '{\"configure_sudoers\":\"false\"}' main.yml | tee -a ${idempotence}\"", "label": 1, "commit_name": "Fix other instance of inline JSON."}
{"code": "- \"ansible-playbook --extra-vars '{\\\"configure_sudoers\\\":\\\"false\\\"}' main.yml | tee -a ${idempotence}\"", "label": 0, "commit_name": "Fix other instance of inline JSON."}
{"code": "- name: create & set chmod user:user to /var/www/{{ domain }}/html path: \"{{ item.path }}\" mode: 0644 with_items: - { path: \"/var/www\" } - { path: \"/var/www/{{ domain }}/html\" } mode: 0644 mode: 0644", "label": 1, "commit_name": "Fix chown (0700) for /var/www"}
{"code": "- name: create & set chown user:user to /var/www/{{ domain }}/html path: /var/www/{{ domain }}/html mode: 0700 mode: 0700 mode: 0700", "label": 0, "commit_name": "Fix chown (0700) for /var/www"}
{"code": "# @tag: configuration # description of configuration # @task: install # install all the needed apps", "label": 1, "commit_name": "minor fixes"}
{"code": "# @tag: configuration # description of configuration\u00e7 # @action: install # install all the needed apps\u00e7 # \u00f1\u00e7\u00e7", "label": 0, "commit_name": "minor fixes"}
{"code": "hosts: all tasks: - name: install tree become: true apt: state: present name: - tree", "label": 1, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "become: true apt: state: present name: - tree", "label": 0, "commit_name": "refactor: updated the task files to be alligned with standards"}
{"code": "# ca file copied from engine:/etc/pki/ovirt-engine/ca.pem; path is relative to playbook directory #qcow_url: https://cloud.centos.org/centos/7/images/centos-7-x86_64-genericcloud.qcow2 root_ssh_key:", "label": 1, "commit_name": "Small fixes for RHV provider:"}
{"code": "# ca file copied or downloaded from engine; path is relative to playbook directory. # download url https://<engine>/ovirt-engine/services/pki-resource?resource=ca-certificate&format=x509-pem-ca # if you are running on engine, you could use the below. # engine_cafile: /etc/pki/ovirt-engine/ca.pem #qcow_url: https://cloud.centos.org/centos/7/images/centos-7-x86_64-genericcloud.qcow2c root_ssh_key: \"{{ lookup('file', '~/.ssh/id_rsa.pub') }}\"", "label": 0, "commit_name": "Small fixes for RHV provider:"}
{"code": "command: \"sudo scripts/gate-check-commit.sh {{ scenario }} {{ action }}\" environment: '{{ zuul | zuul_legacy_vars }}'", "label": 1, "commit_name": "Merge \"Update aio job to use become and fix environment\""}
{"code": "become: yes become_user: root command: \"scripts/gate-check-commit.sh {{ scenario }} {{ action }}\" environment: # zuul_project is used by tests/get-ansible-role-requirements to # determine when ci provided repos should be used. zuul_project: \"{{ zuul.project.short_name }}\"", "label": 0, "commit_name": "Merge \"Update aio job to use become and fix environment\""}
{"code": "autoscan_container_image: '{{ autoscan_container_repo }}{{ \":\" + autoscan_container_tag }}'", "label": 1, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "autoscan_container_image: 'cloudb0x/autoscan:{{ autoscan_container_tag }}'", "label": 0, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "# https://github.com/ansible-community/molecule-vagrant/blob/main/readme.rst - name: instance # https://www.jeffgeerling.com/blog/2020/getting-colorized-output-molecule-and-ansible-on-github-actions-ci", "label": 1, "commit_name": "tweaks"}
{"code": "# molecule docs: # - https://molecule.readthedocs.io/en/latest/examples.html # - https://github.com/ansible-community/molecule-vagrant/blob/main/readme.rst - name: test_instance # https://www.jeffgeerling.com/blog/2020/getting-colorized-output-molecule-and-ansible-on-github-actions-ci # https://docs.ansible.com/ansible/latest/reference_appendices/config.html#default-timeout # ansible_timeout: 180 # ansible_persistent_command_timeout: 180 # ansible_persistent_connect_retry_timeout: 120 # ansible_config: 'ansible.cfg' config_options: defaults: vault_password_file: \"${molecule_project_directory}/.vault_pass\" # lint: | # ansible-lint", "label": 0, "commit_name": "tweaks"}
{"code": "name: \"{{ item }}\" with_items: ['apticron', 'heirloom-mailx', 'unattended-upgrades'] line: 'email=\"helpdesk@plugintheworld.com\"' line: 'unattended-upgrade::mail \"helpdesk@plugintheworld.com\";'", "label": 1, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "name: ['apticron', 'heirloom-mailx', 'unattended-upgrades'] line: 'email=\"{{ mail_username }}@{{ domain }}\"' line: 'unattended-upgrade::mail \"{{ mail_username }}@{{ domain }}\";'", "label": 0, "commit_name": "update ansible syntax, fix issues with ci role"}
{"code": "- \"{{pl_rancher_port}}:8080\" until: rancher_logs.stdout.find(\"listening on\") != -1", "label": 1, "commit_name": "rancher fixes"}
{"code": "- \"{{pl_rancher_port}}:{{pl_rancher_port}}\" pull: true volumes: - /var/run/docker.sock:/var/run/docker.sock until: rancher_logs.stdout.find(\"listening on\") != -1 or rancher_logs.stdout.find(\"waiting to become master\") != -1", "label": 0, "commit_name": "rancher fixes"}
{"code": "- name: '[packages_flatpak] ensure ~/.var directory is owned by user.' file: path: \"{{ ansible_user_home_dir }}/.var\" owner: \"{{ ansible_user }}\" group: \"{{ ansible_user }}\" state: directory mode: '0755' recurse: true", "label": 1, "commit_name": "Only fix ownership if repo has changed."}
{"code": "register: books_cloned when: books_cloned is changed", "label": 0, "commit_name": "Only fix ownership if repo has changed."}
{"code": "- docker buildx build --build-arg version=${version} --platform ${platform} --tag alpine-ansible --cache-to type=local,dest=.cache/${platform} --load . --cache-from type=local,src=.cache/linux/amd64 \\ --cache-from type=local,src=.cache/linux/arm64 \\ --cache-from type=local,src=.cache/linux/arm/v7 \\ --cache-from type=local,src=.cache/linux/arm/v6 \\", "label": 1, "commit_name": "Fix cache path"}
{"code": "- docker buildx build --build-arg version=${version} --platform ${platform} --tag alpine-ansible --cache-to type=local,dest=.cache/${platform}/${version} --load . --cache-from type=local,src=.cache/linux/amd64/${version} \\ --cache-from type=local,src=.cache/linux/arm64/${version} \\ --cache-from type=local,src=.cache/linux/arm/v7/${version} \\ --cache-from type=local,src=.cache/linux/arm/v6/${version} \\", "label": 0, "commit_name": "Fix cache path"}
{"code": "packages_to_install:", "label": 1, "commit_name": "Fix merge conflict"}
{"code": "packages_to_install_debian: packages_to_install_redhat: - tmux - bash-completion - vim", "label": 0, "commit_name": "Fix merge conflict"}
{"code": "services: ubuntu: build: context:", "label": 1, "commit_name": "Fix volumes"}
{"code": "# containers services: # container ubuntu: build: context: . dockerfile: dockerfile user: \"root:root\" restart: unless-stopped container_name: ubuntu tty: true ports: - \"22:22\" environment: - ssh_auth_sock=/ssh-agent volumes: - /var/run/docker.sock:/var/run/docker.sock - ${ssh_auth_sock}:/ssh-agent - ${dot_ssh}:/root/.ssh #<- path to your .ssh directory - ${ansible_playbooks}:/root/ansible #<- path to your ansible project/directory # - /mnt/c/laragon/bin/cmder/.ssh:/root/.ssh # - ./ansible:/root/ansible # - ${ssh_auth_sock}:/ssh-agent working_dir: /root", "label": 0, "commit_name": "Fix volumes"}
{"code": "- find . \\( -name \"yaml-shellcheck\" -prune \\) -o \\( -name \"*.yml\" -print0 \\) \\", "label": 1, "commit_name": "fix pipeline"}
{"code": "- >- find . \\( -name \"yaml-shellcheck\" -prune \\) -o \\( -name \"*.yml\" -print0 \\)", "label": 0, "commit_name": "fix pipeline"}
{"code": "community.general.cargo:", "label": 1, "commit_name": "Fix indentation"}
{"code": "community.general.cargo:", "label": 0, "commit_name": "Fix indentation"}
{"code": "- name: create mariadb configuration file ansible.builtin.template: src: my.cnf.j2 dest: /root/.my.cnf mode: 0644 owner: root group: root notify: - restart mariadb", "label": 1, "commit_name": "try to solve the login error"}
{"code": "# - name: create mariadb configuration file # ansible.builtin.template: # src: my.cnf.j2 # dest: /root/.my.cnf # mode: 0644 # owner: root # group: root # notify: # - restart mariadb login_user: root login_user: root update_password: on_create", "label": 0, "commit_name": "try to solve the login error"}
{"code": "yum: name=http://repos.mesosphere.io/el/6/noarch/rpms/mesosphere-el-repo-6-2.noarch.rpm state=present", "label": 1, "commit_name": "CentOS/EL 7 support, test validation."}
{"code": "yum: name={{ mesosphere_repo }} state=present", "label": 0, "commit_name": "CentOS/EL 7 support, test validation."}
{"code": "with_items: privileged_programs.stdout_lines", "label": 1, "commit_name": "Replaced bare variables with the correct syntax in tasks section 2 and 8. Ran the playbook and verified no deprecation errors."}
{"code": "with_items: \"{{ privileged_programs.stdout_lines }}\"", "label": 0, "commit_name": "Replaced bare variables with the correct syntax in tasks section 2 and 8. Ran the playbook and verified no deprecation errors."}
{"code": "notify: restart nginx", "label": 1, "commit_name": "* Fixed a bug that caused Nginx to be restarted twice in"}
{"code": "notify: restart nginx with updated vhost configuration", "label": 0, "commit_name": "* Fixed a bug that caused Nginx to be restarted twice in"}
{"code": "ruby_version: 2.5.0 path: \"{{rbenv_path}}/bin:{{ruby_bin_path}}:{{ansible_env.path}}\"", "label": 1, "commit_name": "upgrade ro 2.5.1 as is required, and fix some PATH issues for setup-env.sh"}
{"code": "ruby_version: 2.5.1 path: \"{{rbenv_path}}/libexec:{{ruby_bin_path}}:{{rbenv_path}}/plugins/ruby-build/bin:{{ansible_env.path}}\" rbenv_root: \"{{mastodon_home}}/.rbenv\"", "label": 0, "commit_name": "upgrade ro 2.5.1 as is required, and fix some PATH issues for setup-env.sh"}
{"code": "#delegate_to: '{{ backup_server_ip }}' #delegate_to: '{{ backup_server_ip }}'", "label": 1, "commit_name": "minor error in delegation"}
{"code": "delegate_to: '{{ backup_server_ip }}' delegate_to: '{{ backup_server_ip }}'", "label": 0, "commit_name": "minor error in delegation"}
{"code": "- shell: ' sudo apt-get install apache2-utils '", "label": 1, "commit_name": "Add treafik2.2 bugs fixes 2"}
{"code": "- shell: ' sudo apt-get install -y apache2-utils '", "label": 0, "commit_name": "Add treafik2.2 bugs fixes 2"}
{"code": "name: src: files/terminal.desktop dest: /usr/share/applications/terminal.desktop owner: root group: root mode: 0644 src: files/tilix.dconf dest: /tmp/tilix.dconf owner: root group: root mode: 0644 fail: msg: \"invalid dconf key format: {{ item.key }}. keys must begin with a slash (/)\" ##- name: set dconf keys with community.general.dconf", "label": 1, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "name: src: files/terminal.desktop dest: /usr/share/applications/terminal.desktop owner: root group: root mode: \"0644\" src: files/tilix.dconf dest: /tmp/tilix.dconf owner: root group: root mode: \"0644\" ansible.builtin.fail: msg: \"invalid dconf key format: {{ item.key }}. keys must begin with a slash (/)\" ## - name: set dconf keys with community.general.dconf", "label": 0, "commit_name": "Update to fix everything with ansible-lint"}
{"code": "- compton.j2: \".config/compton/launch.sh\" - lock.j2: \".config/i3/lock.sh\" - sound.j2: \".config/i3/sound.sh\" - screens.j2: \".config/i3/screens.sh\" - background.j2: \".config/i3/background.sh\" - rofi.j2: \".config/rofi/config\" - rofi-theme.rasi: \".config/rofi/my-theme.rasi\" - polybar.j2: \".config/polybar/config\" - launch_polybar.j2: \".config/polybar/launch.sh\" - dunstrc.ini.j2: \".config/dunst/dunstrc\" - battery.sh.j2: \".config/i3/battery.sh\" mode: '755' src: \"files.desktop\" dest: \"/usr/share/applications/files.desktop\" mode: '0644'", "label": 1, "commit_name": "refactor: start lint"}
{"code": "- compton.j2: .config/compton/launch.sh - lock.j2: .config/i3/lock.sh - sound.j2: .config/i3/sound.sh - screens.j2: .config/i3/screens.sh - background.j2: .config/i3/background.sh - rofi.j2: .config/rofi/config - rofi-theme.rasi: .config/rofi/my-theme.rasi - polybar.j2: .config/polybar/config - launch_polybar.j2: .config/polybar/launch.sh - dunstrc.ini.j2: .config/dunst/dunstrc - battery.sh.j2: .config/i3/battery.sh mode: \"755\" src: files.desktop dest: /usr/share/applications/files.desktop mode: \"0644\"", "label": 0, "commit_name": "refactor: start lint"}
{"code": "state: latest - docker-ce - docker-ce-cli state: started", "label": 1, "commit_name": "Typo in worker kubelet args, install specific version of docker, set daemon params"}
{"code": "state: present - docker-ce=5:18.09.8~3-0~debian-buster - docker-ce-cli=5:18.09.8~3-0~debian-buster - name: hold the docker packages to prevent unexpected upgrades shell: apt-mark hold docker-ce docker-ce-cli - name: copy docker daemon.json copy: src: files/daemon.json dest: /etc/docker/daemon.json state: restarted", "label": 0, "commit_name": "Typo in worker kubelet args, install specific version of docker, set daemon params"}
{"code": "- name: \"verify\" - name: \"get haproxy service current state\" register: haproxy_service_status failed_when: not haproxy_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"haproxy\" - name: \"check haproxy folders and conf\" block: - name: \"check haproxy folders\" loop: - \"{{ inv_install_haproxy_path }}\" - \"{{ inv_install_haproxy_confs_path }}\" - \"{{ inv_install_haproxy_error_path }}\" - \"{{ inv_install_haproxy_ssl_path }}\" loop_control: loop_var: folder_path register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ folder_path }}\" - name: \"check haproxy errors files http\" loop: \"{{ inv_install_haproxy_error_files }}\" loop_control: loop_var: file_path register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_install_haproxy_error_path }}/{{ file_path }}.http\" - name: \"check stats url protection\" when: inv_install_haproxy_listen_stats - name: \"check haproxy connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_haproxy_listen_stats_port }}\" timeout: 120 - name: \"check an unprotected stats http url\" when: not (inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined) and not inv_install_haproxy_listen_stats_https register: result failed_when: result.status != 200 ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" - name: \"check an unprotected stats https url\" when: not (inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined) and not inv_install_haproxy_listen_stats_https register: result failed_when: result.status != 200 ansible.builtin.uri: url: \"https://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" - name: \"check a protected stats http url\" when: inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined and not inv_install_haproxy_listen_stats_https - name: \"check http basic auth-protected url availability\" register: result failed_when: result.status != 401 ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"notmyuser\" password: \"notmypassword\" - name: \"check http basic auth-protected url\" url: \"http://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"{{ inv_install_haproxy_stats_login }}\" password: \"{{ inv_install_haproxy_stats_password }}\" - name: \"check a protected stats https url\" when: inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined and inv_install_haproxy_listen_stats_https block: - name: \"check http basic auth-protected url availability\" register: result failed_when: result.status != 401 ansible.builtin.uri: url: \"https://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" force_basic_auth: true user: \"notmyuser\" password: \"notmypassword\" - name: \"check http basic auth-protected url\" url: \"https://{{ inventory_hostname }}:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" force_basic_auth: true user: \"{{ inv_install_haproxy_stats_login }}\" password: \"{{ inv_install_haproxy_stats_password }}\" # don't forget to keep this file updated # molecule/<scenario>/verify.yml - name: \"verify\" hosts: \"all:&haproxy\" gather_facts: false tasks: - name: \"get haproxy service current state\" register: haproxy_service_status failed_when: not haproxy_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"haproxy\" - name: \"check haproxy confs files\" loop: \"{{ inv_install_haproxy_http_configurations }}\" loop_control: loop_var: configuration register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_install_haproxy_confs_path }}/{{ configuration.name }}.cfg\" # don't forget to keep this file updated # molecule/<scenario>/verify.yml - name: \"verify\" hosts: \"all:&haproxy\" gather_facts: false tasks: - name: \"get haproxy service current state\" register: haproxy_service_status failed_when: not haproxy_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"haproxy\" - name: \"check haproxy confs files\" loop: \"{{ inv_install_haproxy_bdd_configurations }}\" loop_control: loop_var: configuration register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_install_haproxy_confs_path }}/{{ configuration.name }}.cfg\" - name: \"verify\" - name: \"get apache2 service current state\" register: install_apache_service_status failed_when: not install_apache_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"apache2\" - name: \"check apache2 folders and conf\" loop: - \"/etc/apache2/apache2.conf\" - \"/etc/apache2/ports.conf\" loop_control: loop_var: folder_path register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ folder_path }}\" - name: \"check apache2 http connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_apache_http_listen_port }}\" timeout: 120 - name: \"check apache2 https connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_apache_https_listen_port }}\" timeout: 120 - name: \"get apache2 service current state\" register: apache_service_status failed_when: not apache_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"apache2\" - name: \"check apache2 default configuration\" - name: \"check apache2 http and conf\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs_confs_path }}/{{ vhost.server.name }}-http.conf\" - name: \"check apache2 https and conf\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs_confs_path }}/{{ vhost.server.name }}-https.conf\" - name: \"check https conf: certs\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.crt }}\" - name: \"check https conf: keys\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.key }}\" - name: \"check apache2 webserver\" block: - name: \"check apache2 connectivity\" port: \"{{ inv_add_apache_confs_http_listen_port }}\" - name: \"check default vhost on http\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_add_apache_confs_http_listen_port }}/\" method: \"get\" - name: \"check default vhost on https\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"https://{{ inventory_hostname }}:{{ inv_add_apache_confs_https_listen_port }}/\" method: \"get\"", "label": 1, "commit_name": "refacto, iptables, fixes"}
{"code": "- name: \"verify haproxy\" - name: \"verify haproxy\" when: inv_install_haproxy | default(false) - name: \"get haproxy service current state\" register: haproxy_service_status failed_when: not haproxy_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"haproxy\" - name: \"check haproxy folders and conf\" block: - name: \"check haproxy folders\" loop: - \"{{ inv_install_haproxy_path }}\" - \"{{ inv_install_haproxy_confs_path }}\" - \"{{ inv_install_haproxy_error_path }}\" - \"{{ inv_install_haproxy_ssl_path }}\" loop_control: loop_var: folder_path register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ folder_path }}\" - name: \"check haproxy errors files http\" loop: \"{{ inv_install_haproxy_error_files }}\" loop_control: loop_var: file_path register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_install_haproxy_error_path }}/{{ file_path }}.http\" - name: \"check stats url protection\" when: inv_install_haproxy_listen_stats - name: \"check haproxy connectivity\" ansible.builtin.wait_for: host: \"127.0.0.1\" port: \"{{ inv_install_haproxy_listen_stats_port }}\" timeout: 120 - name: \"check an unprotected stats http url\" when: not (inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined) and not inv_install_haproxy_listen_stats_https url: \"http://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" - name: \"check an unprotected stats https url\" when: not (inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined) and not inv_install_haproxy_listen_stats_https url: \"https://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" validate_certs: false - name: \"check a protected stats http url\" when: inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined and not inv_install_haproxy_listen_stats_https block: - name: \"check http basic auth-protected url availability\" register: result failed_when: result.status != 401 ansible.builtin.uri: url: \"http://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"notmyuser\" password: \"notmypassword\" - name: \"check http basic auth-protected url\" register: result failed_when: result.status != 200 ansible.builtin.uri: url: \"http://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"{{ inv_install_haproxy_stats_login }}\" password: \"{{ inv_install_haproxy_stats_password }}\" - name: \"check a protected stats https url\" when: inv_install_haproxy_stats_login is defined and inv_install_haproxy_stats_password is defined and inv_install_haproxy_listen_stats_https block: - name: \"check http basic auth-protected url availability\" register: result failed_when: result.status != 401 ansible.builtin.uri: url: \"https://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"notmyuser\" password: \"notmypassword\" validate_certs: false - name: \"check http basic auth-protected url\" register: result failed_when: result.status != 200 ansible.builtin.uri: url: \"https://127.0.0.1:{{ inv_install_haproxy_listen_stats_port }}/{{ inv_install_haproxy_listen_stats_uri }}\" method: \"get\" force_basic_auth: true user: \"{{ inv_install_haproxy_stats_login }}\" password: \"{{ inv_install_haproxy_stats_password }}\" validate_certs: false - name: \"check haproxy http confs files\" when: inv_add_haproxy_http_confs_configurations | default(false) loop: \"{{ inv_add_haproxy_http_confs_configurations }}\" loop_control: loop_var: configuration register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_install_haproxy_confs_path }}/{{ configuration.name }}.cfg\" - name: \"check haproxy bdd confs files\" when: inv_add_haproxy_bdd_confs_configurations | default(false) loop: \"{{ inv_add_haproxy_bdd_confs_configurations }}\" loop_control: loop_var: configuration register: file_check failed_when: not file_check.stat.exists ansible.builtin.stat: path: \"{{ inv_install_haproxy_confs_path }}/{{ configuration.name }}.cfg\" - name: \"verify apache2\" - name: \"verify apache2\" when: inv_install_haproxy | default(false) - name: \"get apache2 service current state\" register: install_apache_service_status failed_when: not install_apache_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"apache2\" - name: \"check apache2 http connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_install_apache_http_listen_port }}\" timeout: 120 - name: \"check apache2 https connectivity\" port: \"{{ inv_install_apache_https_listen_port }}\" - name: \"get apache2 service current state\" register: apache_service_status failed_when: not apache_service_status.status.activestate == 'active' ansible.builtin.systemd: name: \"apache2\" - name: \"check apache2 default configuration\" block: - name: \"check apache2 folders and conf\" loop: - \"/etc/apache2/apache2.conf\" - \"/etc/apache2/ports.conf\" loop_control: loop_var: folder_path register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ folder_path }}\" - name: \"check apache2 http and conf\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs_confs_path }}/{{ vhost.server.name }}-http.conf\" - name: \"check apache2 https and conf\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ inv_add_apache_confs_confs_path }}/{{ vhost.server.name }}-https.conf\" - name: \"check https conf: certs\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.crt }}\" - name: \"check https conf: keys\" loop: \"{{ inv_add_apache_confs_configurations }}\" loop_control: loop_var: vhost register: folder_check when: vhost.ssl.enabled | default(false) failed_when: not folder_check.stat.exists ansible.builtin.stat: path: \"{{ vhost.ssl.key }}\" - name: \"check apache2 webserver\" block: - name: \"check apache2 connectivity\" ansible.builtin.wait_for: host: \"{{ inventory_hostname }}\" port: \"{{ inv_add_apache_confs_http_listen_port }}\" timeout: 120 - name: \"check default vhost on http\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"http://{{ inventory_hostname }}:{{ inv_add_apache_confs_http_listen_port }}/\" method: \"get\" - name: \"check default vhost on https\" register: result failed_when: not (result.status != 200 or result.status == -1) ansible.builtin.uri: url: \"https://{{ inventory_hostname }}:{{ inv_add_apache_confs_https_listen_port }}/\" method: \"get\"", "label": 0, "commit_name": "refacto, iptables, fixes"}
{"code": "\"$(rev=$(git rev-parse -q --verify \"$gitlab_ci_sign_off_exclude^{commit}\") && echo \"$rev..\")\"", "label": 1, "commit_name": "gitlab-ci: Fix sign-off check on shallow clones"}
{"code": "$(rev=$(git rev-parse -q --verify \"$gitlab_ci_sign_off_exclude^{commit}\") && echo \"$rev..\")", "label": 0, "commit_name": "gitlab-ci: Fix sign-off check on shallow clones"}
{"code": "private: \"{{ dns_private }}\" private: \"{{ dns_private }}\"", "label": 1, "commit_name": "Merge branch 'fix-dns-key-private' into 'main'"}
{"code": "private: \"{{ dns_key_private }}\" private: \"{{ dns_key_private }}\"", "label": 0, "commit_name": "Merge branch 'fix-dns-key-private' into 'main'"}
{"code": "version: 0.2.4", "label": 1, "commit_name": "Update ansible-debian-ami to fix for IMDsv2"}
{"code": "version: 0.2.5", "label": 0, "commit_name": "Update ansible-debian-ami to fix for IMDsv2"}
{"code": "file: state=directory path={{ es_script_dir }} owner={{ es_user }} group={{ es_group }}", "label": 1, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "file: state=directory path={{ es_script_dir }} owner={{ es_user }} group={{ es_group }} recurse=yes", "label": 0, "commit_name": "Support for plugin diffs + improved testing on minor upgrades + fixes"}
{"code": "port 24800:24800", "label": 1, "commit_name": "fixed typo"}
{"code": "port: 24800", "label": 0, "commit_name": "fixed typo"}
{"code": "yum: name=haproxy state=present template: src=haproxy.cfg.j2 dest=/etc/haproxy/haproxy.cfg service: name=haproxy state=started enabled=yes", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "yum: namel: haproxy state: present template: src: haproxy.cfg.j2 dest: /etc/haproxy/haproxy.cfg service: name: haproxy state: started enabled: yes", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "backup: yes - { name: freenas-nfs, ip: 192.168.90.3 }", "label": 1, "commit_name": "Fix yamllint errors"}
{"code": "backup: true - {name: freenas-nfs, ip: 192.168.90.3}", "label": 0, "commit_name": "Fix yamllint errors"}
{"code": "- name: install dependencies - name: install longhorn", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"longhorn: install dependencies\" - name: \"longhorn: install\" - name: \"longhorn: add backblaze b2 secret for backups\" kubernetes.core.k8s: state: present template: backblaze-b2-secret.yml.j2 wait: true vars: accesskey: \"{{ lookup('env', 'longhorn_backblaze_access_key') }}\" secretkey: \"{{ lookup('env', 'longhorn_backblaze_secret_key') }}\" serviceendpoint: \"{{ lookup('env', 'longhorn_service_endpoint') }}\" changed_when: false when: inventory_hostname == master_node", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "author: @crazyusb", "label": 1, "commit_name": "Fixed typo"}
{"code": "author: crazyusb", "label": 0, "commit_name": "Fixed typo"}
{"code": "image: dliappis/ubuntu:14.04 image: debian:7 image: debian:8 image: dliappis/centos:6 image: dliappis/centos:7", "label": 1, "commit_name": "Optimised testing images"}
{"code": "image: dliappis/ubuntu-devopsci:14.04 image: dliappis/debian-devopsci:7 image: dliappis/debian-devopsci:8 image: dliappis/centos-devopsci:6 image: dliappis/centos-devopsci:7", "label": 0, "commit_name": "Optimised testing images"}
{"code": "- keepassx", "label": 1, "commit_name": "Fix playbooks for kubuntu focal with new additions"}
{"code": "- wget - keepassxc", "label": 0, "commit_name": "Fix playbooks for kubuntu focal with new additions"}
{"code": "- dns_private_key", "label": 1, "commit_name": "typo"}
{"code": "- dns_key_private", "label": 0, "commit_name": "typo"}
{"code": "- name: set up apache virtuahhost", "label": 1, "commit_name": "Fixed typo"}
{"code": "- name: set up apache virtualhost", "label": 0, "commit_name": "Fixed typo"}
{"code": "traefik.http.services.hello_world.loadbalancer.server.port: \"4040\"", "label": 1, "commit_name": "Fixes Wrong loadbalancer port in `hello_world` example? #671"}
{"code": "traefik.http.services.hello_world.loadbalancer.server.port: \"8000\"", "label": 0, "commit_name": "Fixes Wrong loadbalancer port in `hello_world` example? #671"}
{"code": "- name: heal apt autoclean: yes", "label": 1, "commit_name": "fix: deep clean apt"}
{"code": "- name: apt autoremove - name: apt autoclean become: yes apt: autoclean: yes - name: apt fix become: yes apt:", "label": 0, "commit_name": "fix: deep clean apt"}
{"code": "file: path=files/private.pem state=touch mode=400", "label": 1, "commit_name": "Updated local.yml to install software and modifying permissions of private file"}
{"code": "file: path={{playbook_dir}}/files/private.pem state=touch mode=600", "label": 0, "commit_name": "Updated local.yml to install software and modifying permissions of private file"}
{"code": "msg: \"hello, {{ greeting | default('ansibl')}}!\"", "label": 1, "commit_name": "Fixed typo"}
{"code": "msg: \"hello, {{ greeting | default('ansible')}}!\"", "label": 0, "commit_name": "Fixed typo"}
{"code": "yum: enablerepo: https://brave-browser-rpm-release.s3.brave.com/x86_64/ - name: add rpm fusion free and non-free repos - bash_completion - vscodium - aria2c - speedtest - vim - yubikey-personatization-gui", "label": 1, "commit_name": "Small fixes"}
{"code": "yum.repository: name: brave-browser description: brave browser repository baseurl: https://brave-browser-rpm-release.s3.brave.com/x86_64/ enabled: true - name: add rpm fusion free and non-free repos # will not work until official fedora 36 release, testing branches available. - bash-completion - codium - aria2 - speedtest-cli - vim-enhanced - yubikey-personalization-gui", "label": 0, "commit_name": "Small fixes"}
{"code": "- name: install longhorn dependencies", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"longhorn: install dependencies\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "service: name=${elasticsearch.service} state=restarted", "label": 1, "commit_name": "Role refactor"}
{"code": "sudo: yes service: name={{ elasticsearch.deb.service }} state=restarted", "label": 0, "commit_name": "Role refactor"}
{"code": "- community.posix", "label": 1, "commit_name": "typo in collection name"}
{"code": "- ansible.posix", "label": 0, "commit_name": "typo in collection name"}
{"code": "pl_rancher_name: '{{hostname}}' pl_rancher_version: 'v1.6.10'", "label": 1, "commit_name": "rancher fixes"}
{"code": "pl_rancher_name: \"{{rancher_cluster_name|default(hostname)}}\" pl_rancher_version: \"{{rancher_version|default('v1.6.10')}}\"", "label": 0, "commit_name": "rancher fixes"}
{"code": "{% if(k8s_containerd_variant | lower == \"github\") %} runc download url {{ k8s_runc_download_url }}", "label": 1, "commit_name": "fix: typo"}
{"code": "container runtime: {{ k8s_cri }} {{ \"runc download url \" + k8s_runc_download_url if(k8s_containerd_variant == \"github\") else \"runc version: latest\" }} {% if(k8s_containerd_variant == \"github\") %} when: k8s_prepull_images", "label": 0, "commit_name": "fix: typo"}
{"code": "docker_nginx_config_root: \"{{ directory_structure_config }}/{{ docker_container_name_nginx }}\" docker_nginx_confd: \"{{ directory_structure_config }}/{{ docker_container_name_nginx }}/conf.d\" docker_nginx_http: \"{{ directory_structure_config }}/{{ docker_container_name_nginx }}/http\" docker_nginx_ssl: \"{{ directory_structure_data }}/{{ docker_container_name_nginx }}/ssl\" docker_nginx_logs: \"{{ directory_structure_logs }}/{{ docker_container_name_nginx }}\"", "label": 1, "commit_name": "Merge branch 'fix-bugs' into 'development'"}
{"code": "directory_nginx_config_root: \"{{ directory_structure_config }}/{{ docker_container_name_nginx }}\" directory_nginx_confd: \"{{ directory_structure_config }}/{{ docker_container_name_nginx }}/conf.d\" directory_nginx_http: \"{{ directory_structure_config }}/{{ docker_container_name_nginx }}/http\" directory_nginx_ssl: \"{{ directory_structure_data }}/{{ docker_container_name_nginx }}/ssl\" directory_nginx_logs: \"{{ directory_structure_logs }}/{{ docker_container_name_nginx }}\"", "label": 0, "commit_name": "Merge branch 'fix-bugs' into 'development'"}
{"code": "script: /tmp/raspbian-ua-netinst/build.sh script: /tmp/raspbian-ua-netinst/clean.sh", "label": 1, "commit_name": "build: fix scripts usage"}
{"code": "command: /usr/bin/bash /tmp/raspbian-ua-netinst/build.sh command: /usr/bin/bash /tmp/raspbian-ua-netinst/clean.sh", "label": 0, "commit_name": "build: fix scripts usage"}
{"code": "# - openvpn=2.3.10-1ubuntu2.2 # fixing version '=ver' for package, remove it if any can be used - openvpn #ovpnc_os_dist_ver: 16 ovpnc_os_dist_ver: 19", "label": 1, "commit_name": "Final source re-arrangements before second code review"}
{"code": "- openvpn=2.3.10-1ubuntu2.2 # fixing version '=ver' for package, remove it if any can be used ovpnc_os_dist_ver: 16", "label": 0, "commit_name": "Final source re-arrangements before second code review"}
{"code": "type: swimlanes matrix_synapse_manhole_enabled: \"{{ ssm_vars_synapse.manhole_enabled }}\" matrix_synapse_federation_enabled: \"{{ ssm_vars_synapse.federation_enabled }}\" matrix_synapse_metrics_enabled: \"{{ ssm_vars_synapse.metrics_enabled }}\" matrix_synapse_registration_enabled: \"{{ ssm_vars_synapse.registration_enabled }}\" matrix_s3_media_store_enabled: \"{{ ssm_vars_synapse.s3_media_store_enabled }}\" matrix_synapse_email_enabled: \"{{ ssm_vars_synapse.email_enabled }}\" matrix_ma1sd_federation_enabled: \"{{ ssm_vars_synapse.federation_enabled }}\" matrix_ma1sd_synapsesql_connection: \"postgresql://{{ matrix_synapse_db_hostname }}:{{ matrix_synapse_db_port }}/{{ matrix_synapse_db_name }}?user={{ matrix_synapse_db_username }}&password={{ matrix_synapse_db_password }}\" matrix_sygnal_enabled: true", "label": 1, "commit_name": "various fixes"}
{"code": "type: route type: check_fields ma1sd: type: check_fields container_name.regex: \".*ma1sd.*\" sygnal: type: check_fields container_name.regex: \".*sygnal.*\" ma1sd: inputs: [matrix_split.ma1sd] group_name: \"{{ ssm_vars.log_group_ma1sd }}\" <<: *docker_backend_common sygnal: inputs: [matrix_split.sygnal] group_name: \"{{ ssm_vars.log_group_sygnal }}\" <<: *docker_backend_common matrix_synapse_version: \"{{ ssm_vars_synapse.synapse_version }}\" matrix_synapse_manhole_enabled: \"{{ ssm_vars_synapse.manhole_enabled | bool }}\" matrix_synapse_federation_enabled: \"{{ ssm_vars_synapse.federation_enabled | bool }}\" matrix_synapse_metrics_enabled: \"{{ ssm_vars_synapse.metrics_enabled | bool }}\" matrix_synapse_user_directory_enabled: \"{{ ssm_vars_synapse.user_directory_enabled | bool }}\" matrix_synapse_enable_room_list_search: \"{{ ssm_vars_synapse.enable_room_list_search | bool }}\" matrix_synapse_encryption_enabled_by_default_for_room_type: \"{{ ssm_vars_synapse.encryption_enabled_by_default_for_room_type | default('all') }}\" matrix_synapse_registration_enabled: \"{{ ssm_vars_synapse.registration_enabled | bool }}\" matrix_s3_media_store_enabled: \"{{ ssm_vars_synapse.s3_media_store_enabled | bool }}\" matrix_synapse_email_enabled: \"{{ ssm_vars_synapse.email_enabled | bool }}\" matrix_ma1sd_version: \"{{ ssm_vars_ma1sd.ma1sd_version }}\" matrix_ma1sd_federation_enabled: \"{{ ssm_vars_synapse.federation_enabled | bool }}\" matrix_ma1sd_synapsesql_connection: \"//{{ matrix_synapse_db_hostname }}:{{ matrix_synapse_db_port }}/{{ matrix_synapse_db_name }}?user={{ matrix_synapse_db_username }}&password={{ matrix_synapse_db_password }}&sslmode=verify-full&sslrootcert=/ca.crt\" matrix_sygnal_enabled: \"{{ ssm_vars_sygnal.sygnal_enabled| bool }}\" matrix_sygnal_version: \"{{ ssm_vars_sygnal.sygnal_version }}\"", "label": 0, "commit_name": "various fixes"}
{"code": "- name: \"slowsaz\" tasks: - name: \"include role\" include_role: name: wordpress", "label": 1, "commit_name": "Minor fix"}
{"code": "- name: \"lamp-wordpress\" roles: - wordpress", "label": 0, "commit_name": "Minor fix"}
{"code": "loop: \"{{ groups['all'] }}\" - listen 80", "label": 1, "commit_name": "fix: fix stream and testing"}
{"code": "loop: \"{{ groups['backend'] }}\" when: inventory_hostname in groups['proxy'] - name: add dns entries for proxy node lineinfile: line: \"{{ hostvars[inventory_hostname].ansible_default_ipv4.address }} {{ hostvars[item]['backend_type'] }}.internal.test\" state: present dest: /etc/hosts loop: \"{{ groups['backend'] }}\" when: inventory_hostname in groups['proxy'] - name: configure ssl certs hosts: all become: true vars: cert_name: test_selfsigned molecule_run_dir: \"{{ lookup('env', 'molecule_ephemeral_directory') }}\" pre_tasks: - block: - name: create temporary dir for run file: path: \"{{ molecule_run_dir }}/tmp\" state: directory register: cert_tmpdir - name: create ca key community.crypto.openssl_privatekey: path: \"{{ cert_tmpdir.path }}/ca_key.pem\" register: ca_key - name: create the ca csr community.crypto.openssl_csr: path: \"{{ cert_tmpdir.path }}/ca.csr\" privatekey_path: \"{{ ca_key.filename }}\" basic_constraints: - ca:true common_name: \"my-ca\" register: ca_csr - name: sign the ca csr community.crypto.x509_certificate: path: \"{{ cert_tmpdir.path }}/ca.crt\" csr_path: \"{{ ca_csr.filename }}\" privatekey_path: \"{{ ca_key.filename }}\" provider: selfsigned register: ca_crt - name: generate an openssl private key with the default values (4096 bits, rsa) community.crypto.openssl_privatekey: path: \"{{ cert_tmpdir.path }}/{{ cert_name }}.pem\" register: test_key - name: generate an openssl certificate signing request community.crypto.openssl_csr: path: \"{{ cert_tmpdir.path }}/{{ cert_name }}.csr\" privatekey_path: \"{{ test_key.filename }}\" common_name: \"*.internal.test\" subject_alt_name: - \"ip:{{ hostvars[inventory_hostname]['ansible_eth0']['ipv4']['address'] }}\" - \"ip:127.0.0.1\" - \"dns:localhost\" - \"dns:*.internal.test\" register: test_csr - name: generate a self signed openssl certificate community.crypto.x509_certificate: path: \"{{ cert_tmpdir.path }}/{{ cert_name }}.crt\" privatekey_path: \"{{ test_key.filename }}\" csr_path: \"{{ test_csr.filename }}\" ownca_path: \"{{ ca_crt.filename }}\" ownca_privatekey_path: \"{{ ca_key.filename }}\" provider: ownca register: test_crt run_once: true become: false delegate_to: localhost when: inventory_hostname in groups['backend'] - name: copy openssl files copy: src: \"{{ item.file }}\" dest: \"{{ item.dest }}\" when: inventory_hostname in groups['backend'] loop: - dest: \"/etc/pki/tls/certs/{{ test_crt.filename | basename }}\" file: \"{{ test_crt.filename }}\" - dest: \"/etc/pki/tls/private/{{ test_key.filename | basename }}\" file: \"{{ test_key.filename }}\" - name: copy ca certificate copy: src: \"{{ item.file }}\" dest: \"{{ item.dest }}\" loop: - dest: \"/etc/pki/ca-trust/source/anchors/{{ ca_crt.filename | basename }}\" file: \"{{ ca_crt.filename }}\" - name: update ca trust command: | update-ca-trust extract update-ca-trust enable changed_when: false become: true vars: cert_name: test_selfsigned - listen 443 ssl - ssl_certificate_key /etc/pki/tls/private/{{ cert_name }}.pem - ssl_certificate /etc/pki/tls/certs/{{ cert_name }}.crt", "label": 0, "commit_name": "fix: fix stream and testing"}
{"code": "swift_system_user_name: swift swift_system_shell: /bin/bash swift_system_comment: swift system user swift_system_home_folder: \"/var/lib/{{ swift_system_user_name }}\"", "label": 1, "commit_name": "Merge \"Fix Ceilometer deployments\""}
{"code": "swift_system_user_name: \"{{ hostvars['localhost']['swift_system_user_name'] }}\" swift_system_shell: \"{{ hostvars['localhost']['swift_system_shell'] }}\" swift_system_comment: \"{{ hostvars['localhost']['swift_system_comment'] }}\" swift_system_home_folder: \"{{ hostvars['localhost']['swift_system_home_folder'] }}\" # ceilometer vars used when ceilometer is enabled ceilometer_service_user_name: \"{{ hostvars['localhost']['ceilometer_service_user_name'] }}\" ceilometer_service_tenant_name: \"{{ hostvars['localhost']['ceilometer_service_tenant_name'] }}\"", "label": 0, "commit_name": "Merge \"Fix Ceilometer deployments\""}
{"code": "beets_container_image: '{{ beets_container_repo }}{{ \":\" + beets_container_tag }}'", "label": 1, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "beets_container_image: 'linuxserver/beets:{{ beets_container_tag }}'", "label": 0, "commit_name": "Merge branch 'fix-container-roles' into 'develop'"}
{"code": "traefik.http.grafana.netdata.loadbalancer.server.port: \"3000\"", "label": 1, "commit_name": "Grafana was not linked in traefik anymore, this fixes https://github.com/davestephens/ansible-nas/issues/437"}
{"code": "traefik.http.services.grafana.loadbalancer.server.port: \"3000\"", "label": 0, "commit_name": "Grafana was not linked in traefik anymore, this fixes https://github.com/davestephens/ansible-nas/issues/437"}
{"code": "command: gitlab-ctl reconfigure", "label": 1, "commit_name": "update code"}
{"code": "become: true shell: gitlab-ctl reconfigure", "label": 0, "commit_name": "update code"}
{"code": "- name: install keycloak", "label": 1, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- name: \"keycloak: install\"", "label": 0, "commit_name": "Fix a bunch of names so it's easier to track what is happening when ansible runs, including some fixes to nextcloud and addition of b2 secret for longhorn for backup purposes"}
{"code": "- rm -rf /usr/local/homebrew - rm -rf /usr/local/caskroom - rm -rf /usr/local/bin/brew", "label": 1, "commit_name": "Issue #61: Use sudo when removing brew stuff."}
{"code": "- sudo rm -rf /usr/local/homebrew - sudo rm -rf /usr/local/caskroom - sudo rm -rf /usr/local/bin/brew", "label": 0, "commit_name": "Issue #61: Use sudo when removing brew stuff."}
{"code": "reboot: set_fact: wait_for:", "label": 1, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "ansible.builtin.reboot: ansible.builtin.set_fact: ansible.builtin.wait_for:", "label": 0, "commit_name": "Refactor: Modules and linting suggestions"}
{"code": "ipvlan_swarm_internal: \"{{ not (voip_options.gateway is defined or voip_default_route is defined) }}\"", "label": 1, "commit_name": "5046 fix internal flag on voip network"}
{"code": "ipvlan_swarm_internal: \"{{ not (voip_options.gateway | d('') != '' or voip_default_route | d('') != '') }}\"", "label": 0, "commit_name": "5046 fix internal flag on voip network"}
{"code": "- oefenweb.slack", "label": 1, "commit_name": "lint fixes"}
{"code": "- oefenweb.slack # todo possibly replace with flatpak", "label": 0, "commit_name": "lint fixes"}
{"code": "# listen for connections. empty for all interfaces, defaults to localhost only smtp_listen_interface: \"127.0.0.1 ; ::1\"", "label": 1, "commit_name": "fix smtp vars"}
{"code": "# listen for connections. empty for all interfaces, defaults to localhost ipv4 only smtp_listen_interface: \"127.0.0.1\" # default is to have one config file # this is a string not a bool smtp_use_split_config: \"false\" - {name: ntp, proto: tcp, port: 123, comment: \"outgoing ntp using tcp\"}", "label": 0, "commit_name": "fix smtp vars"}
{"code": "yum: name={{ item }} state=present seboolean: name=httpd_can_network_connect_db state=true persistent=yes service: name=httpd state=started enabled=yes", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "yum: name: \"{{ item }}\" state: present seboolean: name: httpd_can_network_connect_db state: true persistent: yes service: name: httpd state: started enabled: yes", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax."}
{"code": "name: knot-resolver=4* - restart slice - restart slice - name: create cache directory path: \"{{ item }}\" state: directory mode: 0755 owner: knot-resolver group: knot-resolver loop: - /data/knot-resolver - /data/knot-resolver/cache notify: - restart slice - name: prepare service configuration override directory state: directory mode: 0755 - name: override service configuration src: ../templates/override.conf dest: /etc/systemd/system/kresd@.service.d/override.conf - restart slice - name: enable socket become: yes systemd: name: kresd.socket enabled: yes state: started notify: - restart slice - name: disable tls socket become: yes systemd: name: kresd-tls.socket masked: yes enabled: no state: stopped notify: - restart slice", "label": 1, "commit_name": "fix: latest Raspbian and Ansible support"}
{"code": "name: knot-resolver=5* - restart knot resolver - restart knot resolver - name: clean up old cache directory path: /data/knot-resolver state: absent - name: clean up old configuration state: absent - name: knot resolver configuration src: ../templates/kresd.conf dest: /etc/knot-resolver/kresd.conf - restart knot resolver", "label": 0, "commit_name": "fix: latest Raspbian and Ansible support"}
{"code": "login_password: \"{{mysql_root_password}}\" login_user: \"{{mysql_root_user}}\" # no_log: true", "label": 1, "commit_name": "add integration with hcl vault, move passwords to vault, remove unnecessary dirs, fix some style typos"}
{"code": "- name: get pip installer get_url: url: https://bootstrap.pypa.io/pip/2.7/get-pip.py dest: /tmp/get-pip.py - name: install pip ansible.builtin.command: cmd: python /tmp/get-pip.py - name: remove trash ansible.builtin.file: path: /tmp/get-pip.py state: absent - name: install python libs ansible.builtin.pip: name: pymysql login_password: \"{{ mysql_root_password }}\" login_user: \"{{ mysql_root_user }}\" no_log: true", "label": 0, "commit_name": "add integration with hcl vault, move passwords to vault, remove unnecessary dirs, fix some style typos"}
{"code": "sudo: yes # are we running on sciencecloud? pre_tasks: - command: echo {{ ansible_ssh_host }} register: host - include_vars: targets/clouds3it.yml when: '\"172.23.\" in host.stdout' deploy_user: \"{{ ansible_ssh_user }}\" site_name: pelkmanslab # are we running on sciencecloud? pre_tasks: - command: echo {{ ansible_ssh_host }} register: host - include_vars: targets/clouds3it.yml when: '\"172.23.\" in host.stdout'", "label": 1, "commit_name": "Minor fixes"}
{"code": "sudo: yes deploy_user: \"{{ ansible_ssh_user }}\" site_name: plaque-data storage_password: q0lgzjbrwcgyx", "label": 0, "commit_name": "Minor fixes"}
{"code": "- python-certbot-nginx", "label": 1, "commit_name": "fix: switch to python3 for le"}
{"code": "- python3-certbot-nginx", "label": 0, "commit_name": "fix: switch to python3 for le"}
{"code": "get_url: ( packages | rejectattr('state', 'defined') ) | ternary( [res_download_dir.path, item.deb | basename] | path_join, item.deb ) | default(omit)", "label": 1, "commit_name": "ansible-lint: Fix some errors"}
{"code": "ansible.builtin.get_url: (packages | rejectattr('state', 'defined')) | ternary([res_download_dir.path, item.deb | basename] | path_join, item.deb) | default(omit)", "label": 0, "commit_name": "ansible-lint: Fix some errors"}
{"code": "tower_env: \"local\"", "label": 1, "commit_name": "fix CI 2"}
{"code": "#tower_env: \"local\"", "label": 0, "commit_name": "fix CI 2"}
{"code": "jira: public_port: 443 server_name: jira.internal.test upstream_host: http://{{ jira_int }} confluence: template: templates/nginx_sites.conf.j2 public_port: 443 server_name: confluence.internal.test upstream_host: http://{{ confluence_int }}", "label": 1, "commit_name": "fix: fix stream and testing"}
{"code": "stream: backends: jira: server_name: jira.internal.test upstream_host: \"{{ groups['jira_backend'][0] }}:443\" confluence: server_name: confluence.internal.test upstream_host: \"{{ groups['confluence_backend'][0] }}:443\" public_ports: - 443 - 9001", "label": 0, "commit_name": "fix: fix stream and testing"}
{"code": "# - locale-config # - backgrounds # - basic # - python3 # - terminator # - xorg # - i3 # - screen # - firefox # - wireguard # - yaprompt # - unlock # - network # - code # - vim # - volta # - rust # - docker # - zsh # - ssh # - signal # - terraform # - terragrunt # - kube # - helm # - vault # - tor # - libreoffice # - discord # - syncthings # - verracrypt # - mumble # - yubico", "label": 1, "commit_name": "fix: add all roles"}
{"code": "- locale-config - backgrounds - basic - python3 - terminator - xorg - i3 - screen - firefox - wireguard - yaprompt - unlock - network - code - vim - volta - rust - docker - zsh - ssh - signal - terraform - terragrunt - kube - helm - vault - tor - libreoffice - discord - syncthings - verracrypt - mumble - yubico", "label": 0, "commit_name": "fix: add all roles"}
{"code": "name: '{{ item }}' with_items: \"{{ packages.flatpak.install }}\" name: \"{{ item }}\" with_items: \"{{ packages.flatpak.remove }}\"", "label": 1, "commit_name": "Addressed looping package installation deprecation."}
{"code": "name: '{{ packages.flatpak.install }}' name: \"{{ packages.flatpak.remove }}\"", "label": 0, "commit_name": "Addressed looping package installation deprecation."}
{"code": "- name: \"block all trafic from other hosts on port maxscale http(s) (disable acces to portainer without apache2)\"", "label": 1, "commit_name": "fix typo"}
{"code": "- name: \"block all trafic from other hosts on port maxscale http(s) (disable acces to maxscale without apache2)\"", "label": 0, "commit_name": "fix typo"}
{"code": "- name: mds specicic actions", "label": 1, "commit_name": "fix ingress variant of VoIP deployment, add doc for MDS installation"}
{"code": "- name: mds specific actions", "label": 0, "commit_name": "fix ingress variant of VoIP deployment, add doc for MDS installation"}
{"code": "docker_tags: > ${ci_registry_image}:${distribution}-${distribution_version} $(echo $docker_tags | sed -r 's/(^|\\s)/\\1--tag /g') docker push $(echo $docker_tags | sed -r 's/(^|\\s)/\\1--tag /g')", "label": 1, "commit_name": "Fix CI docker tags"}
{"code": "docker_tags: ${ci_registry_image}:${distribution}-${distribution_version} --tag $docker_tags docker push $docker_tags", "label": 0, "commit_name": "Fix CI docker tags"}
{"code": "command: /bin/bash /tmp/raspbian-ua-netinst/build.sh command: /usr/bin/bash /tmp/raspbian-ua-netinst/clean.sh", "label": 1, "commit_name": "build: fix commands"}
{"code": "command: /tmp/raspbian-ua-netinst/build.sh args: chdir: /tmp/raspbian-ua-netinst/ command: /tmp/raspbian-ua-netinst/clean.sh args: chdir: /tmp/raspbian-ua-netinst/", "label": 0, "commit_name": "build: fix commands"}
{"code": "service: name=iptables state=restarted", "label": 1, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "service: name: iptables state: restarted", "label": 0, "commit_name": "Fix ansible-lint reported errors and update syntax in lamp_simple."}
{"code": "failed_when: result.status != 200 retries: 10 delay: 10 url: \"http://localhost:{{ inv_install_nexus_repository__web_port }}/\" method: \"get\"", "label": 1, "commit_name": "fix CI 2"}
{"code": "failed_when: (result.status != 200 and result.status != -1) url: \"http://{{ inventory_hostname }}:{{ inv_install_nexus_repository__web_port }}/\" method: \"get\"", "label": 0, "commit_name": "fix CI 2"}
{"code": "## nova virtualization type autodetect # set to true if nova_virt_type is not defined, then it will auto # choose kvm or qemu for nova_virt_type according to /proc/cpuinfo nova_virt_autodetect: true # once nova_virt_type is defined, then nova_virt_autodetect won't work any more nova_virt_type: kvm", "label": 1, "commit_name": "Merge \"Fix nova_virt_type auto-detection\""}
{"code": "# if this is not set, then the playbook will try to guess it. #nova_virt_type: kvm", "label": 0, "commit_name": "Merge \"Fix nova_virt_type auto-detection\""}
{"code": "- php5-pear", "label": 1, "commit_name": "Cleanup formatting and fix pear"}
{"code": "- php-pear", "label": 0, "commit_name": "Cleanup formatting and fix pear"}
{"code": "- {role: oracle_jdk, when: jdk_installed is not defined }", "label": 1, "commit_name": "Tag fixes. [ci skip]"}
{"code": "- { role: oracle_jdk, when: jdk_installed is not defined } - hive - hive - hive", "label": 0, "commit_name": "Tag fixes. [ci skip]"}
{"code": "enabled: yes", "label": 1, "commit_name": "Added smoke test, firewalld setup, heapster, encrypting secrets at rest"}
{"code": "- name: drain node shell: kubectl drain {{inventory_hostname}} --ignore-daemonsets delegate_to: \"{{ groups['all-masters'][0] }}\" enabled: yes - name: bring the host back online shell: kubectl uncordon {{inventory_hostname}} delegate_to: \"{{ groups['all-masters'][0] }}\"", "label": 0, "commit_name": "Added smoke test, firewalld setup, heapster, encrypting secrets at rest"}
{"code": "become: \"{{ rustdesk_user }}\"", "label": 1, "commit_name": "Become fix"}
{"code": "become_user: \"{{ rustdesk_user }}\"", "label": 0, "commit_name": "Become fix"}
{"code": "when: (steam_game_dirs.results | map(attribute='stat') | selectattr('islnk', 'eq', false) | length) >= 1", "label": 1, "commit_name": "Added block level validation for existing files and unlinked dirs"}
{"code": "vars: stats: \"{{ steam_game_dirs.results | map(attribute='stat') }}\" files_exist: \"{{ (stats | selectattr('exists', 'eq', true) | length) >= 1 }}\" unlinked_dirs: \"{{ (stats | selectattr('islnk', 'eq', false) | length) >= 1 }}\" when: files_exist and unlinked_dirs", "label": 0, "commit_name": "Added block level validation for existing files and unlinked dirs"}
{"code": "docker_group: dockergroup", "label": 1, "commit_name": "Disable check mode for shell tasks"}
{"code": "docker_group: dockergroup check_mode: no check_mode: no", "label": 0, "commit_name": "Disable check mode for shell tasks"}
{"code": "command: 'ln -sf /usr/share/zoneinfo/\"{{ ntptimezone }}\" /etc/localtime'", "label": 1, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "command: 'ln -sf /usr/share/zoneinfo/\"{{ timezone }}\" /etc/localtime'", "label": 0, "commit_name": "Minor bugfixes. Actually nothing important."}
{"code": "- name: install bobthefish theme shell: \"omf install bobthefish\" check_mode: no", "label": 1, "commit_name": "further tweaks"}
{"code": "- mv ~/.ansible-downloads/dotfiles/iterm/config.fish ~/.config/fish/config.fish run_once: true - name: source bash profile. shell: source $home/.bash_profile # - name: install bobthefish theme # shell: \"omf install bobthefish\" # check_mode: no", "label": 0, "commit_name": "further tweaks"}
{"code": "remote_user: root", "label": 1, "commit_name": "Added security role and configuration"}
{"code": "remote_user: \"{{ server_user_name }}\"", "label": 0, "commit_name": "Added security role and configuration"}
{"code": "- src: https://gitlab.com/stemid-ansible/roles/rpmfusion_repo.git scm: git name: rpmfusion_repo - src: https://github.com/stemid/ansible-systemd-timers.git scm: git version: feature-user-timers", "label": 1, "commit_name": "refactor"}
{"code": "roles: - src: https://gitlab.com/stemid-ansible/roles/rpmfusion_repo.git scm: git name: rpmfusion_repo - src: https://github.com/stemid/ansible-systemd-timers.git scm: git version: feature-user-timers collections: - community.general", "label": 0, "commit_name": "refactor"}
{"code": "- name: common - create vm - name: common - install docker", "label": 1, "commit_name": "\ud83d\udd12 vm: Ensure that no one except root can access my application data"}
{"code": "- name: common - create the vm - name: common - provision the vm tasks: - name: common - create mount directory for truenas become: true ansible.builtin.file: path: \"{{ root_mount_dir }}\" owner: root group: root mode: \"0700\" state: directory", "label": 0, "commit_name": "\ud83d\udd12 vm: Ensure that no one except root can access my application data"}
{"code": "- import_playbook: ./pipx.yml", "label": 1, "commit_name": "\ud83d\udea8 fixes some lint errors"}
{"code": "- name: install pipx import_playbook: ./pipx.yml", "label": 0, "commit_name": "\ud83d\udea8 fixes some lint errors"}
{"code": "# pre_tasks: # - name: update dnf cache # dnf: # update_cache: yes # - apache # - php", "label": 1, "commit_name": "Fixed the MySQL Auth problem"}
{"code": "pre_tasks: - name: update dnf cache dnf: update_cache: yes - apache - php", "label": 0, "commit_name": "Fixed the MySQL Auth problem"}
{"code": "- { role: \"setup\", tags: [\"setup\"] } - { role: \"nftables\", tags: [\"nftables\"] } - { role: \"ssh\", tags: [\"ssh\"] } - { role: \"download\", tags: [\"download\"] } - { role: \"mount\", tags: [\"mount\"] } - { role: \"php\", tags: [\"php\"] } - { role: \"apache\", tags: [\"apache\"] } - { role: \"database\", tags: [\"database\"] } - { role: \"nextcloud\", tags: [\"nextcloud\"] }", "label": 1, "commit_name": "Fix yamllint errors"}
{"code": "- {role: \"setup\", tags: [\"setup\"]} - {role: \"nftables\", tags: [\"nftables\"]} - {role: \"ssh\", tags: [\"ssh\"]} - {role: \"download\", tags: [\"download\"]} - {role: \"mount\", tags: [\"mount\"]} - {role: \"php\", tags: [\"php\"]} - {role: \"apache\", tags: [\"apache\"]} - {role: \"database\", tags: [\"database\"]} - {role: \"nextcloud\", tags: [\"nextcloud\"]}", "label": 0, "commit_name": "Fix yamllint errors"}
